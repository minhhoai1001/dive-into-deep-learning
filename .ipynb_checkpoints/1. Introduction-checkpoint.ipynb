{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dive into deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Giới thiệu\n",
    "## 1.1 Một ví dụ truyền cảm hứng\n",
    "Tưởng tượng rằng ta mới viết một chương trình để phản hồi một hiệu lệnh đánh thức như là “Alexa”, “Okay, Google” hoặc “Siri”. Hãy thử tự viết nó chỉ với một chiếc máy tính và một trình soạn thảo mã nguồn như minh hoạ trong Fig. 1.1.1. Bạn sẽ bắt đầu viết một chương trình như vậy như thế nào? Thử nghĩ xem… vấn đề này khó đấy. Cứ mỗi giây, chiếc mic sẽ thu thập cỡ tầm 44,000 mẫu tín hiệu. Mỗi mẫu là một giá trị biên độ của sóng âm. Quy tắc đáng tin cậy nào có thể từ một đoạn âm thanh thô đưa ra các dự đoán {có, không} để xác định đoạn âm thanh đó có chứa hiệu lệnh đánh thức hay không? Nếu bạn không biết xử lý điều này như thế nào, thì cũng đừng lo lắng. Chúng tôi cũng không biết làm cách nào để viết một chương trình như vậy từ đầu. Đó là lý do vì sao chúng tôi sử dụng học máy.\n",
    "\n",
    "\n",
    "Quá trình huấn luyện thường giống như mô tả trong hình Fig. 1.1.2:\n",
    "\n",
    "1. Khởi tạo mô hình một cách ngẫu nhiên. Lúc này nó vẫn chưa thể thực hiện bất kỳ tác vụ có ích nào.\n",
    "2. Thu thập một số dữ liệu đã được gán nhán (ví dụ như đoạn âm thanh kèm nhãn {có, không} tương ứng).\n",
    "3. Thay đổi các núm vặn để mô hình dự đoán chính xác hơn trên các mẫu.\n",
    "4. Lặp lại cho đến khi có một mô hình hoạt động tốt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fig. 1.1.2 Một quá trình huấn luyện điển hình](images/ml-loop.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Học sâu chỉ là một trong nhiều phương pháp phổ biến để giải quyết những bài toán học máy. Tới giờ chúng ta mới chỉ nói tổng quát về học máy chứ chưa nói về học sâu. Để thấy được tại sao học sâu lại quan trọng, ta nên dừng lại một chút để làm rõ một vài điểm thiết yếu.\n",
    "\n",
    "Thứ nhất, những vấn đề mà chúng ta đã thảo luận–học từ tín hiệu âm thanh thô, từ những giá trị điểm ảnh của tấm ảnh, hoặc dịch những câu có độ dài bất kỳ sang một ngôn ngữ khác–là những vấn đề học sâu có thể xử lý tốt còn học máy truyền thống thì không. Mô hình sâu thực sự sâu theo nghĩa nó có thể học nhiều tầng tính toán (layers of computation). Những mô hình đa tầng (hoặc có thứ bậc) -[many-layered (or hierarchical)] này có khả năng xử lý dữ liệu tri giác mức thấp theo cái cách mà những công cụ trước đây không thể. Trước đây, một phần quan trọng trong việc áp dụng học máy vào các bài toán này là tìm thủ công những kỹ thuật biến đổi dữ liệu sang một hình thức mà những mô hình nông có khả năng xử lý. Một lợi thế then chốt của học sâu là nó không chỉ thay thế mô hình nông ở thành phần cuối cùng của pipeline học tập truyền thống mà còn thay thế quá trình thiết kế đặc trưng tốn nhiều công sức. Thứ hai, bằng cách thay thế các kỹ thuật “tiền xử lý theo từng phân ngành”, học sâu đã loại bỏ ranh giới giữa thị giác máy tính, nhận dạng tiếng nói, xử lý ngôn ngữ tự nhiên, tin học y khoa và các lĩnh vực khác, cung cấp một tập hợp các công cụ xử lý những loại bài toán khác nhau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Các thành phần chính: Dữ liệu, Mô hình và Thuật toán\n",
    "Trước hết, chúng tôi muốn giải thích rõ hơn về các thành phần cốt lõi sẽ theo chúng ta xuyên suốt tất cả các bài toán học máy:\n",
    "\n",
    "1. Dữ liệu (*data*) mà chúng ta có thể học.\n",
    "2. Một mô hình (*model*) về cách biến đổi dữ liệu.\n",
    "3. Một hàm mất mát (*loss funtion*) định lượng độ lỗi của mô hình.\n",
    "4. Một thuật toán (*algorithm *) điều chỉnh các tham số của mô hình để giảm thiểu mất mát."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Dữ liệu\n",
    "Có một sự thật hiển nhiên là bạn không thể làm khoa học dữ liệu mà không có dữ liệu. Thông thường, chúng ta quan tâm đến một bộ mẫu (còn được gọi là điểm dữ liệu, ví dụ hoặc trường hợp). Để làm việc với dữ liệu một cách hữu ích, chúng ta thường cần có một cách biễu diễn chúng phù hợp dưới dạng số. Mỗi ví dụ thường bao gồm một bộ thuộc tính số gọi là đặc trưng. Các đặc trưng mà mô hình dựa vào để đưa ra dự đoán có thể được gọi đơn giản là các đặc trưng (*features*), (hoặc thường là đầu vào (*input*), hiệp biến (*covariates*) hoặc biến độc lập (*independent variables*))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi mỗi mẫu được biểu diễn bởi cùng một số lượng các giá trị, ta nói rằng dữ liệu bao gồm các vector có độ dài cố định và ta mô tả độ dài (không đổi) của vector là chiều của dữ liệu. Bạn có thể hình dung, chiều dài cố định có thể là một thuộc tính thuận tiện. Nếu ta mong muốn huấn luyện một mô hình để nhận biết ung thư qua hình ảnh từ kính hiển vi, độ dài cố định của đầu vào sẽ giúp ta loại bỏ một vấn đề cần quan tâm.\n",
    "\n",
    "Tuy nhiên, không phải tất cả dữ liệu có thể được dễ dàng biểu diễn dưới dạng vector có độ dài cố định. Đôi khi ta có thể mong đợi hình ảnh từ kính hiển vi đến từ thiết bị tiêu chuẩn, nhưng ta không thể mong đợi hình ảnh được khai thác từ Internet sẽ hiển thị với cùng độ phân giải hoặc tỉ lệ được. Đối với hình ảnh, ta có thể tính đến việc cắt xén nhằm đưa chúng về kích thước tiêu chuẩn, nhưng chiến lược này chỉ đưa ta đến đấy mà thôi. Và ta có nguy cơ sẽ mất đi thông tin trong các phần bị cắt bỏ. Hơn nữa, dữ liệu văn bản không thích hợp với cách biểu diễn dưới dạng vector có độ dài cố định. Một lợi thế lớn của học sâu so với các phương pháp truyền thống đó là các mô hình học sâu hiện đại có thể xử lý dữ liệu có độ dài biến đổi một cách uyển chuyển hơn.\n",
    "\n",
    "Nhìn chung, chúng ta có càng nhiều dữ liệu thì công việc sẽ càng dễ dàng hơn. Khi ta có nhiều dữ liệu hơn, ta có thể huấn luyện ra những mô hình mạnh mẽ hơn và ít phụ thuộc hơn vào các giả định được hình thành từ trước. Việc chuyển từ dữ liệu nhỏ sang dữ liệu lớn là một đóng góp chính cho sự thành công của học sâu hiện đại.\n",
    "\n",
    "Cuối cùng, có nhiều dữ liệu và xử lý dữ liệu một cách khéo léo thôi thì chưa đủ. Ta cần những dữ liệu đúng. Nếu dữ liệu mang đầy lỗi, hoặc nếu các đặc trưng được chọn lại không dự đoán được số lượng mục tiêu cần quan tâm, việc học sẽ thất bại. Tình huống trên có thể được khái quát bởi thuật ngữ: đưa rác vào thì nhận rác ra (garbage in, garbage out). Hơn nữa, chất lượng dự đoán kém không phải hậu quả tiềm tàng duy nhất. Trong các ứng dụng học máy có tính nhạy cảm như: dự đoán hành vi phạm pháp, sàng lọc hồ sơ cá nhân và mô hình rủi ro được sử dụng để cho vay, chúng ta phải đặc biệt cảnh giác với hậu quả của dữ liệu rác. Một dạng lỗi thường thấy xảy ra trong các bộ dữ liệu là khi một nhóm người không tồn tại trong dữ liệu huấn luyện. Hãy hình dung khi áp dụng một hệ thống nhận diện ung thư da trong thực tế mà trước đây nó chưa từng thấy qua da màu đen. Thất bại cũng có thể xảy ra khi dữ liệu không đại diện đầy đủ và chính xác cho một số nhóm người, nhưng lại đánh giá nhóm người này dựa vào định kiến của xã hội. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Mô hình\n",
    "Phần lớn học máy đều liên quan đến việc biến đổi dữ liệu theo một cách nào đó. Có thể ta muốn xây dựng một hệ thống nhận ảnh đầu vào và dự đoán mức độ cười của khuôn mặt trong ảnh. Hoặc đó cũng có thể là một hệ thống nhận vào dữ liệu đo đạc từ cảm biến và dự đoán độ bình thường hay bất thường của chúng. Ở đây chúng ta gọi mô hình là một hệ thống tính toán nhận đầu vào là một dạng dữ liệu và sau đó trả về kết quả dự đoán, có thể ở một dạng dữ liệu khác. Điểm khác biệt chính của học sâu so với các phương pháp cổ điển là các mô hình mạnh mẽ mà nó nhắm vào. Những mô hình đó bao gồm rất nhiều phép biến đổi dữ liệu liên tiếp, được liên kết với nhau từ trên xuống dưới, và đó cũng là ý nghĩa của cái tên “học sâu”. Trong quá trình thảo luận về các mạng nơ-ron sâu, ta cũng sẽ nhắc tới các phương pháp truyền thống."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3. Hàm mục tiêu\n",
    "Trước đó, chúng tôi có giới thiệu học máy là việc “học từ kinh nghiệm”. Học ở đây tức là việc tiến bộ ở một tác vụ nào đó theo thời gian. Nhưng ai biết được như thế nào là tiến bộ?\n",
    "Để có thể phát triển một mô hình toán học chính quy cho học máy, chúng ta cần những phép đo chính quy xem mô hình đang tốt (hoặc tệ) như thế nào. Trong học máy, hay rộng hơn là lĩnh vực tối ưu hoá, ta gọi chúng là các hàm mục tiêu (*objective function*). Theo quy ước, ta thường định nghĩa các hàm tối ưu sao cho giá trị càng thấp thì mô hình càng tốt. Chính vì ta mong muốn hàm có giá trị thấp, nó còn được gọi là hàm mất mát (*loss function*) và hàm chi phí (*cost function*).\n",
    "\n",
    "Khi muốn dự đoán một giá trị số, hàm mục tiêu phổ biến nhất là hàm bình phương sai số. Với bài toán phân loại, mục tiêu phổ biến nhất là cực tiểu hóa tỉ lệ lỗi, tức tỉ lệ mẫu mà dự đoán của mô hình lệch với nhãn thực tế. Một vài hàm mục tiêu (ví dụ như bình phương sai số) khá dễ tối ưu hóa. Các hàm khác (như tỉ lệ lỗi) lại khó tối ưu hóa trực tiếp, có thể do các hàm này không khả vi hoặc những vấn đề khác. Trong những trường hợp như vậy, ta thường tối ưu hóa một hàm mục tiêu thay thế (*surrogate objective*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thông thường, hàm mất mát được định nghĩa theo các tham số mô hình và phụ thuộc vào tập dữ liệu. Những giá trị tham số mô hình tốt nhất được học bằng cách cực tiểu hóa hàm mất mát trên một tập huấn luyện bao gồm các mẫu được thu thập cho việc huấn luyện. Tuy nhiên, mô hình hoạt động tốt trên tập huấn luyện không có nghĩa là nó sẽ hoạt động tốt trên dữ liệu kiểm tra (mà mô hình chưa nhìn thấy). Bởi vậy, ta thường chia dữ liệu sẵn có thành hai phần: dữ liệu huấn luyện (để khớp các tham số mô hình) và dữ liệu kiểm tra (được giữ lại cho việc đánh giá). Sau đó ta quan sát hai đại lượng:\n",
    "\n",
    "* **Lỗi huấn luyện (Training Error)**: Lỗi trên dữ liệu được dùng để huấn luyện mô hình. Bạn có thể coi nó như điểm của một sinh viên trên bài thi thử để chuẩn bị cho bài thi thật. Ngay cả khi kết quả thi thử khả quan, không thể đảm bảo rằng bài thi thật sẽ đạt kết quả tốt.\n",
    "* **Lỗi kiểm tra (Test Error)**: Đây là lỗi trên tập kiểm tra (không dùng để huấn luyện mô hình). Đại lượng này có thể chênh lệch đáng kể so với lỗi huấn luyện. Khi một mô hình hoạt động tốt trên tập huấn luyện nhưng lại không có khả năng tổng quát hóa trên dữ liệu chưa gặp, ta nói rằng mô hình bị quá khớp (*overfit*). Theo ngôn ngữ thường ngày, đây là hiện tượng “học lệch tủ” khi kết quả bài thi thật rất kém mặc dù có kết quả cao trong bài thi thử."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4. Các thuật toán tối ưu\n",
    "Một khi ta có dữ liệu, một mô hình và một hàm mục tiêu rõ ràng, ta cần một thuật toán có khả năng tìm kiếm các tham số khả dĩ tốt nhất để cực tiểu hóa hàm mất mát. Các thuật toán tối ưu phổ biến nhất cho mạng nơ-ron đều theo một hướng tiếp cận gọi là hạ gradient (*gradient descent*). Một cách ngắn gọn, tại mỗi bước và với mỗi tham số, ta kiểm tra xem hàm mất mát thay đổi như thế nào nếu ta thay đổi tham số đó bởi một lượng nhỏ. Sau đó các tham số này được cập nhật theo hướng làm giảm hàm mất mát."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Các dạng Học Máy\n",
    "### 1.3.1. Học có giám sát (supervised learning)\n",
    "Học có giám sát giải quyết tác vụ dự đoán mục tiêu với đầu vào cho trước. Các mục tiêu, thường được gọi là nhãn (*labels*), phần lớn được ký hiệu bằng $y$ . Dữ liệu đầu vào, thường được gọi là đặc trưng (*features*) hoặc hiệp biến, thông thường được ký hiệu là $x$ . Mỗi cặp (đầu vào, mục tiêu) được gọi là một mẫu. Thi thoảng, khi văn cảnh rõ ràng hơn, chúng ta có thể sử dụng thuật ngữ các mẫu để chỉ một tập các đầu vào, ngay cả khi chưa xác định được mục tiêu tương ứng. Ta ký hiệu một mẫu cụ thể với một chỉ số dưới, thường là  $i$ , ví dụ ( $x_i,y_i$ ). Một tập dữ liệu là một tập của  n  mẫu  $[x_i,y_i]^n_{i=1}$ . Mục đích của chúng ta là xây dựng một mô hình  $f_θ$  ánh xạ đầu vào bất kỳ  xi  tới một dự đoán  $f_θ(x_i)$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một ví dụ cụ thể hơn, trong lĩnh vực chăm sóc sức khoẻ, chúng ta có thể muốn dự đoán liệu một bệnh nhân có bị đau tim hay không. Việc bị đau tim hay không bị đau tim sẽ là nhãn $y$ . Dữ liệu đầu vào **x**  có thể là các dấu hiệu quan trọng như nhịp tim, huyết áp tâm trương và tâm thu, v.v."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theo thuật ngữ xác suất, ta thường quan tâm tới việc đánh giá xác suất có điều kiện $P(y|x)$. Dù chỉ là một trong số nhiều mô hình trong học máy, học có giám sát là nhân tố chính đem đến sự thành công cho các ứng dụng của học máy trong công nghiệp. Một phần vì rất nhiều tác vụ có thể được mô tả dưới dạng ước lượng xác suất của một đại lượng chưa biết cho trước trong một tập dữ liệu cụ thể:\n",
    "\n",
    "* Dự đoán có bị ung thư hay không cho trước một bức ảnh CT.\n",
    "* Dự đoán bản dịch chính xác trong tiếng Pháp cho trước một câu trong tiếng Anh.\n",
    "* Dự đoán giá của cổ phiếu trong tháng tới dựa trên dữ liệu báo cáo tài chính của tháng này.\n",
    "\n",
    "Một cách dễ hiểu, quá trình học gồm những bước sau: Lấy một tập mẫu lớn với các hiệp biến đã biết trước. Từ đó chọn ra một tập con ngẫu nhiên và thu thập các nhãn gốc cho chúng. Đôi khi những nhãn này có thể đã có sẵn trong dữ liệu (ví dụ, liệu bệnh nhân đã qua đời trong năm tiếp theo?). Trong trường hợp khác, chúng ta cần thuê người gán nhãn cho dữ liệu (ví dụ, gán một bức ảnh vào một hạng mục nào đó)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![supervised-learning](images/supervised-learning.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1.1. Hồi quy (Regression)\n",
    "Có lẽ tác vụ học có giám sát đơn giản nhất là hồi quy. Xét ví dụ một tập dữ liệu thu thập được từ cơ sở dữ liệu buôn bán nhà. Chúng ta có thể xây dựng một bảng dữ liệu, ở đó mỗi hàng tương ứng với một nhà và mỗi cột tương ứng với một thuộc tính liên quan nào đó, chẳng hạn như diện tích nhà, số lượng phòng ngủ, số lượng phòng tắm và thời gian (theo phút) để đi bộ tới trung tâm thành phố. Trong tập dữ liệu này, mỗi mẫu là một căn nhà cụ thể và vector đặc trưng tương ứng là một hàng trong bảng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
