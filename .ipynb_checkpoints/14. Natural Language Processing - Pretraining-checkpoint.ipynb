{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Xử lý Ngôn ngữ Tự nhiên: Tiền Huấn luyện\n",
    "Con người luôn có nhu cầu được giao tiếp. Chính từ nhu cầu cơ bản này mà một lượng lớn dữ liệu văn bản được tạo ra mỗi ngày. Với lượng dữ liệu văn bản đa dạng từ mạng xã hội, ứng dụng trò chuyện, email, đánh giá sản phẩm, tài liệu nghiên cứu và sách báo, việc giúp máy tính hiểu được những dữ liệu này trở nên quan trọng, nhằm đưa ra cách thức hỗ trợ hoặc quyết định dựa trên ngôn ngữ của con người.\n",
    "\n",
    "Xử lý ngôn ngữ tự nhiên nghiên cứu sự tương tác bằng ngôn ngữ tự nhiên giữa máy tính và con người. Trong thực tế, việc sử dụng các kỹ thuật xử lý ngôn ngữ tự nhiên để xử lý và phân tích dữ liệu văn bản (ngôn ngữ tự nhiên của con người) rất phổ biến, chẳng hạn như các mô hình ngôn ngữ trong Section 8.3 hay các mô hình dịch máy trong Section 9.5.\n",
    "\n",
    "Để hiểu dữ liệu văn bản, ta có thể bắt đầu với cách biểu diễn loại dữ liệu này, chẳng hạn xem mỗi từ hay từ con như một token riêng lẻ. Trong chương này, biểu diễn của mỗi token có thể được tiền huấn luyện trên một kho ngữ liệu lớn, sử dụng các mô hình word2vec, GloVe, hay embedding cho từ con. Sau khi tiền huấn luyện, biểu diễn của mỗi token có thể là một vector. Tuy nhiên, biểu diễn này vẫn không đổi dù ngữ cảnh xung quanh bất kể là gì. Ví dụ, biểu diễn vector của từ “bank” là giống nhau trong câu “go to the bank to deposit some money” (ra ngân hàng để gửi tiền) và “go to the bank to sit down” (ra bờ hồ ngồi hóng mát). Do đó, nhiều mô hình tiền huấn luyện gần đây điều chỉnh biểu diễn của cùng một token với các ngữ cảnh khác nhau. Trong số đó có BERT, một mô hình sâu hơn rất nhiều dựa trên bộ mã hóa Transformer. Trong chương này, ta sẽ tập trung vào cách tiền huấn luyện các biểu diễn như vậy cho văn bản, như được mô tả trong Fig. 14.1.\n",
    "\n",
    "![](images/nlp-map-pretrain.svg)\n",
    "\n",
    "Fig. 14.1 Các biểu diễn văn bản được tiền huấn luyện có thể được truyền vào các kiến trúc học sâu khác nhau cho các ứng dụng xử lý ngôn ngữ tự nhiên xuôi dòng khác nhau. Chương này tập trung vào cách tiền huấn luyện biểu diễn văn bản ngược dòng (upstream).\n",
    "\n",
    "Như mô tả trong Fig. 14.1, các biểu diễn văn bản được tiền huấn luyện có thể được truyền vào những kiến trúc học sâu cho các ứng dụng xử lý ngôn ngữ tự nhiên xuôi dòng khác nhau. Chúng tôi sẽ trình bày các phần này trong Section 15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.1. Embedding Từ (word2vec)\n",
    "Ngôn ngữ tự nhiên là một hệ thống phức tạp mà con người sử dụng để diễn đạt ngữ nghĩa. Trong hệ thống này, từ là đơn vị cơ bản của ngữ nghĩa. Như tên gọi của nó, một vector từ (**word vector**) là một vector được sử dụng để biểu diễn một từ. Vector từ cũng có thể được xem là vector đặc trưng của một từ. Kỹ thuật ánh xạ từ ngữ sang vector số thực còn được gọi là kỹ thuật embedding từ (**word embedding**). Trong vài năm gần đây, embedding từ dần trở thành kiến thức cơ bản trong xử lý ngôn ngữ tự nhiên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.1. Tại sao không Sử dụng Vector One-hot?\n",
    "Chúng ta đã sử dụng vector one-hot để đại diện cho từ (thực chất là ký tự) trong Section 8.5. Nhớ lại rằng khi giả sử số lượng các từ riêng biệt trong từ điển (tức kích thước từ điển) là  $N$ , mỗi từ có thể tương ứng một-một với các số nguyên liên tiếp từ $0$ đến  $N−1$ , được gọi là chỉ số của từ. Giả sử chỉ số của một từ là  $i$ . Để thu được biểu diễn vector one-hot của từ đó, ta tạo một vector có  $N$  phần tử có giá trị là 0 và đặt phần tử thứ  $i$  bằng $1$. Theo đó, mỗi từ được biểu diễn dưới dạng vector có độ dài  $N$  có thể được trực tiếp đưa vào mạng nơ-ron.\n",
    "\n",
    "Mặc dù rất dễ xây dựng các vector one-hot, nhưng chúng thường không phải là lựa chọn tốt. Một trong những lý do chính là các vector one-hot không thể biểu diễn một cách chính xác độ tương tự giữa các từ khác nhau, chẳng hạn như độ tương tự cô-sin mà ta thường sử dụng. Độ tương tự cô-sin của hai vectors  $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^d$  là giá trị cô-sin của góc giữa chúng:\n",
    "\n",
    "<center>$\\frac{\\mathbf{x}^\\top \\mathbf{y}}{\\|\\mathbf{x}\\| \\|\\mathbf{y}\\|} \\in [-1, 1]$</center>\n",
    "\n",
    "Do độ tương tự cô-sin giữa các vector one-hot của bất kỳ hai từ khác nhau nào đều bằng 0, nên rất khó sử dụng vector one-hot để biểu diễn độ tương tự giữa các từ khác nhau.\n",
    "\n",
    "[Word2vec](https://code.google.com/archive/p/word2vec/) là một công cụ được phát minh để giải quyết vấn đề trên. Nó biểu diễn mỗi từ bằng một vector có độ dài cố định và sử dụng những vector này để biểu thị tốt hơn độ tương tự và và các quan hệ loại suy (**analogy relationship**) giữa các từ. Công cụ Word2vec gồm hai mô hình: skip-gam [Mikolov et al., 2013b] và túi từ liên tục (**continuous bag of words – CBOW**) [Mikolov et al., 2013a]. Tiếp theo, ta sẽ xem xét hai mô hình này và phương pháp huấn luyện chúng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.2. Mô hình Skip-Gram\n",
    "Mô hình skip-gam giả định rằng một từ có thể được sử dụng để sinh ra các từ xung quanh nó trong một chuỗi văn bản. Ví dụ, giả sử chuỗi văn bản là “the”, “man”, “loves”, “his” và “son”. Ta sử dụng “loves” làm từ đích trung tâm và đặt kích thước cửa sổ ngữ cảnh bằng 2. Như mô tả trong Fig. 14.1.1, với từ đích trung tâm “loves”, mô hình skip-gram quan tâm đến xác suất có điều kiện sinh ra các từ ngữ cảnh (“the”, “man”, “his” và “son”) nằm trong khoảng cách không quá 2 từ:\n",
    "\n",
    "$P(\"the\",\"man\",\"his\",\"son\"∣\"loves\")$\n",
    " \n",
    "Ta giả định rằng, với từ đích trung tâm cho trước, các từ ngữ cảnh được sinh ra độc lập với nhau. Trong trường hợp này, công thức trên có thể được viết lại thành\n",
    "\n",
    "$P(\"the\"∣\"loves\")⋅P(\"man\"∣\"loves\")⋅P(\"his\"∣\"loves\")⋅P(\"son\"∣\"loves\")$\n",
    "\n",
    "![](images/skip-gram.svg)\n",
    "\n",
    "Fig. 14.1.1 Mô hình skip-gram quan tâm đến xác suất có điều kiện sinh ra các từ ngữ cảnh với một từ đích trung tâm cho trước."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong mô hình skip-gam, mỗi từ được biểu diễn bằng hai vector  $d$ -chiều để tính xác suất có điều kiện. Giả sử chỉ số của một từ trong từ điển là  $i$ , vector của từ được biểu diễn là  $\\mathbf{v}_i\\in\\mathbb{R}^d$  khi từ này là từ đích trung tâm và là  $\\mathbf{u}_i\\in\\mathbb{R}^d$  khi từ này là một từ ngữ cảnh. Gọi  $c$  và  $o$  lần lượt là chỉ số của từ đích trung tâm  $w_c$  và từ ngữ cảnh  $w_o$  trong từ điển. Có thể thu được xác suất có điều kiện sinh ra từ ngữ cảnh cho một từ đích trung tâm cho trước bằng phép toán softmax trên tích vô hướng của vector:\n",
    "\n",
    "<center>$P(w_o \\mid w_c) = \\frac{\\text{exp}(\\mathbf{u}_o^\\top \\mathbf{v}_c)}{ \\sum_{i \\in \\mathcal{V}} \\text{exp}(\\mathbf{u}_i^\\top \\mathbf{v}_c)}$</center>\n",
    " \n",
    "trong đó, tập chỉ số trong bộ từ vựng là  V={0,1,…,|V|−1} . Giả sử trong một chuỗi văn bản có độ dài  T , từ tại bước thời gian  t  được ký hiệu là  w(t) . Giả sử rằng các từ ngữ cảnh được sinh độc lập với từ trung tâm cho trước. Khi kích thước cửa sổ ngữ cảnh là  m , hàm hợp lý (**likelihood**) của mô hình skip-gam là xác suất kết hợp sinh ra tất cả các từ ngữ cảnh với bất kỳ từ trung tâm cho trước nào\n",
    "\n",
    "<center>$\\prod_{t=1}^{T} \\prod_{-m \\leq j \\leq m,\\ j \\neq 0} P(w^{(t+j)} \\mid w^{(t)})$</center>\n",
    " \n",
    "Ở đây, bất kỳ bước thời gian nào nhỏ hơn 1 hoặc lớn hơn  T  đều có thể được bỏ qua."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.3. Huấn luyện Mô hình Skip-Gram\n",
    "Các tham số trong mô hình skip-gram là vector từ đích trung tâm và vector từ ngữ cảnh cho từng từ riêng lẻ. Trong quá trình huấn luyện, chúng ta sẽ học các tham số mô hình bằng cách cực đại hóa hàm hợp lý, còn gọi là ước lượng hợp lý cực đại. Việc này tương tự với việc giảm thiểu hàm mất mát sau đây:\n",
    "\n",
    "<center>$- \\sum_{t=1}^{T} \\sum_{-m \\leq j \\leq m,\\ j \\neq 0} \\text{log}\\, P(w^{(t+j)} \\mid w^{(t)})$</center>\n",
    " \n",
    "Nếu ta dùng SGD, thì trong mỗi vòng lặp, ta chọn ra một chuỗi con nhỏ hơn bằng việc lấy mẫu ngẫu nhiên để tính toán mất mát cho chuỗi con đó, rồi sau đó tính gradient để cập nhật các tham số mô hình. Điểm then chốt của việc tính toán gradient là tính gradient của logarit xác suất có điều kiện cho vector từ trung tâm và vector từ ngữ cảnh. Đầu tiên, theo định nghĩa ta có\n",
    "\n",
    "<center>$\\log P(w_o \\mid w_c) =\n",
    "\\mathbf{u}_o^\\top \\mathbf{v}_c - \\log\\left(\\sum_{i \\in \\mathcal{V}} \\text{exp}(\\mathbf{u}_i^\\top \\mathbf{v}_c)\\right)$</center>\n",
    " \n",
    "Thông qua phép tính đạo hàm, ta nhận được giá trị gradient  vc  từ công thức trên.\n",
    "\n",
    "\\begin{split}\\begin{aligned}\n",
    "\\frac{\\partial \\text{log}\\, P(w_o \\mid w_c)}{\\partial \\mathbf{v}_c}\n",
    "&= \\mathbf{u}_o - \\frac{\\sum_{j \\in \\mathcal{V}} \\exp(\\mathbf{u}_j^\\top \\mathbf{v}_c)\\mathbf{u}_j}{\\sum_{i \\in \\mathcal{V}} \\exp(\\mathbf{u}_i^\\top \\mathbf{v}_c)}\\\\\n",
    "&= \\mathbf{u}_o - \\sum_{j \\in \\mathcal{V}} \\left(\\frac{\\text{exp}(\\mathbf{u}_j^\\top \\mathbf{v}_c)}{ \\sum_{i \\in \\mathcal{V}} \\text{exp}(\\mathbf{u}_i^\\top \\mathbf{v}_c)}\\right) \\mathbf{u}_j\\\\\n",
    "&= \\mathbf{u}_o - \\sum_{j \\in \\mathcal{V}} P(w_j \\mid w_c) \\mathbf{u}_j.\n",
    "\\end{aligned}\\end{split}\n",
    " \n",
    "Phép tính cho ra xác suất có điều kiện cho mọi từ có trong từ điển với từ đích trung tâm  wc  cho trước. Sau đó, ta lại sử dụng phương pháp đó để tìm gradient cho các vector từ khác.\n",
    "\n",
    "Sau khi huấn luyện xong, với từ bất kỳ có chỉ số là  $i$  trong từ điển, ta sẽ nhận được tập hai vector từ  $v_i$  và  $u_i$ . Trong các ứng dụng xử lý ngôn ngữ tự nhiên, vector từ đích trung tâm trong mô hình skip-gram thường được sử dụng để làm vector biểu diễn một từ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.4. Mô hình Túi từ Liên tục (CBOW)\n",
    "Mô hình túi từ liên tục (Continuous bag of words - CBOW) tương tự như mô hình skip-gram. Khác biệt lớn nhất là mô hình CBOW giả định rằng từ đích trung tâm được tạo ra dựa trên các từ ngữ cảnh phía trước và sau nó trong một chuỗi văn bản. Với cùng một chuỗi văn bản gồm các từ “the”, “man”, “loves”, “his” và “son”, trong đó “love” là từ đích trung tâm, với kích thước cửa sổ ngữ cảnh bằng 2, mô hình CBOW quan tâm đến xác suất có điều kiện để sinh ra từ đích “love” dựa trên các từ ngữ cảnh “the”, “man”, “his” và “son” (minh họa ở Fig. 14.1.2) như sau:\n",
    "\n",
    "$P(\"loves\"∣\"the\",\"man\",\"his\",\"son\")$\n",
    "\n",
    "![](images/cbow.svg)\n",
    "\n",
    "Fig. 14.1.2 Mô hình CBOW quan tâm đến xác suất có điều kiện tạo ra từ đích trung tâm dựa trên các từ ngữ cảnh cho trước."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vì có quá nhiều từ ngữ cảnh trong mô hình CBOW, ta sẽ lấy trung bình các vector từ của chúng và sau đó sử dụng phương pháp tương tự như trong mô hình skip-gram để tính xác suất có điều kiện. Giả sử  vi∈Rd  và  ui∈Rd  là vector từ ngữ cảnh và vector từ đích trung tâm của từ có chỉ số  i  trong từ điển (lưu ý rằng các ký hiệu này ngược với các ký hiệu trong mô hình skip-gram). Gọi  c  là chỉ số của từ đích trung tâm  wc , và  o1,…,o2m  là chỉ số các từ ngữ cảnh  wo1,…,wo2m  trong từ điển. Do đó, xác suất có điều kiện sinh ra từ đích trung tâm dựa vào các từ ngữ cảnh cho trước là\n",
    "\n",
    "<center>$P(w_c \\mid w_{o_1}, \\ldots, w_{o_{2m}}) = \\frac{\\text{exp}\\left(\\frac{1}{2m}\\mathbf{u}_c^\\top (\\mathbf{v}_{o_1} + \\ldots, + \\mathbf{v}_{o_{2m}}) \\right)}{ \\sum_{i \\in \\mathcal{V}} \\text{exp}\\left(\\frac{1}{2m}\\mathbf{u}_i^\\top (\\mathbf{v}_{o_1} + \\ldots, + \\mathbf{v}_{o_{2m}}) \\right)}$</center>\n",
    "\n",
    "Để rút gọn, ký hiệu  $\\mathcal{W}_o= \\{w_{o_1}, \\ldots, w_{o_{2m}}\\}$ , và  $\\bar{\\mathbf{v}}_o = \\left(\\mathbf{v}_{o_1} + \\ldots, + \\mathbf{v}_{o_{2m}} \\right)/(2m)$ . Phương trình trên được đơn giản hóa thành\n",
    "\n",
    "<center>$P(w_c \\mid \\mathcal{W}_o) = \\frac{\\exp\\left(\\mathbf{u}_c^\\top \\bar{\\mathbf{v}}_o\\right)}{\\sum_{i \\in \\mathcal{V}} \\exp\\left(\\mathbf{u}_i^\\top \\bar{\\mathbf{v}}_o\\right)}$</center>\n",
    "\n",
    "Cho một chuỗi văn bản có độ dài  T , ta giả định rằng từ xuất hiện tại bước thời gian  t  là  w(t) , và kích thước của cửa sổ ngữ cảnh là  m . Hàm hợp lý của mô hình CBOW là xác suất sinh ra bất kỳ từ đích trung tâm nào dựa vào những từ ngữ cảnh.\n",
    "\n",
    "<center>$\\prod_{t=1}^{T}  P(w^{(t)} \\mid  w^{(t-m)}, \\ldots, w^{(t-1)}, w^{(t+1)}, \\ldots, w^{(t+m)})$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.5. Huấn luyện Mô hình CBOW\n",
    "Quá trình huấn luyện mô hình CBOW khá giống với quá trình huấn luyện mô hình skip-gram. Uớc lượng hợp lý cực đại của mô hình CBOW tương đương với việc cực tiểu hóa hàm mất mát:\n",
    "\n",
    "<center>$-\\sum_{t=1}^T  \\text{log}\\, P(w^{(t)} \\mid  w^{(t-m)}, \\ldots, w^{(t-1)}, w^{(t+1)}, \\ldots, w^{(t+m)}).$</center>\n",
    " \n",
    "Lưu ý rằng\n",
    "\n",
    "<center>$\\log\\,P(w_c \\mid \\mathcal{W}_o) = \\mathbf{u}_c^\\top \\bar{\\mathbf{v}}_o - \\log\\,\\left(\\sum_{i \\in \\mathcal{V}} \\exp\\left(\\mathbf{u}_i^\\top \\bar{\\mathbf{v}}_o\\right)\\right)$</center>\n",
    " \n",
    "Thông qua phép đạo hàm, ta có thể tính log của xác suất có điều kiện của gradient của bất kỳ vector từ ngữ cảnh nào  $i = 1, \\ldots, 2m$ trong công thức trên.\n",
    "\n",
    "<center>$\\frac{\\partial \\log\\, P(w_c \\mid \\mathcal{W}_o)}{\\partial \\mathbf{v}_{o_i}} = \\frac{1}{2m} \\left(\\mathbf{u}_c - \\sum_{j \\in \\mathcal{V}} \\frac{\\exp(\\mathbf{u}_j^\\top \\bar{\\mathbf{v}}_o)\\mathbf{u}_j}{ \\sum_{i \\in \\mathcal{V}} \\text{exp}(\\mathbf{u}_i^\\top \\bar{\\mathbf{v}}_o)} \\right) = \\frac{1}{2m}\\left(\\mathbf{u}_c - \\sum_{j \\in \\mathcal{V}} P(w_j \\mid \\mathcal{W}_o) \\mathbf{u}_j \\right)$</center>\n",
    " \n",
    "Sau đó, ta sử dụng cùng phương pháp đó để tính gradient cho các vector của từ khác. Không giống như mô hình skip-gam, trong mô hình CBOW ta thường sử dụng vector từ ngữ cảnh làm vector biểu diễn một từ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.6. Tóm tắt\n",
    "- Vector từ là một vector được sử dụng để biểu diễn một từ. Kỹ thuật ánh xạ các từ sang vector số thực còn được gọi là kỹ thuật embedding từ.\n",
    "- Word2vec bao gồm cả mô hình túi từ liên tục (CBOW) và mô hình skip-gam. Mô hình skip-gam giả định rằng các từ ngữ cảnh được sinh ra dựa trên từ đích trung tâm. Mô hình CBOW giả định rằng từ đích trung tâm được sinh ra dựa trên các từ ngữ cảnh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1.7. Bài tập\n",
    "1. Độ phức tạp tính toán của mỗi gradient là bao nhiêu? Nếu từ điển chứa một lượng lớn các từ, điều này sẽ gây ra vấn đề gì?\n",
    "2. Có một số cụm từ cố định trong tiếng Anh bao gồm nhiều từ, chẳng hạn như “new york”. Bạn sẽ huấn luyện các vector từ của chúng như thế nào? Gợi ý: Xem phần 4 trong bài báo Word2vec[2].\n",
    "3. Sử dụng mô hình skip-gam làm ví dụ để tìm hiểu về thiết kế của mô hình word2vec. Mối quan hệ giữa tích vô hướng của hai vector từ và độ tương tự cô-sin trong mô hình skip-gam là gì? Đối với một cặp từ có ngữ nghĩa gần nhau, tại sao hai vector từ này lại thường có độ tương tự cô-sin cao?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.2. Huấn luyện Gần đúng\n",
    "Hãy nhớ lại nội dung của phần trước. Đặc điểm cốt lõi của mô hình skip-gram là việc sử dụng các toán tử softmax để tính xác suất có điều kiện sinh ra từ ngữ cảnh  $w_o$  dựa trên từ đích trung tâm cho trước  $w_c$ .\n",
    "\n",
    "<center>$P(w_o \\mid w_c) = \\frac{\\text{exp}(\\mathbf{u}_o^\\top \\mathbf{v}_c)}{ \\sum_{i \\in \\mathcal{V}} \\text{exp}(\\mathbf{u}_i^\\top \\mathbf{v}_c)}.$</center>\n",
    " \n",
    "Mất mát logarit tương ứng với xác suất có điều kiện trên được tính như sau\n",
    "\n",
    "<center>$-\\log P(w_o \\mid w_c) =\n",
    "-\\mathbf{u}_o^\\top \\mathbf{v}_c + \\log\\left(\\sum_{i \\in \\mathcal{V}} \\text{exp}(\\mathbf{u}_i^\\top \\mathbf{v}_c)\\right).$</center>\n",
    " \n",
    "Do toán tử softmax xem xét từ ngữ cảnh có thể là bất kỳ từ nào trong từ điển  $\\mathcal{V}$ ,\n",
    "nên mất mát được đề cập ở trên thật ra bao gồm phép lấy tổng qua tất cả phần tử trong từ điển. Ở phần trước, ta đã biết rằng cả hai mô hình skip-gram và CBOW đều tính xác suất có điều kiện thông qua toán tử softmax, do đó việc tính toán gradient cho mỗi bước bao gồm phép lấy tổng qua toàn bộ các phần tử trong từ điển. Đối với các từ điển lớn hơn với hàng trăm nghìn hoặc thậm chí hàng triệu từ, chi phí tính toán cho mỗi gradient có thể rất cao. Để giảm độ phức tạp tính toán này, chúng tôi sẽ giới thiệu hai phương pháp huấn luyện gần đúng trong phần này, đó là lấy mẫu âm (**negative sampling**) và toán tử softmax phân cấp (**hierarchical softmax**). Do không có sự khác biệt lớn giữa mô hình skip-gram và mô hình CBOW, trong phần này ta chỉ sử dụng mô hình skip-gram làm ví dụ để giới thiệu hai phương pháp huấn luyện trên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.1. Lấy mẫu Âm\n",
    "Phương pháp lấy mẫu âm sửa đổi hàm mục tiêu ban đầu. Cho một cửa sổ ngữ cảnh với từ đích trung tâm  $w_c$ , ta xem việc từ ngữ cảnh  $w_o$  xuất hiện trong cửa sổ ngữ cảnh là một sự kiện và tính xác suất của sự kiện này theo\n",
    "\n",
    "<center>$P(D=1\\mid w_c, w_o) = \\sigma(\\mathbf{u}_o^\\top \\mathbf{v}_c),$</center>\n",
    " \n",
    "Ở đây, hàm  σ  có cùng định nghĩa với hàm kích hoạt sigmoid:\n",
    "\n",
    "<center>$\\sigma(x) = \\frac{1}{1+\\exp(-x)}.$</center>\n",
    " \n",
    "Đầu tiên, ta sẽ xem xét việc huấn luyện vector từ (word vector) bằng cách cực đại hóa xác suất kết hợp của tất cả các sự kiện trong chuỗi văn bản. Cho một chuỗi văn bản có độ dài  T , ta giả sử rằng từ tại bước thời gian  t  là  w(t)  và kích thước cửa sổ ngữ cảnh là  m . Bây giờ, ta sẽ xem xét việc cực đại hóa xác suất kết hợp\n",
    "\n",
    "<center>$\\prod_{t=1}^{T} \\prod_{-m \\leq j \\leq m,\\ j \\neq 0} P(D=1\\mid w^{(t)}, w^{(t+j)}).$</center>\n",
    " \n",
    "Tuy nhiên, các sự kiện trong mô hình chỉ xem xét các mẫu dương. Trong trường hợp này, chỉ khi tất cả các vector từ bằng nhau và giá trị của chúng tiến tới vô cùng, xác suất kết hợp trên mới có thể đạt giá trị cực đại bằng 1. Rõ ràng, các vector từ như vậy là vô nghĩa. Phương pháp lấy mẫu âm khiến hàm mục tiêu có ý nghĩa hơn bằng cách lấy thêm các mẫu âm. Giả sử sự kiện  $P$  xảy ra khi từ ngữ cảnh  $w_o$  xuất hiện trong cửa sổ ngữ cảnh của từ đích trung tâm  $w_c$ , và ta lấy mẫu  $K$  từ không xuất hiện trong cửa sổ ngữ cảnh, đóng vai trò là các từ nhiễu, theo phân phối  $P(w)$ . Ta giả sử sự kiện từ nhiễu  $w_k ( k=1,…,K )$ không xuất hiện trong cửa sổ ngữ cảnh của từ đích trung tâm  $w_c$  là  $N_k$ . Giả sử các sự kiện  $P$  và  $N_1,…,N_K$  cho cả mẫu dương lẫn và mẫu âm là độc lập với nhau. Bằng cách xem xét phương pháp lấy mẫu âm, ta có thể viết lại xác suất kết hợp chỉ xem xét các mẫu dương ở trên như sau\n",
    "\n",
    "<center>$\\prod_{t=1}^{T} \\prod_{-m \\leq j \\leq m,\\ j \\neq 0} P(w^{(t+j)} \\mid w^{(t)}),$</center>\n",
    " \n",
    "Ở đây, xác suất có điều kiện được tính gần đúng bằng\n",
    "\n",
    "<center>$P(w^{(t+j)} \\mid w^{(t)}) =P(D=1\\mid w^{(t)}, w^{(t+j)})\\prod_{k=1,\\ w_k \\sim P(w)}^K P(D=0\\mid w^{(t)}, w_k).$</center>\n",
    " \n",
    "Đặt chỉ số của từ  $w^{(t)}$  trong chuỗi văn bản tại bước thời gian  $t$  là  $i_t$  và chỉ số của từ nhiễu  $w_k$  trong từ điển là  $h_k$ . Mất mát logarit cho xác suất có điều kiện ở trên là\n",
    "\n",
    "\\begin{split}\\begin{aligned}\n",
    "-\\log P(w^{(t+j)} \\mid w^{(t)})\n",
    "=& -\\log P(D=1\\mid w^{(t)}, w^{(t+j)}) - \\sum_{k=1,\\ w_k \\sim P(w)}^K \\log P(D=0\\mid w^{(t)}, w_k)\\\\\n",
    "=&-  \\log\\, \\sigma\\left(\\mathbf{u}_{i_{t+j}}^\\top \\mathbf{v}_{i_t}\\right) - \\sum_{k=1,\\ w_k \\sim P(w)}^K \\log\\left(1-\\sigma\\left(\\mathbf{u}_{h_k}^\\top \\mathbf{v}_{i_t}\\right)\\right)\\\\\n",
    "=&-  \\log\\, \\sigma\\left(\\mathbf{u}_{i_{t+j}}^\\top \\mathbf{v}_{i_t}\\right) - \\sum_{k=1,\\ w_k \\sim P(w)}^K \\log\\sigma\\left(-\\mathbf{u}_{h_k}^\\top \\mathbf{v}_{i_t}\\right).\n",
    "\\end{aligned}\\end{split}\n",
    " \n",
    "Ở đây, tính toán gradient trong mỗi bước huấn luyện không còn liên quan đến kích thước từ điển, mà có quan hệ tuyến tính với  $K$ . Khi  $K$  có giá trị nhỏ hơn, thì phương pháp lấy mẫu âm có chi phí tính toán cho mỗi bước thấp hơn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.2. Softmax Phân cấp\n",
    "Softmax phân cấp (**Hierarchical softmax**) là một phương pháp huấn luyện gần đúng khác. Phương pháp này sử dụng cấu trúc dữ liệu cây nhị phân như minh hoạ trong Fig. 14.2.1, với các nút lá của cây biểu diễn tất cả các từ trong từ điển  $\\mathcal{V}$ .\n",
    "\n",
    "![](images/hi-softmax.svg)\n",
    "Fig. 14.2.1 Softmax Phân cấp. Mỗi nút lá của cây biểu diễn một từ trong từ điển.\n",
    "\n",
    "Ta giả định  $L(w)$  là số nút trên đường đi (gồm cả gốc lẫn các nút lá) từ gốc của cây nhị phân đến nút lá của từ  $w$ . Gọi  $n(w,j)$  là nút thứ  $j$  trên đường đi này, với vector ngữ cảnh của từ là  $u_{n(w,j)}$ . Ta sử dụng ví dụ trong Fig. 14.2.1, theo đó  $L(w_3)=4$ . Softmax phân cấp tính xấp xỉ xác suất có điều kiện trong mô hình skip-gram như sau\n",
    "\n",
    "<center>$P(w_o \\mid w_c) = \\prod_{j=1}^{L(w_o)-1} \\sigma\\left( [\\![  n(w_o, j+1) = \\text{leftChild}(n(w_o, j)) ]\\!] \\cdot \\mathbf{u}_{n(w_o, j)}^\\top \\mathbf{v}_c\\right)$</center>\n",
    " \n",
    "Trong đó hàm  $σ$  có định nghĩa giống với hàm kích hoạt `sigmoid`, và  `leftChild(n)`  là nút con bên trái của nút  $n$ . Nếu  $x$  đúng thì  $[\\![x]\\!] = 1$ ; ngược lại  $[\\![x]\\!] = -1$ . Giờ ta sẽ tính xác suất có điều kiện của việc sinh ra từ  $w_3$  dựa theo từ  $w_c$  được cho trong Fig. 14.2.1. Ta cần tìm tích vô hướng của vector từ  $v_c$  (cho từ  $w_c$ ) với mỗi vector nút mà không phải là nút lá trên đường đi từ nút gốc đến  $w_3$ . Do trong cây nhị phân, đường đi từ nút gốc đến nút lá  $w3$  là trái, phải, rồi lại trái (đường đi được in đậm trong Fig. 14.2.1) nên ta có\n",
    "\n",
    "<center>$P(w_3 \\mid w_c) = \\sigma(\\mathbf{u}_{n(w_3, 1)}^\\top \\mathbf{v}_c) \\cdot \\sigma(-\\mathbf{u}_{n(w_3, 2)}^\\top \\mathbf{v}_c) \\cdot \\sigma(\\mathbf{u}_{n(w_3, 3)}^\\top \\mathbf{v}_c).$</center>\n",
    " \n",
    "Do  $\\sigma(x)+\\sigma(-x) = 1$  nên điều kiện mà tổng xác suất có điều kiện của bất kì từ nào trong từ điển $\\mathcal{V}$  được sinh ra dựa trên từ đích trung tâm cho trước  $w_c$  phải bằng 1 cũng được thoả mãn:\n",
    "\n",
    "<center>$\\sum_{w \\in \\mathcal{V}} P(w \\mid w_c) = 1.$</center>\n",
    " \n",
    "Hơn nữa, do độ lớn của  $L(w_o)-1$  là $\\mathcal{O}(\\text{log}_2|\\mathcal{V}|)$  nên khi kích thước từ điển  $\\mathcal{V}$  lớn, chi phí tính toán phụ trợ tại mỗi bước trong softmax phân cấp được giảm đáng kể so với khi không áp dụng huấn luyện gần đúng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.3. Tóm tắt\n",
    "- Lấy mẫu âm xây dựng hàm mất mát bằng cách xét các sự kiện độc lập bao gồm cả mẫu âm lẫn mẫu dương. Chi phí tính toán gradient tại mỗi bước trong quá trình huấn luyện có mối quan hệ tuyến tính với số từ nhiễu mà ta lấy mẫu.\n",
    "- Softmax phân cấp sử dụng một cây nhị phân và xây dụng hàm mất mát dựa trên đường đi từ nút gốc đến nút lá. Chi phí phụ trợ khi tính toán gradient tại mỗi bước trong quá trình huấn luyện có mối quan hệ theo hàm logarit với kích thước từ điển."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2.4. Bài tập\n",
    "1. Trước khi đọc phần tiếp theo, hãy nghĩ xem ta nên lấy mẫu các từ nhiễu như thế nào trong kĩ thuật lấy mẫu âm.\n",
    "2. Điều gì giúp cho công thức cuối cùng trong phần này là đúng?\n",
    "3. Ta có thể áp dụng lấy mẫu âm và softmax phân cấp như thế nào trong mô hình skip-gram?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.3. Tập dữ liệu để Tiền Huấn luyện Embedding Từ\n",
    "Trong phần này, chúng tôi sẽ giới thiệu cách tiền xử lý một tập dữ liệu với phương pháp lấy mẫu âm Section 14.2 và tạo các minibatch để huấn luyện word2vec. Tập dữ liệu mà ta sẽ sử dụng là [Penn Tree Bank (PTB)](https://catalog.ldc.upenn.edu/LDC99T42), một kho ngữ liệu nhỏ nhưng được sử dụng phổ biến. Tập dữ liệu này được thu thập từ các bài báo của Wall Street Journal và bao gồm các tập huấn luyện, tập kiểm định và tập kiểm tra.\n",
    "\n",
    "Đầu tiên, ta nhập các gói và mô-đun cần thiết cho thí nghiệm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.1. Đọc và Tiền xử lý Dữ liệu\n",
    "Tập dữ liệu này đã được tiền xử lý trước. Mỗi dòng của tập dữ liệu được xem là một câu. Tất cả các từ trong một câu được phân cách bằng dấu cách. Trong bài toán embedding từ, mỗi từ là một token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ..\\data\\ptb.zip from http://d2l-data.s3-accelerate.amazonaws.com/ptb.zip...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# sentences: 42069'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@save\n",
    "d2l.DATA_HUB['ptb'] = (d2l.DATA_URL + 'ptb.zip',\n",
    "                       '319d85e578af0cdc590547f26231e4e31cdf1e42')\n",
    "\n",
    "#@save\n",
    "def read_ptb():\n",
    "    data_dir = d2l.download_extract('ptb')\n",
    "    with open(os.path.join(data_dir, 'ptb.train.txt')) as f:\n",
    "        raw_text = f.read()\n",
    "    return [line.split() for line in raw_text.split('\\n')]\n",
    "\n",
    "sentences = read_ptb()\n",
    "f'# sentences: {len(sentences)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo ta sẽ xây dựng bộ từ vựng, trong đó các từ xuất hiện dưới 10 lần sẽ được xem như token “<unk>”. Lưu ý rằng tập dữ liệu PTB đã được tiền xử lý cũng chứa các token “<unk>” đại diện cho các từ hiếm gặp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vocab size: 6719'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = d2l.Vocab(sentences, min_freq=10)\n",
    "f'vocab size: {len(vocab)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.2. Lấy mẫu con\n",
    "Trong dữ liệu văn bản, thường có một số từ xuất hiện với tần suất cao, chẳng hạn như các từ “the”, “a” và “in” trong tiếng Anh. Nói chung, trong cửa sổ ngữ cảnh, sẽ tốt hơn nếu ta huấn luyện mô hình embedding từ khi một từ bình thường (chẳng hạn như “chip”) và một từ có tần suất thấp hơn (chẳng hạn như “microprocessor”) xuất hiện cùng lúc, hơn là khi một từ bình thường xuất hiện với một từ có tần suất cao hơn (chẳng hạn như “the”). Do đó, khi huấn luyện mô hình embedding từ, ta có thể thực hiện lấy mẫu con [2] trên các từ. Cụ thể, mỗi từ  wi  được gán chỉ số trong tập dữ liệu sẽ bị loại bỏ với một xác suất nhất định. Xác suất loại bỏ được tính như sau:\n",
    "\n",
    "<center>$P(w_i) = \\max\\left(1 - \\sqrt{\\frac{t}{f(w_i)}}, 0\\right)$</center>\n",
    " \n",
    "Ở đây,  $f(wi)$  là tỷ lệ giữa số lần xuất hiện từ  $wi$  với tổng số từ trong tập dữ liệu, và hằng số  $t$  là một siêu tham số (có giá trị bằng  $10^{−4}$  trong thí nghiệm này). Như ta có thể thấy, từ  wi  chỉ có thể được loại bỏ trong lúc lấy mẫu con khi  $f(w_i)>t$ . Tần suất của từ càng cao, xác suất loại bỏ càng lớn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def subsampling(sentences, vocab):\n",
    "    # Map low frequency words into <unk>\n",
    "    sentences = [[vocab.idx_to_token[vocab[tk]] for tk in line]\n",
    "                 for line in sentences]\n",
    "    # Count the frequency for each word\n",
    "    counter = d2l.count_corpus(sentences)\n",
    "    num_tokens = sum(counter.values())\n",
    "\n",
    "    # Return True if to keep this token during subsampling\n",
    "    def keep(token):\n",
    "        return (random.uniform(0, 1) < math.sqrt(\n",
    "            1e-4 / counter[token] * num_tokens))\n",
    "\n",
    "    # Now do the subsampling\n",
    "    return [[tk for tk in line if keep(tk)] for line in sentences]\n",
    "\n",
    "subsampled = subsampling(sentences, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So sánh độ dài chuỗi trước và sau khi lấy mẫu, ta có thể thấy việc lấy mẫu con làm giảm đáng kể độ dài chuỗi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n",
       "<svg height=\"180.65625pt\" version=\"1.1\" viewBox=\"0 0 262.190625 180.65625\" width=\"262.190625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       " <metadata>\r\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n",
       "   <cc:Work>\r\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n",
       "    <dc:date>2021-05-06T20:42:19.300879</dc:date>\r\n",
       "    <dc:format>image/svg+xml</dc:format>\r\n",
       "    <dc:creator>\r\n",
       "     <cc:Agent>\r\n",
       "      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n",
       "     </cc:Agent>\r\n",
       "    </dc:creator>\r\n",
       "   </cc:Work>\r\n",
       "  </rdf:RDF>\r\n",
       " </metadata>\r\n",
       " <defs>\r\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n",
       " </defs>\r\n",
       " <g id=\"figure_1\">\r\n",
       "  <g id=\"patch_1\">\r\n",
       "   <path d=\"M 0 180.65625 \r\n",
       "L 262.190625 180.65625 \r\n",
       "L 262.190625 0 \r\n",
       "L 0 0 \r\n",
       "z\r\n",
       "\" style=\"fill:none;\"/>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_1\">\r\n",
       "   <g id=\"patch_2\">\r\n",
       "    <path d=\"M 59.690625 143.1 \r\n",
       "L 254.990625 143.1 \r\n",
       "L 254.990625 7.2 \r\n",
       "L 59.690625 7.2 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_3\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 68.567898 143.1 \r\n",
       "L 75.814651 143.1 \r\n",
       "L 75.814651 120.973312 \r\n",
       "L 68.567898 120.973312 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_4\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 86.684781 143.1 \r\n",
       "L 93.931534 143.1 \r\n",
       "L 93.931534 81.753547 \r\n",
       "L 86.684781 81.753547 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_5\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 104.801664 143.1 \r\n",
       "L 112.048417 143.1 \r\n",
       "L 112.048417 72.227631 \r\n",
       "L 104.801664 72.227631 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_6\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 122.918547 143.1 \r\n",
       "L 130.1653 143.1 \r\n",
       "L 130.1653 92.931291 \r\n",
       "L 122.918547 92.931291 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_7\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 141.03543 143.1 \r\n",
       "L 148.282183 143.1 \r\n",
       "L 148.282183 122.18428 \r\n",
       "L 141.03543 122.18428 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_8\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 159.152313 143.1 \r\n",
       "L 166.399067 143.1 \r\n",
       "L 166.399067 135.996022 \r\n",
       "L 159.152313 135.996022 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_9\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 177.269196 143.1 \r\n",
       "L 184.51595 143.1 \r\n",
       "L 184.51595 141.492816 \r\n",
       "L 177.269196 141.492816 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_10\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 195.38608 143.1 \r\n",
       "L 202.632833 143.1 \r\n",
       "L 202.632833 142.692623 \r\n",
       "L 195.38608 142.692623 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_11\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 213.502963 143.1 \r\n",
       "L 220.749716 143.1 \r\n",
       "L 220.749716 142.960487 \r\n",
       "L 213.502963 142.960487 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_12\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 231.619846 143.1 \r\n",
       "L 238.866599 143.1 \r\n",
       "L 238.866599 143.021873 \r\n",
       "L 231.619846 143.021873 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_13\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 75.814651 143.1 \r\n",
       "L 83.061404 143.1 \r\n",
       "L 83.061404 13.671429 \r\n",
       "L 75.814651 13.671429 \r\n",
       "z\r\n",
       "\" style=\"fill:#ff7f0e;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_14\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 93.931534 143.1 \r\n",
       "L 101.178287 143.1 \r\n",
       "L 101.178287 50.07862 \r\n",
       "L 93.931534 50.07862 \r\n",
       "z\r\n",
       "\" style=\"fill:#ff7f0e;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_15\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 112.048417 143.1 \r\n",
       "L 119.29517 143.1 \r\n",
       "L 119.29517 131.492557 \r\n",
       "L 112.048417 131.492557 \r\n",
       "z\r\n",
       "\" style=\"fill:#ff7f0e;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_16\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 130.1653 143.1 \r\n",
       "L 137.412054 143.1 \r\n",
       "L 137.412054 142.458242 \r\n",
       "L 130.1653 142.458242 \r\n",
       "z\r\n",
       "\" style=\"fill:#ff7f0e;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_17\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 148.282183 143.1 \r\n",
       "L 155.528937 143.1 \r\n",
       "L 155.528937 143.033034 \r\n",
       "L 148.282183 143.033034 \r\n",
       "z\r\n",
       "\" style=\"fill:#ff7f0e;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_18\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 166.399067 143.1 \r\n",
       "L 173.64582 143.1 \r\n",
       "L 173.64582 143.1 \r\n",
       "L 166.399067 143.1 \r\n",
       "z\r\n",
       "\" style=\"fill:#ff7f0e;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_19\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 184.51595 143.1 \r\n",
       "L 191.762703 143.1 \r\n",
       "L 191.762703 143.1 \r\n",
       "L 184.51595 143.1 \r\n",
       "z\r\n",
       "\" style=\"fill:#ff7f0e;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_20\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 202.632833 143.1 \r\n",
       "L 209.879586 143.1 \r\n",
       "L 209.879586 143.1 \r\n",
       "L 202.632833 143.1 \r\n",
       "z\r\n",
       "\" style=\"fill:#ff7f0e;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_21\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 220.749716 143.1 \r\n",
       "L 227.996469 143.1 \r\n",
       "L 227.996469 143.1 \r\n",
       "L 220.749716 143.1 \r\n",
       "z\r\n",
       "\" style=\"fill:#ff7f0e;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_22\">\r\n",
       "    <path clip-path=\"url(#p225e40efc1)\" d=\"M 238.866599 143.1 \r\n",
       "L 246.113352 143.1 \r\n",
       "L 246.113352 143.1 \r\n",
       "L 238.866599 143.1 \r\n",
       "z\r\n",
       "\" style=\"fill:#ff7f0e;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_1\">\r\n",
       "    <g id=\"xtick_1\">\r\n",
       "     <g id=\"line2d_1\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 0 3.5 \r\n",
       "\" id=\"mc7d0d2c2e5\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"66.756209\" xlink:href=\"#mc7d0d2c2e5\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_1\">\r\n",
       "      <!-- 0 -->\r\n",
       "      <g transform=\"translate(63.574959 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 31.78125 66.40625 \r\n",
       "Q 24.171875 66.40625 20.328125 58.90625 \r\n",
       "Q 16.5 51.421875 16.5 36.375 \r\n",
       "Q 16.5 21.390625 20.328125 13.890625 \r\n",
       "Q 24.171875 6.390625 31.78125 6.390625 \r\n",
       "Q 39.453125 6.390625 43.28125 13.890625 \r\n",
       "Q 47.125 21.390625 47.125 36.375 \r\n",
       "Q 47.125 51.421875 43.28125 58.90625 \r\n",
       "Q 39.453125 66.40625 31.78125 66.40625 \r\n",
       "z\r\n",
       "M 31.78125 74.21875 \r\n",
       "Q 44.046875 74.21875 50.515625 64.515625 \r\n",
       "Q 56.984375 54.828125 56.984375 36.375 \r\n",
       "Q 56.984375 17.96875 50.515625 8.265625 \r\n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \r\n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \r\n",
       "Q 6.59375 17.96875 6.59375 36.375 \r\n",
       "Q 6.59375 54.828125 13.0625 64.515625 \r\n",
       "Q 19.53125 74.21875 31.78125 74.21875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-48\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_2\">\r\n",
       "     <g id=\"line2d_2\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"110.943729\" xlink:href=\"#mc7d0d2c2e5\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_2\">\r\n",
       "      <!-- 20 -->\r\n",
       "      <g transform=\"translate(104.581229 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 19.1875 8.296875 \r\n",
       "L 53.609375 8.296875 \r\n",
       "L 53.609375 0 \r\n",
       "L 7.328125 0 \r\n",
       "L 7.328125 8.296875 \r\n",
       "Q 12.9375 14.109375 22.625 23.890625 \r\n",
       "Q 32.328125 33.6875 34.8125 36.53125 \r\n",
       "Q 39.546875 41.84375 41.421875 45.53125 \r\n",
       "Q 43.3125 49.21875 43.3125 52.78125 \r\n",
       "Q 43.3125 58.59375 39.234375 62.25 \r\n",
       "Q 35.15625 65.921875 28.609375 65.921875 \r\n",
       "Q 23.96875 65.921875 18.8125 64.3125 \r\n",
       "Q 13.671875 62.703125 7.8125 59.421875 \r\n",
       "L 7.8125 69.390625 \r\n",
       "Q 13.765625 71.78125 18.9375 73 \r\n",
       "Q 24.125 74.21875 28.421875 74.21875 \r\n",
       "Q 39.75 74.21875 46.484375 68.546875 \r\n",
       "Q 53.21875 62.890625 53.21875 53.421875 \r\n",
       "Q 53.21875 48.921875 51.53125 44.890625 \r\n",
       "Q 49.859375 40.875 45.40625 35.40625 \r\n",
       "Q 44.1875 33.984375 37.640625 27.21875 \r\n",
       "Q 31.109375 20.453125 19.1875 8.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-50\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_3\">\r\n",
       "     <g id=\"line2d_3\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"155.131249\" xlink:href=\"#mc7d0d2c2e5\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_3\">\r\n",
       "      <!-- 40 -->\r\n",
       "      <g transform=\"translate(148.768749 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 37.796875 64.3125 \r\n",
       "L 12.890625 25.390625 \r\n",
       "L 37.796875 25.390625 \r\n",
       "z\r\n",
       "M 35.203125 72.90625 \r\n",
       "L 47.609375 72.90625 \r\n",
       "L 47.609375 25.390625 \r\n",
       "L 58.015625 25.390625 \r\n",
       "L 58.015625 17.1875 \r\n",
       "L 47.609375 17.1875 \r\n",
       "L 47.609375 0 \r\n",
       "L 37.796875 0 \r\n",
       "L 37.796875 17.1875 \r\n",
       "L 4.890625 17.1875 \r\n",
       "L 4.890625 26.703125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-52\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_4\">\r\n",
       "     <g id=\"line2d_4\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"199.318769\" xlink:href=\"#mc7d0d2c2e5\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_4\">\r\n",
       "      <!-- 60 -->\r\n",
       "      <g transform=\"translate(192.956269 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 33.015625 40.375 \r\n",
       "Q 26.375 40.375 22.484375 35.828125 \r\n",
       "Q 18.609375 31.296875 18.609375 23.390625 \r\n",
       "Q 18.609375 15.53125 22.484375 10.953125 \r\n",
       "Q 26.375 6.390625 33.015625 6.390625 \r\n",
       "Q 39.65625 6.390625 43.53125 10.953125 \r\n",
       "Q 47.40625 15.53125 47.40625 23.390625 \r\n",
       "Q 47.40625 31.296875 43.53125 35.828125 \r\n",
       "Q 39.65625 40.375 33.015625 40.375 \r\n",
       "z\r\n",
       "M 52.59375 71.296875 \r\n",
       "L 52.59375 62.3125 \r\n",
       "Q 48.875 64.0625 45.09375 64.984375 \r\n",
       "Q 41.3125 65.921875 37.59375 65.921875 \r\n",
       "Q 27.828125 65.921875 22.671875 59.328125 \r\n",
       "Q 17.53125 52.734375 16.796875 39.40625 \r\n",
       "Q 19.671875 43.65625 24.015625 45.921875 \r\n",
       "Q 28.375 48.1875 33.59375 48.1875 \r\n",
       "Q 44.578125 48.1875 50.953125 41.515625 \r\n",
       "Q 57.328125 34.859375 57.328125 23.390625 \r\n",
       "Q 57.328125 12.15625 50.6875 5.359375 \r\n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \r\n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \r\n",
       "Q 6.984375 17.96875 6.984375 36.375 \r\n",
       "Q 6.984375 53.65625 15.1875 63.9375 \r\n",
       "Q 23.390625 74.21875 37.203125 74.21875 \r\n",
       "Q 40.921875 74.21875 44.703125 73.484375 \r\n",
       "Q 48.484375 72.75 52.59375 71.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-54\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_5\">\r\n",
       "     <g id=\"line2d_5\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"243.506289\" xlink:href=\"#mc7d0d2c2e5\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_5\">\r\n",
       "      <!-- 80 -->\r\n",
       "      <g transform=\"translate(237.143789 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 31.78125 34.625 \r\n",
       "Q 24.75 34.625 20.71875 30.859375 \r\n",
       "Q 16.703125 27.09375 16.703125 20.515625 \r\n",
       "Q 16.703125 13.921875 20.71875 10.15625 \r\n",
       "Q 24.75 6.390625 31.78125 6.390625 \r\n",
       "Q 38.8125 6.390625 42.859375 10.171875 \r\n",
       "Q 46.921875 13.96875 46.921875 20.515625 \r\n",
       "Q 46.921875 27.09375 42.890625 30.859375 \r\n",
       "Q 38.875 34.625 31.78125 34.625 \r\n",
       "z\r\n",
       "M 21.921875 38.8125 \r\n",
       "Q 15.578125 40.375 12.03125 44.71875 \r\n",
       "Q 8.5 49.078125 8.5 55.328125 \r\n",
       "Q 8.5 64.0625 14.71875 69.140625 \r\n",
       "Q 20.953125 74.21875 31.78125 74.21875 \r\n",
       "Q 42.671875 74.21875 48.875 69.140625 \r\n",
       "Q 55.078125 64.0625 55.078125 55.328125 \r\n",
       "Q 55.078125 49.078125 51.53125 44.71875 \r\n",
       "Q 48 40.375 41.703125 38.8125 \r\n",
       "Q 48.828125 37.15625 52.796875 32.3125 \r\n",
       "Q 56.78125 27.484375 56.78125 20.515625 \r\n",
       "Q 56.78125 9.90625 50.3125 4.234375 \r\n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \r\n",
       "Q 19.734375 -1.421875 13.25 4.234375 \r\n",
       "Q 6.78125 9.90625 6.78125 20.515625 \r\n",
       "Q 6.78125 27.484375 10.78125 32.3125 \r\n",
       "Q 14.796875 37.15625 21.921875 38.8125 \r\n",
       "z\r\n",
       "M 18.3125 54.390625 \r\n",
       "Q 18.3125 48.734375 21.84375 45.5625 \r\n",
       "Q 25.390625 42.390625 31.78125 42.390625 \r\n",
       "Q 38.140625 42.390625 41.71875 45.5625 \r\n",
       "Q 45.3125 48.734375 45.3125 54.390625 \r\n",
       "Q 45.3125 60.0625 41.71875 63.234375 \r\n",
       "Q 38.140625 66.40625 31.78125 66.40625 \r\n",
       "Q 25.390625 66.40625 21.84375 63.234375 \r\n",
       "Q 18.3125 60.0625 18.3125 54.390625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-56\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_6\">\r\n",
       "     <!-- # tokens per sentence -->\r\n",
       "     <g transform=\"translate(100.6125 171.376563)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 51.125 44 \r\n",
       "L 36.921875 44 \r\n",
       "L 32.8125 27.6875 \r\n",
       "L 47.125 27.6875 \r\n",
       "z\r\n",
       "M 43.796875 71.78125 \r\n",
       "L 38.71875 51.515625 \r\n",
       "L 52.984375 51.515625 \r\n",
       "L 58.109375 71.78125 \r\n",
       "L 65.921875 71.78125 \r\n",
       "L 60.890625 51.515625 \r\n",
       "L 76.125 51.515625 \r\n",
       "L 76.125 44 \r\n",
       "L 58.984375 44 \r\n",
       "L 54.984375 27.6875 \r\n",
       "L 70.515625 27.6875 \r\n",
       "L 70.515625 20.21875 \r\n",
       "L 53.078125 20.21875 \r\n",
       "L 48 0 \r\n",
       "L 40.1875 0 \r\n",
       "L 45.21875 20.21875 \r\n",
       "L 30.90625 20.21875 \r\n",
       "L 25.875 0 \r\n",
       "L 18.015625 0 \r\n",
       "L 23.09375 20.21875 \r\n",
       "L 7.71875 20.21875 \r\n",
       "L 7.71875 27.6875 \r\n",
       "L 24.90625 27.6875 \r\n",
       "L 29 44 \r\n",
       "L 13.28125 44 \r\n",
       "L 13.28125 51.515625 \r\n",
       "L 30.90625 51.515625 \r\n",
       "L 35.890625 71.78125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-35\"/>\r\n",
       "       <path id=\"DejaVuSans-32\"/>\r\n",
       "       <path d=\"M 18.3125 70.21875 \r\n",
       "L 18.3125 54.6875 \r\n",
       "L 36.8125 54.6875 \r\n",
       "L 36.8125 47.703125 \r\n",
       "L 18.3125 47.703125 \r\n",
       "L 18.3125 18.015625 \r\n",
       "Q 18.3125 11.328125 20.140625 9.421875 \r\n",
       "Q 21.96875 7.515625 27.59375 7.515625 \r\n",
       "L 36.8125 7.515625 \r\n",
       "L 36.8125 0 \r\n",
       "L 27.59375 0 \r\n",
       "Q 17.1875 0 13.234375 3.875 \r\n",
       "Q 9.28125 7.765625 9.28125 18.015625 \r\n",
       "L 9.28125 47.703125 \r\n",
       "L 2.6875 47.703125 \r\n",
       "L 2.6875 54.6875 \r\n",
       "L 9.28125 54.6875 \r\n",
       "L 9.28125 70.21875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-116\"/>\r\n",
       "       <path d=\"M 30.609375 48.390625 \r\n",
       "Q 23.390625 48.390625 19.1875 42.75 \r\n",
       "Q 14.984375 37.109375 14.984375 27.296875 \r\n",
       "Q 14.984375 17.484375 19.15625 11.84375 \r\n",
       "Q 23.34375 6.203125 30.609375 6.203125 \r\n",
       "Q 37.796875 6.203125 41.984375 11.859375 \r\n",
       "Q 46.1875 17.53125 46.1875 27.296875 \r\n",
       "Q 46.1875 37.015625 41.984375 42.703125 \r\n",
       "Q 37.796875 48.390625 30.609375 48.390625 \r\n",
       "z\r\n",
       "M 30.609375 56 \r\n",
       "Q 42.328125 56 49.015625 48.375 \r\n",
       "Q 55.71875 40.765625 55.71875 27.296875 \r\n",
       "Q 55.71875 13.875 49.015625 6.21875 \r\n",
       "Q 42.328125 -1.421875 30.609375 -1.421875 \r\n",
       "Q 18.84375 -1.421875 12.171875 6.21875 \r\n",
       "Q 5.515625 13.875 5.515625 27.296875 \r\n",
       "Q 5.515625 40.765625 12.171875 48.375 \r\n",
       "Q 18.84375 56 30.609375 56 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-111\"/>\r\n",
       "       <path d=\"M 9.078125 75.984375 \r\n",
       "L 18.109375 75.984375 \r\n",
       "L 18.109375 31.109375 \r\n",
       "L 44.921875 54.6875 \r\n",
       "L 56.390625 54.6875 \r\n",
       "L 27.390625 29.109375 \r\n",
       "L 57.625 0 \r\n",
       "L 45.90625 0 \r\n",
       "L 18.109375 26.703125 \r\n",
       "L 18.109375 0 \r\n",
       "L 9.078125 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-107\"/>\r\n",
       "       <path d=\"M 56.203125 29.59375 \r\n",
       "L 56.203125 25.203125 \r\n",
       "L 14.890625 25.203125 \r\n",
       "Q 15.484375 15.921875 20.484375 11.0625 \r\n",
       "Q 25.484375 6.203125 34.421875 6.203125 \r\n",
       "Q 39.59375 6.203125 44.453125 7.46875 \r\n",
       "Q 49.3125 8.734375 54.109375 11.28125 \r\n",
       "L 54.109375 2.78125 \r\n",
       "Q 49.265625 0.734375 44.1875 -0.34375 \r\n",
       "Q 39.109375 -1.421875 33.890625 -1.421875 \r\n",
       "Q 20.796875 -1.421875 13.15625 6.1875 \r\n",
       "Q 5.515625 13.8125 5.515625 26.8125 \r\n",
       "Q 5.515625 40.234375 12.765625 48.109375 \r\n",
       "Q 20.015625 56 32.328125 56 \r\n",
       "Q 43.359375 56 49.78125 48.890625 \r\n",
       "Q 56.203125 41.796875 56.203125 29.59375 \r\n",
       "z\r\n",
       "M 47.21875 32.234375 \r\n",
       "Q 47.125 39.59375 43.09375 43.984375 \r\n",
       "Q 39.0625 48.390625 32.421875 48.390625 \r\n",
       "Q 24.90625 48.390625 20.390625 44.140625 \r\n",
       "Q 15.875 39.890625 15.1875 32.171875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-101\"/>\r\n",
       "       <path d=\"M 54.890625 33.015625 \r\n",
       "L 54.890625 0 \r\n",
       "L 45.90625 0 \r\n",
       "L 45.90625 32.71875 \r\n",
       "Q 45.90625 40.484375 42.875 44.328125 \r\n",
       "Q 39.84375 48.1875 33.796875 48.1875 \r\n",
       "Q 26.515625 48.1875 22.3125 43.546875 \r\n",
       "Q 18.109375 38.921875 18.109375 30.90625 \r\n",
       "L 18.109375 0 \r\n",
       "L 9.078125 0 \r\n",
       "L 9.078125 54.6875 \r\n",
       "L 18.109375 54.6875 \r\n",
       "L 18.109375 46.1875 \r\n",
       "Q 21.34375 51.125 25.703125 53.5625 \r\n",
       "Q 30.078125 56 35.796875 56 \r\n",
       "Q 45.21875 56 50.046875 50.171875 \r\n",
       "Q 54.890625 44.34375 54.890625 33.015625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-110\"/>\r\n",
       "       <path d=\"M 44.28125 53.078125 \r\n",
       "L 44.28125 44.578125 \r\n",
       "Q 40.484375 46.53125 36.375 47.5 \r\n",
       "Q 32.28125 48.484375 27.875 48.484375 \r\n",
       "Q 21.1875 48.484375 17.84375 46.4375 \r\n",
       "Q 14.5 44.390625 14.5 40.28125 \r\n",
       "Q 14.5 37.15625 16.890625 35.375 \r\n",
       "Q 19.28125 33.59375 26.515625 31.984375 \r\n",
       "L 29.59375 31.296875 \r\n",
       "Q 39.15625 29.25 43.1875 25.515625 \r\n",
       "Q 47.21875 21.78125 47.21875 15.09375 \r\n",
       "Q 47.21875 7.46875 41.1875 3.015625 \r\n",
       "Q 35.15625 -1.421875 24.609375 -1.421875 \r\n",
       "Q 20.21875 -1.421875 15.453125 -0.5625 \r\n",
       "Q 10.6875 0.296875 5.421875 2 \r\n",
       "L 5.421875 11.28125 \r\n",
       "Q 10.40625 8.6875 15.234375 7.390625 \r\n",
       "Q 20.0625 6.109375 24.8125 6.109375 \r\n",
       "Q 31.15625 6.109375 34.5625 8.28125 \r\n",
       "Q 37.984375 10.453125 37.984375 14.40625 \r\n",
       "Q 37.984375 18.0625 35.515625 20.015625 \r\n",
       "Q 33.0625 21.96875 24.703125 23.78125 \r\n",
       "L 21.578125 24.515625 \r\n",
       "Q 13.234375 26.265625 9.515625 29.90625 \r\n",
       "Q 5.8125 33.546875 5.8125 39.890625 \r\n",
       "Q 5.8125 47.609375 11.28125 51.796875 \r\n",
       "Q 16.75 56 26.8125 56 \r\n",
       "Q 31.78125 56 36.171875 55.265625 \r\n",
       "Q 40.578125 54.546875 44.28125 53.078125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-115\"/>\r\n",
       "       <path d=\"M 18.109375 8.203125 \r\n",
       "L 18.109375 -20.796875 \r\n",
       "L 9.078125 -20.796875 \r\n",
       "L 9.078125 54.6875 \r\n",
       "L 18.109375 54.6875 \r\n",
       "L 18.109375 46.390625 \r\n",
       "Q 20.953125 51.265625 25.265625 53.625 \r\n",
       "Q 29.59375 56 35.59375 56 \r\n",
       "Q 45.5625 56 51.78125 48.09375 \r\n",
       "Q 58.015625 40.1875 58.015625 27.296875 \r\n",
       "Q 58.015625 14.40625 51.78125 6.484375 \r\n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \r\n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \r\n",
       "Q 20.953125 3.328125 18.109375 8.203125 \r\n",
       "z\r\n",
       "M 48.6875 27.296875 \r\n",
       "Q 48.6875 37.203125 44.609375 42.84375 \r\n",
       "Q 40.53125 48.484375 33.40625 48.484375 \r\n",
       "Q 26.265625 48.484375 22.1875 42.84375 \r\n",
       "Q 18.109375 37.203125 18.109375 27.296875 \r\n",
       "Q 18.109375 17.390625 22.1875 11.75 \r\n",
       "Q 26.265625 6.109375 33.40625 6.109375 \r\n",
       "Q 40.53125 6.109375 44.609375 11.75 \r\n",
       "Q 48.6875 17.390625 48.6875 27.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-112\"/>\r\n",
       "       <path d=\"M 41.109375 46.296875 \r\n",
       "Q 39.59375 47.171875 37.8125 47.578125 \r\n",
       "Q 36.03125 48 33.890625 48 \r\n",
       "Q 26.265625 48 22.1875 43.046875 \r\n",
       "Q 18.109375 38.09375 18.109375 28.8125 \r\n",
       "L 18.109375 0 \r\n",
       "L 9.078125 0 \r\n",
       "L 9.078125 54.6875 \r\n",
       "L 18.109375 54.6875 \r\n",
       "L 18.109375 46.1875 \r\n",
       "Q 20.953125 51.171875 25.484375 53.578125 \r\n",
       "Q 30.03125 56 36.53125 56 \r\n",
       "Q 37.453125 56 38.578125 55.875 \r\n",
       "Q 39.703125 55.765625 41.0625 55.515625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-114\"/>\r\n",
       "       <path d=\"M 48.78125 52.59375 \r\n",
       "L 48.78125 44.1875 \r\n",
       "Q 44.96875 46.296875 41.140625 47.34375 \r\n",
       "Q 37.3125 48.390625 33.40625 48.390625 \r\n",
       "Q 24.65625 48.390625 19.8125 42.84375 \r\n",
       "Q 14.984375 37.3125 14.984375 27.296875 \r\n",
       "Q 14.984375 17.28125 19.8125 11.734375 \r\n",
       "Q 24.65625 6.203125 33.40625 6.203125 \r\n",
       "Q 37.3125 6.203125 41.140625 7.25 \r\n",
       "Q 44.96875 8.296875 48.78125 10.40625 \r\n",
       "L 48.78125 2.09375 \r\n",
       "Q 45.015625 0.34375 40.984375 -0.53125 \r\n",
       "Q 36.96875 -1.421875 32.421875 -1.421875 \r\n",
       "Q 20.0625 -1.421875 12.78125 6.34375 \r\n",
       "Q 5.515625 14.109375 5.515625 27.296875 \r\n",
       "Q 5.515625 40.671875 12.859375 48.328125 \r\n",
       "Q 20.21875 56 33.015625 56 \r\n",
       "Q 37.15625 56 41.109375 55.140625 \r\n",
       "Q 45.0625 54.296875 48.78125 52.59375 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-99\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-35\"/>\r\n",
       "      <use x=\"83.789062\" xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "      <use x=\"115.576172\" xlink:href=\"#DejaVuSans-116\"/>\r\n",
       "      <use x=\"154.785156\" xlink:href=\"#DejaVuSans-111\"/>\r\n",
       "      <use x=\"215.966797\" xlink:href=\"#DejaVuSans-107\"/>\r\n",
       "      <use x=\"270.251953\" xlink:href=\"#DejaVuSans-101\"/>\r\n",
       "      <use x=\"331.775391\" xlink:href=\"#DejaVuSans-110\"/>\r\n",
       "      <use x=\"395.154297\" xlink:href=\"#DejaVuSans-115\"/>\r\n",
       "      <use x=\"447.253906\" xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "      <use x=\"479.041016\" xlink:href=\"#DejaVuSans-112\"/>\r\n",
       "      <use x=\"542.517578\" xlink:href=\"#DejaVuSans-101\"/>\r\n",
       "      <use x=\"604.041016\" xlink:href=\"#DejaVuSans-114\"/>\r\n",
       "      <use x=\"645.154297\" xlink:href=\"#DejaVuSans-32\"/>\r\n",
       "      <use x=\"676.941406\" xlink:href=\"#DejaVuSans-115\"/>\r\n",
       "      <use x=\"729.041016\" xlink:href=\"#DejaVuSans-101\"/>\r\n",
       "      <use x=\"790.564453\" xlink:href=\"#DejaVuSans-110\"/>\r\n",
       "      <use x=\"853.943359\" xlink:href=\"#DejaVuSans-116\"/>\r\n",
       "      <use x=\"893.152344\" xlink:href=\"#DejaVuSans-101\"/>\r\n",
       "      <use x=\"954.675781\" xlink:href=\"#DejaVuSans-110\"/>\r\n",
       "      <use x=\"1018.054688\" xlink:href=\"#DejaVuSans-99\"/>\r\n",
       "      <use x=\"1073.035156\" xlink:href=\"#DejaVuSans-101\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_2\">\r\n",
       "    <g id=\"ytick_1\">\r\n",
       "     <g id=\"line2d_6\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L -3.5 0 \r\n",
       "\" id=\"m667f303e46\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.690625\" xlink:href=\"#m667f303e46\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_7\">\r\n",
       "      <!-- 0 -->\r\n",
       "      <g transform=\"translate(46.328125 146.899219)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_2\">\r\n",
       "     <g id=\"line2d_7\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.690625\" xlink:href=\"#m667f303e46\" y=\"115.197492\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_8\">\r\n",
       "      <!-- 5000 -->\r\n",
       "      <g transform=\"translate(27.240625 118.996711)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 10.796875 72.90625 \r\n",
       "L 49.515625 72.90625 \r\n",
       "L 49.515625 64.59375 \r\n",
       "L 19.828125 64.59375 \r\n",
       "L 19.828125 46.734375 \r\n",
       "Q 21.96875 47.46875 24.109375 47.828125 \r\n",
       "Q 26.265625 48.1875 28.421875 48.1875 \r\n",
       "Q 40.625 48.1875 47.75 41.5 \r\n",
       "Q 54.890625 34.8125 54.890625 23.390625 \r\n",
       "Q 54.890625 11.625 47.5625 5.09375 \r\n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \r\n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \r\n",
       "Q 12.796875 0.140625 7.71875 1.703125 \r\n",
       "L 7.71875 11.625 \r\n",
       "Q 12.109375 9.234375 16.796875 8.0625 \r\n",
       "Q 21.484375 6.890625 26.703125 6.890625 \r\n",
       "Q 35.15625 6.890625 40.078125 11.328125 \r\n",
       "Q 45.015625 15.765625 45.015625 23.390625 \r\n",
       "Q 45.015625 31 40.078125 35.4375 \r\n",
       "Q 35.15625 39.890625 26.703125 39.890625 \r\n",
       "Q 22.75 39.890625 18.8125 39.015625 \r\n",
       "Q 14.890625 38.140625 10.796875 36.28125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-53\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_3\">\r\n",
       "     <g id=\"line2d_8\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.690625\" xlink:href=\"#m667f303e46\" y=\"87.294985\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_9\">\r\n",
       "      <!-- 10000 -->\r\n",
       "      <g transform=\"translate(20.878125 91.094204)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 12.40625 8.296875 \r\n",
       "L 28.515625 8.296875 \r\n",
       "L 28.515625 63.921875 \r\n",
       "L 10.984375 60.40625 \r\n",
       "L 10.984375 69.390625 \r\n",
       "L 28.421875 72.90625 \r\n",
       "L 38.28125 72.90625 \r\n",
       "L 38.28125 8.296875 \r\n",
       "L 54.390625 8.296875 \r\n",
       "L 54.390625 0 \r\n",
       "L 12.40625 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-49\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_4\">\r\n",
       "     <g id=\"line2d_9\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.690625\" xlink:href=\"#m667f303e46\" y=\"59.392477\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_10\">\r\n",
       "      <!-- 15000 -->\r\n",
       "      <g transform=\"translate(20.878125 63.191696)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_5\">\r\n",
       "     <g id=\"line2d_10\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.690625\" xlink:href=\"#m667f303e46\" y=\"31.48997\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_11\">\r\n",
       "      <!-- 20000 -->\r\n",
       "      <g transform=\"translate(20.878125 35.289189)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_12\">\r\n",
       "     <!-- count -->\r\n",
       "     <g transform=\"translate(14.798438 89.25625)rotate(-90)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 8.5 21.578125 \r\n",
       "L 8.5 54.6875 \r\n",
       "L 17.484375 54.6875 \r\n",
       "L 17.484375 21.921875 \r\n",
       "Q 17.484375 14.15625 20.5 10.265625 \r\n",
       "Q 23.53125 6.390625 29.59375 6.390625 \r\n",
       "Q 36.859375 6.390625 41.078125 11.03125 \r\n",
       "Q 45.3125 15.671875 45.3125 23.6875 \r\n",
       "L 45.3125 54.6875 \r\n",
       "L 54.296875 54.6875 \r\n",
       "L 54.296875 0 \r\n",
       "L 45.3125 0 \r\n",
       "L 45.3125 8.40625 \r\n",
       "Q 42.046875 3.421875 37.71875 1 \r\n",
       "Q 33.40625 -1.421875 27.6875 -1.421875 \r\n",
       "Q 18.265625 -1.421875 13.375 4.4375 \r\n",
       "Q 8.5 10.296875 8.5 21.578125 \r\n",
       "z\r\n",
       "M 31.109375 56 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-117\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-99\"/>\r\n",
       "      <use x=\"54.980469\" xlink:href=\"#DejaVuSans-111\"/>\r\n",
       "      <use x=\"116.162109\" xlink:href=\"#DejaVuSans-117\"/>\r\n",
       "      <use x=\"179.541016\" xlink:href=\"#DejaVuSans-110\"/>\r\n",
       "      <use x=\"242.919922\" xlink:href=\"#DejaVuSans-116\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_23\">\r\n",
       "    <path d=\"M 59.690625 143.1 \r\n",
       "L 59.690625 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_24\">\r\n",
       "    <path d=\"M 254.990625 143.1 \r\n",
       "L 254.990625 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_25\">\r\n",
       "    <path d=\"M 59.690625 143.1 \r\n",
       "L 254.990625 143.1 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_26\">\r\n",
       "    <path d=\"M 59.690625 7.2 \r\n",
       "L 254.990625 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"legend_1\">\r\n",
       "    <g id=\"patch_27\">\r\n",
       "     <path d=\"M 155.389063 44.55625 \r\n",
       "L 247.990625 44.55625 \r\n",
       "Q 249.990625 44.55625 249.990625 42.55625 \r\n",
       "L 249.990625 14.2 \r\n",
       "Q 249.990625 12.2 247.990625 12.2 \r\n",
       "L 155.389063 12.2 \r\n",
       "Q 153.389063 12.2 153.389063 14.2 \r\n",
       "L 153.389063 42.55625 \r\n",
       "Q 153.389063 44.55625 155.389063 44.55625 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"patch_28\">\r\n",
       "     <path d=\"M 157.389063 23.798437 \r\n",
       "L 177.389063 23.798437 \r\n",
       "L 177.389063 16.798437 \r\n",
       "L 157.389063 16.798437 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_13\">\r\n",
       "     <!-- origin -->\r\n",
       "     <g transform=\"translate(185.389063 23.798437)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 9.421875 54.6875 \r\n",
       "L 18.40625 54.6875 \r\n",
       "L 18.40625 0 \r\n",
       "L 9.421875 0 \r\n",
       "z\r\n",
       "M 9.421875 75.984375 \r\n",
       "L 18.40625 75.984375 \r\n",
       "L 18.40625 64.59375 \r\n",
       "L 9.421875 64.59375 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-105\"/>\r\n",
       "       <path d=\"M 45.40625 27.984375 \r\n",
       "Q 45.40625 37.75 41.375 43.109375 \r\n",
       "Q 37.359375 48.484375 30.078125 48.484375 \r\n",
       "Q 22.859375 48.484375 18.828125 43.109375 \r\n",
       "Q 14.796875 37.75 14.796875 27.984375 \r\n",
       "Q 14.796875 18.265625 18.828125 12.890625 \r\n",
       "Q 22.859375 7.515625 30.078125 7.515625 \r\n",
       "Q 37.359375 7.515625 41.375 12.890625 \r\n",
       "Q 45.40625 18.265625 45.40625 27.984375 \r\n",
       "z\r\n",
       "M 54.390625 6.78125 \r\n",
       "Q 54.390625 -7.171875 48.1875 -13.984375 \r\n",
       "Q 42 -20.796875 29.203125 -20.796875 \r\n",
       "Q 24.46875 -20.796875 20.265625 -20.09375 \r\n",
       "Q 16.0625 -19.390625 12.109375 -17.921875 \r\n",
       "L 12.109375 -9.1875 \r\n",
       "Q 16.0625 -11.328125 19.921875 -12.34375 \r\n",
       "Q 23.78125 -13.375 27.78125 -13.375 \r\n",
       "Q 36.625 -13.375 41.015625 -8.765625 \r\n",
       "Q 45.40625 -4.15625 45.40625 5.171875 \r\n",
       "L 45.40625 9.625 \r\n",
       "Q 42.625 4.78125 38.28125 2.390625 \r\n",
       "Q 33.9375 0 27.875 0 \r\n",
       "Q 17.828125 0 11.671875 7.65625 \r\n",
       "Q 5.515625 15.328125 5.515625 27.984375 \r\n",
       "Q 5.515625 40.671875 11.671875 48.328125 \r\n",
       "Q 17.828125 56 27.875 56 \r\n",
       "Q 33.9375 56 38.28125 53.609375 \r\n",
       "Q 42.625 51.21875 45.40625 46.390625 \r\n",
       "L 45.40625 54.6875 \r\n",
       "L 54.390625 54.6875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-103\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-111\"/>\r\n",
       "      <use x=\"61.181641\" xlink:href=\"#DejaVuSans-114\"/>\r\n",
       "      <use x=\"102.294922\" xlink:href=\"#DejaVuSans-105\"/>\r\n",
       "      <use x=\"130.078125\" xlink:href=\"#DejaVuSans-103\"/>\r\n",
       "      <use x=\"193.554688\" xlink:href=\"#DejaVuSans-105\"/>\r\n",
       "      <use x=\"221.337891\" xlink:href=\"#DejaVuSans-110\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"patch_29\">\r\n",
       "     <path d=\"M 157.389063 38.476562 \r\n",
       "L 177.389063 38.476562 \r\n",
       "L 177.389063 31.476562 \r\n",
       "L 157.389063 31.476562 \r\n",
       "z\r\n",
       "\" style=\"fill:#ff7f0e;\"/>\r\n",
       "    </g>\r\n",
       "    <g id=\"text_14\">\r\n",
       "     <!-- subsampled -->\r\n",
       "     <g transform=\"translate(185.389063 38.476562)scale(0.1 -0.1)\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 48.6875 27.296875 \r\n",
       "Q 48.6875 37.203125 44.609375 42.84375 \r\n",
       "Q 40.53125 48.484375 33.40625 48.484375 \r\n",
       "Q 26.265625 48.484375 22.1875 42.84375 \r\n",
       "Q 18.109375 37.203125 18.109375 27.296875 \r\n",
       "Q 18.109375 17.390625 22.1875 11.75 \r\n",
       "Q 26.265625 6.109375 33.40625 6.109375 \r\n",
       "Q 40.53125 6.109375 44.609375 11.75 \r\n",
       "Q 48.6875 17.390625 48.6875 27.296875 \r\n",
       "z\r\n",
       "M 18.109375 46.390625 \r\n",
       "Q 20.953125 51.265625 25.265625 53.625 \r\n",
       "Q 29.59375 56 35.59375 56 \r\n",
       "Q 45.5625 56 51.78125 48.09375 \r\n",
       "Q 58.015625 40.1875 58.015625 27.296875 \r\n",
       "Q 58.015625 14.40625 51.78125 6.484375 \r\n",
       "Q 45.5625 -1.421875 35.59375 -1.421875 \r\n",
       "Q 29.59375 -1.421875 25.265625 0.953125 \r\n",
       "Q 20.953125 3.328125 18.109375 8.203125 \r\n",
       "L 18.109375 0 \r\n",
       "L 9.078125 0 \r\n",
       "L 9.078125 75.984375 \r\n",
       "L 18.109375 75.984375 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-98\"/>\r\n",
       "       <path d=\"M 34.28125 27.484375 \r\n",
       "Q 23.390625 27.484375 19.1875 25 \r\n",
       "Q 14.984375 22.515625 14.984375 16.5 \r\n",
       "Q 14.984375 11.71875 18.140625 8.90625 \r\n",
       "Q 21.296875 6.109375 26.703125 6.109375 \r\n",
       "Q 34.1875 6.109375 38.703125 11.40625 \r\n",
       "Q 43.21875 16.703125 43.21875 25.484375 \r\n",
       "L 43.21875 27.484375 \r\n",
       "z\r\n",
       "M 52.203125 31.203125 \r\n",
       "L 52.203125 0 \r\n",
       "L 43.21875 0 \r\n",
       "L 43.21875 8.296875 \r\n",
       "Q 40.140625 3.328125 35.546875 0.953125 \r\n",
       "Q 30.953125 -1.421875 24.3125 -1.421875 \r\n",
       "Q 15.921875 -1.421875 10.953125 3.296875 \r\n",
       "Q 6 8.015625 6 15.921875 \r\n",
       "Q 6 25.140625 12.171875 29.828125 \r\n",
       "Q 18.359375 34.515625 30.609375 34.515625 \r\n",
       "L 43.21875 34.515625 \r\n",
       "L 43.21875 35.40625 \r\n",
       "Q 43.21875 41.609375 39.140625 45 \r\n",
       "Q 35.0625 48.390625 27.6875 48.390625 \r\n",
       "Q 23 48.390625 18.546875 47.265625 \r\n",
       "Q 14.109375 46.140625 10.015625 43.890625 \r\n",
       "L 10.015625 52.203125 \r\n",
       "Q 14.9375 54.109375 19.578125 55.046875 \r\n",
       "Q 24.21875 56 28.609375 56 \r\n",
       "Q 40.484375 56 46.34375 49.84375 \r\n",
       "Q 52.203125 43.703125 52.203125 31.203125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-97\"/>\r\n",
       "       <path d=\"M 52 44.1875 \r\n",
       "Q 55.375 50.25 60.0625 53.125 \r\n",
       "Q 64.75 56 71.09375 56 \r\n",
       "Q 79.640625 56 84.28125 50.015625 \r\n",
       "Q 88.921875 44.046875 88.921875 33.015625 \r\n",
       "L 88.921875 0 \r\n",
       "L 79.890625 0 \r\n",
       "L 79.890625 32.71875 \r\n",
       "Q 79.890625 40.578125 77.09375 44.375 \r\n",
       "Q 74.3125 48.1875 68.609375 48.1875 \r\n",
       "Q 61.625 48.1875 57.5625 43.546875 \r\n",
       "Q 53.515625 38.921875 53.515625 30.90625 \r\n",
       "L 53.515625 0 \r\n",
       "L 44.484375 0 \r\n",
       "L 44.484375 32.71875 \r\n",
       "Q 44.484375 40.625 41.703125 44.40625 \r\n",
       "Q 38.921875 48.1875 33.109375 48.1875 \r\n",
       "Q 26.21875 48.1875 22.15625 43.53125 \r\n",
       "Q 18.109375 38.875 18.109375 30.90625 \r\n",
       "L 18.109375 0 \r\n",
       "L 9.078125 0 \r\n",
       "L 9.078125 54.6875 \r\n",
       "L 18.109375 54.6875 \r\n",
       "L 18.109375 46.1875 \r\n",
       "Q 21.1875 51.21875 25.484375 53.609375 \r\n",
       "Q 29.78125 56 35.6875 56 \r\n",
       "Q 41.65625 56 45.828125 52.96875 \r\n",
       "Q 50 49.953125 52 44.1875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-109\"/>\r\n",
       "       <path d=\"M 9.421875 75.984375 \r\n",
       "L 18.40625 75.984375 \r\n",
       "L 18.40625 0 \r\n",
       "L 9.421875 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-108\"/>\r\n",
       "       <path d=\"M 45.40625 46.390625 \r\n",
       "L 45.40625 75.984375 \r\n",
       "L 54.390625 75.984375 \r\n",
       "L 54.390625 0 \r\n",
       "L 45.40625 0 \r\n",
       "L 45.40625 8.203125 \r\n",
       "Q 42.578125 3.328125 38.25 0.953125 \r\n",
       "Q 33.9375 -1.421875 27.875 -1.421875 \r\n",
       "Q 17.96875 -1.421875 11.734375 6.484375 \r\n",
       "Q 5.515625 14.40625 5.515625 27.296875 \r\n",
       "Q 5.515625 40.1875 11.734375 48.09375 \r\n",
       "Q 17.96875 56 27.875 56 \r\n",
       "Q 33.9375 56 38.25 53.625 \r\n",
       "Q 42.578125 51.265625 45.40625 46.390625 \r\n",
       "z\r\n",
       "M 14.796875 27.296875 \r\n",
       "Q 14.796875 17.390625 18.875 11.75 \r\n",
       "Q 22.953125 6.109375 30.078125 6.109375 \r\n",
       "Q 37.203125 6.109375 41.296875 11.75 \r\n",
       "Q 45.40625 17.390625 45.40625 27.296875 \r\n",
       "Q 45.40625 37.203125 41.296875 42.84375 \r\n",
       "Q 37.203125 48.484375 30.078125 48.484375 \r\n",
       "Q 22.953125 48.484375 18.875 42.84375 \r\n",
       "Q 14.796875 37.203125 14.796875 27.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-100\"/>\r\n",
       "      </defs>\r\n",
       "      <use xlink:href=\"#DejaVuSans-115\"/>\r\n",
       "      <use x=\"52.099609\" xlink:href=\"#DejaVuSans-117\"/>\r\n",
       "      <use x=\"115.478516\" xlink:href=\"#DejaVuSans-98\"/>\r\n",
       "      <use x=\"178.955078\" xlink:href=\"#DejaVuSans-115\"/>\r\n",
       "      <use x=\"231.054688\" xlink:href=\"#DejaVuSans-97\"/>\r\n",
       "      <use x=\"292.333984\" xlink:href=\"#DejaVuSans-109\"/>\r\n",
       "      <use x=\"389.746094\" xlink:href=\"#DejaVuSans-112\"/>\r\n",
       "      <use x=\"453.222656\" xlink:href=\"#DejaVuSans-108\"/>\r\n",
       "      <use x=\"481.005859\" xlink:href=\"#DejaVuSans-101\"/>\r\n",
       "      <use x=\"542.529297\" xlink:href=\"#DejaVuSans-100\"/>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       " </g>\r\n",
       " <defs>\r\n",
       "  <clipPath id=\"p225e40efc1\">\r\n",
       "   <rect height=\"135.9\" width=\"195.3\" x=\"59.690625\" y=\"7.2\"/>\r\n",
       "  </clipPath>\r\n",
       " </defs>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2l.set_figsize()\n",
    "d2l.plt.hist([[len(line) for line in sentences],\n",
    "              [len(line) for line in subsampled]])\n",
    "d2l.plt.xlabel('# tokens per sentence')\n",
    "d2l.plt.ylabel('count')\n",
    "d2l.plt.legend(['origin', 'subsampled']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với các token riêng lẻ, tỉ lệ lấy mẫu của các từ có tần suất cao như từ “the” nhỏ hơn 1/20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# of \"the\": before=50770, after=2123'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_counts(token):\n",
    "    return (f'# of \"{token}\": '\n",
    "            f'before={sum([line.count(token) for line in sentences])}, '\n",
    "            f'after={sum([line.count(token) for line in subsampled])}')\n",
    "\n",
    "compare_counts('the')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhưng các từ có tần số thấp như từ “join” hoàn toàn được giữ nguyên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# of \"join\": before=45, after=45'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_counts('join')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuối cùng, ta ánh xạ từng token tới một chỉ số tương ứng để xây dựng kho ngữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [392, 2115, 406], [5277, 3054, 1580]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [vocab[line] for line in subsampled]\n",
    "corpus[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.3. Nạp Dữ liệu\n",
    "Tiếp theo, ta đọc kho ngữ liệu với các chỉ số token thành các batch dữ liệu cho quá trình huấn luyện."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.3.1. Trích xuất từ Đích Trung tâm và Từ Ngữ cảnh\n",
    "Ta sử dụng các từ với khoảng cách tới từ đích trung tâm không quá độ dài cửa sổ ngữ cảnh để làm từ ngữ cảnh cho từ đích trung tâm đó. Hàm sau đây trích xuất tất cả từ đích trung tâm và các từ ngữ cảnh của chúng. Ta chọn kích thước cửa sổ ngữ cảnh là một số nguyên từ 1 tới `max_window_size` (kích thước cửa sổ tối đa), được lấy ngẫu nhiên theo phân phối đều."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def get_centers_and_contexts(corpus, max_window_size):\n",
    "    centers, contexts = [], []\n",
    "    for line in corpus:\n",
    "        # Each sentence needs at least 2 words to form a \"central target word\n",
    "        # - context word\" pair\n",
    "        if len(line) < 2:\n",
    "            continue\n",
    "        centers += line\n",
    "        for i in range(len(line)):  # Context window centered at i\n",
    "            window_size = random.randint(1, max_window_size)\n",
    "            indices = list(\n",
    "                range(max(0, i - window_size),\n",
    "                      min(len(line), i + 1 + window_size)))\n",
    "            # Exclude the central target word from the context words\n",
    "            indices.remove(i)\n",
    "            contexts.append([line[idx] for idx in indices])\n",
    "    return centers, contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kế tiếp, ta tạo một tập dữ liệu nhân tạo chứa hai câu có lần lượt 7 và 3 từ. Hãy giả sử cửa sổ ngữ cảnh cực đại là 2 và in tất cả các từ đích trung tâm và các từ ngữ cảnh của chúng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset [[0, 1, 2, 3, 4, 5, 6], [7, 8, 9]]\n",
      "center 0 has contexts [1]\n",
      "center 1 has contexts [0, 2, 3]\n",
      "center 2 has contexts [0, 1, 3, 4]\n",
      "center 3 has contexts [2, 4]\n",
      "center 4 has contexts [2, 3, 5, 6]\n",
      "center 5 has contexts [4, 6]\n",
      "center 6 has contexts [4, 5]\n",
      "center 7 has contexts [8]\n",
      "center 8 has contexts [7, 9]\n",
      "center 9 has contexts [8]\n"
     ]
    }
   ],
   "source": [
    "tiny_dataset = [list(range(7)), list(range(7, 10))]\n",
    "print('dataset', tiny_dataset)\n",
    "for center, context in zip(*get_centers_and_contexts(tiny_dataset, 2)):\n",
    "    print('center', center, 'has contexts', context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta thiết lập cửa sổ ngữ cảnh cực đại là 5. Đoạn mã sau trích xuất tất cả các từ đích trung tâm và các từ ngữ cảnh của chúng trong tập dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# center-context pairs: 353392'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_centers, all_contexts = get_centers_and_contexts(corpus, 5)\n",
    "f'# center-context pairs: {len(all_centers)}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.3.2. Lấy mẫu Âm\n",
    "Ta thực hiện lấy mẫu âm để huấn luyện gần đúng. Với mỗi cặp từ đích trung tâm và ngữ cảnh, ta lẫy mẫu ngẫu nhiên  $K$  từ nhiễu ( $K=5$  trong thử nghiệm này). Theo đề xuất trong bài báo Word2vec, xác suất lấy mẫu từ nhiễu  $P(w)$  là tỷ lệ giữa tần suất xuất hiện của từ  w  và tổng tần suất xuất hiện của tất cả các từ, lấy mũ 0.75 [2].\n",
    "\n",
    "Trước hết ta sẽ định nghĩa một lớp để lấy ra một ứng cử viên dựa theo các trọng số lấy mẫu. Lớp này sẽ lưu lại 10000 số ngẫu nhiên một lần thay vì gọi `random.choices` liên tục."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 0, 2, 2, 2, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@save\n",
    "class RandomGenerator:\n",
    "    \"\"\"Draw a random int in [0, n] according to n sampling weights.\"\"\"\n",
    "    def __init__(self, sampling_weights):\n",
    "        self.population = list(range(len(sampling_weights)))\n",
    "        self.sampling_weights = sampling_weights\n",
    "        self.candidates = []\n",
    "        self.i = 0\n",
    "\n",
    "    def draw(self):\n",
    "        if self.i == len(self.candidates):\n",
    "            self.candidates = random.choices(self.population,\n",
    "                                             self.sampling_weights, k=10000)\n",
    "            self.i = 0\n",
    "        self.i += 1\n",
    "        return self.candidates[self.i - 1]\n",
    "\n",
    "generator = RandomGenerator([2, 3, 4])\n",
    "[generator.draw() for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def get_negatives(all_contexts, corpus, K):\n",
    "    counter = d2l.count_corpus(corpus)\n",
    "    sampling_weights = [counter[i]**0.75 for i in range(len(counter))]\n",
    "    all_negatives, generator = [], RandomGenerator(sampling_weights)\n",
    "    for contexts in all_contexts:\n",
    "        negatives = []\n",
    "        while len(negatives) < len(contexts) * K:\n",
    "            neg = generator.draw()\n",
    "            # Noise words cannot be context words\n",
    "            if neg not in contexts:\n",
    "                negatives.append(neg)\n",
    "        all_negatives.append(negatives)\n",
    "    return all_negatives\n",
    "\n",
    "all_negatives = get_negatives(all_contexts, corpus, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.3.3. Đọc Dữ liệu thành Batch\n",
    "Chúng ta trích xuất tất cả các từ đích trung tâm `all_centers`, cũng như các từ ngữ cảnh `all_contexts` và những từ nhiễu của mỗi từ đích trung tâm trong tập dữ liệu, rồi đọc chúng thành các minibatch ngẫu nhiên.\n",
    "\n",
    "Trong một minibatch dữ liệu, mẫu thứ  $i$  bao gồm một từ đích trung tâm cùng  $n_i$  từ ngữ cảnh và  $m_i$  từ nhiễu tương ứng với từ đích trung tâm đó. Do kích thước cửa sổ ngữ cảnh của mỗi mẫu có thể khác nhau, nên tổng số từ ngữ cảnh và từ nhiễu,  $n_i+m_i$ , cũng sẽ khác nhau. Khi tạo một minibatch, chúng ta nối (**concatenate**) các từ ngữ cảnh và các từ nhiễu của mỗi mẫu, và đệm thêm các giá trị 0 để độ dài của các đoạn nối bằng nhau, tức bằng  $max_i.n_i+m_i$  (`max_len`). Nhằm tránh ảnh hưởng của phần đệm lên việc tính toán hàm mất mát, chúng ta tạo một biến mặt nạ `masks`, mỗi phần tử trong đó tương ứng với một phần tử trong phần nối giữa từ ngữ cảnh và từ nhiễu, `contexts_negatives`. Khi một phần tử trong biến `contexts_negatives` là đệm, thì phần tử trong biến mặt nạ `masks` ở vị trí đó sẽ là 0, còn lại là bằng 1. Để phân biệt giữa các mẫu dương và âm, chúng ta cũng cần phân biệt các từ ngữ cảnh với các từ nhiễu trong biến `contexts_negatives`. Dựa trên cấu tạo của biến mặt nạ, chúng ta chỉ cần tạo một biến nhãn `labels` có cùng kích thước với biến `contexts_negatives` và đặt giá trị các phần tử tương ứng với các từ ngữ cảnh (mẫu dương) bằng 1 và phần còn lại bằng 0.\n",
    "\n",
    "Tiếp đó, chúng ta lập trình chức năng đọc minibatch `batchify`, với đầu vào `minibatch` data là một danh sách có độ dài là kích thước batch, mỗi phần tử trong đó chứa các từ đích trung tâm `center`, các từ ngữ cảnh `context` và các từ nhiễu `negative`. Dữ liệu trong minibatch được trả về bởi hàm này đều tuân theo định dạng chúng ta cần, bao gồm biến mặt nạ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def batchify(data):\n",
    "    max_len = max(len(c) + len(n) for _, c, n in data)\n",
    "    centers, contexts_negatives, masks, labels = [], [], [], []\n",
    "    for center, context, negative in data:\n",
    "        cur_len = len(context) + len(negative)\n",
    "        centers += [center]\n",
    "        contexts_negatives += [context + negative + [0] * (max_len - cur_len)]\n",
    "        masks += [[1] * cur_len + [0] * (max_len - cur_len)]\n",
    "        labels += [[1] * len(context) + [0] * (max_len - len(context))]\n",
    "    return (torch.tensor(centers).reshape(\n",
    "        (-1, 1)), torch.tensor(contexts_negatives), torch.tensor(masks),\n",
    "            torch.tensor(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tạo hai ví dụ mẫu đơn giản:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centers = tensor([[1],\n",
      "        [1]])\n",
      "contexts_negatives = tensor([[2, 2, 3, 3, 3, 3],\n",
      "        [2, 2, 2, 3, 3, 0]])\n",
      "masks = tensor([[1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0]])\n",
      "labels = tensor([[1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x_1 = (1, [2, 2], [3, 3, 3, 3])\n",
    "x_2 = (1, [2, 2, 2], [3, 3])\n",
    "batch = batchify((x_1, x_2))\n",
    "\n",
    "names = ['centers', 'contexts_negatives', 'masks', 'labels']\n",
    "for name, data in zip(names, batch):\n",
    "    print(name, '=', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta dùng hàm `batchify` vừa được định nghĩa để chỉ định phương thức đọc minibatch trong thực thể `DataLoader`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.4. Kết hợp mọi thứ cùng nhau\n",
    "Cuối cùng, chúng ta định nghĩa hàm `load_data_ptb` để đọc tập dữ liệu PTB và trả về iterator dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def load_data_ptb(batch_size, max_window_size, num_noise_words):\n",
    "    num_workers = d2l.get_dataloader_workers()\n",
    "    sentences = read_ptb()\n",
    "    vocab = d2l.Vocab(sentences, min_freq=10)\n",
    "    subsampled = subsampling(sentences, vocab)\n",
    "    corpus = [vocab[line] for line in subsampled]\n",
    "    all_centers, all_contexts = get_centers_and_contexts(\n",
    "        corpus, max_window_size)\n",
    "    all_negatives = get_negatives(all_contexts, corpus, num_noise_words)\n",
    "\n",
    "    class PTBDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, centers, contexts, negatives):\n",
    "            assert len(centers) == len(contexts) == len(negatives)\n",
    "            self.centers = centers\n",
    "            self.contexts = contexts\n",
    "            self.negatives = negatives\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            return (self.centers[index], self.contexts[index],\n",
    "                    self.negatives[index])\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.centers)\n",
    "\n",
    "    dataset = PTBDataset(all_centers, all_contexts, all_negatives)\n",
    "\n",
    "    data_iter = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True,\n",
    "                                            collate_fn=batchify,\n",
    "                                            num_workers=num_workers)\n",
    "    return data_iter, vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta hãy cùng in ra minibatch đầu tiên trong iterator dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'load_data_ptb.<locals>.PTBDataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-2edcdd1a4bc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data_ptb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'load_data_ptb.<locals>.PTBDataset'"
     ]
    }
   ],
   "source": [
    "data_iter, vocab = load_data_ptb(512, 5, 5)\n",
    "for batch in data_iter:\n",
    "    for name, data in zip(names, batch):\n",
    "        print(name, 'shape:', data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.5. Tóm tắt\n",
    "- Việc lấy mẫu con cố gắng giảm thiểu tác động của các từ có tần suất cao đến việc huấn luyện mô hình embedding từ.\n",
    "- Ta có thể đệm để tạo ra các minibatch với các mẫu có cùng độ dài và sử dụng các biến mặt nạ để phân biệt phần tử đệm, vì thế chỉ có những phần tử không phải đệm mới được dùng để tính toán hàm mất mát."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3.6. Bài tập\n",
    "Chúng ta sử dụng hàm `batchify` để chỉ định phương thức đọc minibatch trong thực thể DataLoader và in ra kích thước của từng biến trong lần đọc batch đầu tiên. Những kích thước này được tính toán như thế nào?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.4. Tiền huấn luyện word2vec\n",
    "Trong phần này, ta sẽ huấn luyện một mô hình skip-gram đã được định nghĩa ở Section 14.1.\n",
    "\n",
    "Đầu tiên, ta nhập các gói thư viện và mô-đun cần thiết cho thí nghiệm, và nạp tập dữ liệu PTB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size, max_window_size, num_noise_words = 512, 5, 5\n",
    "data_iter, vocab = d2l.load_data_ptb(batch_size, max_window_size,\n",
    "                                     num_noise_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.1. Mô hình Skip-Gram\n",
    "Ta sẽ lập trình mô hình skip-gram bằng cách sử dụng các tầng embedding và phép nhân minibatch. Các phương pháp này cũng thường được sử dụng để lập trình các ứng dụng xử lý ngôn ngữ tự nhiên khác."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.1.1. Tầng Embedding¶\n",
    "Để thu được các embedding từ, ta sử dụng tầng embedding, có thể được tạo bằng một thực thể `nn.Embedding` trong Pytorch. Trọng số của tầng embedding là một ma trận có số hàng là kích thước từ điển (`input_dim`) và số cột là chiều của mỗi vector từ (`output_dim`). Ta đặt kích thước từ điển bằng  $20$  và chiều vector từ là  $4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter embedding_weight (torch.Size([20, 4]), dtype={embed.weight.dtype})\n"
     ]
    }
   ],
   "source": [
    "embed = nn.Embedding(num_embeddings=20, embedding_dim=4)\n",
    "print(f'Parameter embedding_weight ({embed.weight.shape}, '\n",
    "      'dtype={embed.weight.dtype})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đầu vào của tầng embedding là chỉ số của từ. Khi ta nhập vào chỉ số  $i$  của một từ, tầng embedding sẽ trả về vector từ tương ứng là hàng thứ  $i$  của ma trận trọng số. Dưới đây ta nhập vào tầng embedding một chỉ số có kích thước $( 2 ,  3 )$. Vì số chiều vector từ là $4$, ta thu được vector từ kích thước $( 2 ,  3 ,  4 )$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1328, -0.4076, -0.0805, -0.4821],\n",
       "         [ 0.8895,  0.6707, -0.0850,  1.1877],\n",
       "         [-1.2939, -0.0885,  0.3774, -0.0920]],\n",
       "\n",
       "        [[-0.2017, -1.1258,  0.3291, -0.4042],\n",
       "         [ 1.6923, -0.6008,  0.0964, -0.1461],\n",
       "         [ 0.0089,  1.8888, -0.3055, -0.9023]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "embed(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.1.2. Phép nhân Minibatch\n",
    "Ta có thể nhân các ma trận trong hai minibatch bằng toán tử nhân minibatch `batch_dot`. Giả sử batch đầu tiên chứa  $n$  ma trận  $X_1,…,X_n$  có kích thước là  $a×b$ , và batch thứ hai chứa  $n$  ma trận  $Y_1,…,Y_n$  có kích thước là  $b×c$ . Đầu ra của toán tử nhân ma trận trên hai batch đầu vào là  $n$  ma trận  $X_1Y_1,…,X_nY_n$  có kích thước là  $a×c$ .\n",
    "Do đó, với hai tensor có kích thước là $( n ,  a ,  b )$ và $( n ,  b ,  c )$, kích thước đầu ra của toán tử nhân minibatch là $( n ,  a ,  c )$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.1.3. Tính toán Truyền xuôi của Mô hình Skip-Gram\n",
    "Ở lượt truyền xuôi, đầu vào của mô hình skip-gram chứa chỉ số `center` của từ đích trung tâm và chỉ số `contexts_and_negatives` được nối lại từ chỉ số của từ ngữ cảnh và từ nhiễu. Trong đó, biến `center` có kích thước là (kích thước batch, 1), và biến `contexts_and_negatives` có kích thước là (kích thước batch, `max_len`). Đầu tiên hai biến này được biến đổi từ chỉ số từ thành vector từ bởi tầng embedding từ, sau đó đầu ra có kích thước là (kích thước batch, 1, `max_len`) thu được bằng phép nhân minibatch. Mỗi phần tử của đầu ra là tích vô hướng của vector từ đích trung tâm và vector từ ngữ cảnh hoặc vector từ nhiễu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_gram(center, contexts_and_negatives, embed_v, embed_u):\n",
    "    v = embed_v(center)\n",
    "    u = embed_u(contexts_and_negatives)\n",
    "    pred = torch.bmm(v, u.permute(0, 2, 1))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy xác nhận kích thước đầu ra là (kích thước batch, 1, max_len)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_gram(torch.ones((2, 1), dtype=torch.long),\n",
    "          torch.ones((2, 4), dtype=torch.long), embed, embed).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.2. Huấn luyện\n",
    "Trước khi huấn luyện mô hình embedding từ, ta cần định nghĩa hàm mất mát của mô hình."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.2.1. Hàm Mất mát Entropy chéo Nhị phân\n",
    "Theo định nghĩa hàm mất mát trong phương pháp lấy mẫu âm, ta có thể sử dụng trực tiếp hàm mất mát entropy chéo nhị phân của Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidBCELoss(nn.Module):\n",
    "    \"BCEWithLogitLoss with masking on call.\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, inputs, target, mask=None):\n",
    "        out = nn.functional.binary_cross_entropy_with_logits(\n",
    "            inputs, target, weight=mask, reduction=\"none\")\n",
    "        return out.mean(dim=1)\n",
    "\n",
    "loss = SigmoidBCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lưu ý là ta có thể sử dụng biến mặt nạ để chỉ định một phần giá trị dự đoán và nhãn được dùng khi tính hàm mất mát trong minibatch: khi mặt nạ bằng 1, giá trị dự đoán và nhãn của vị trí tương ứng sẽ được dùng trong phép tính hàm mất mát; khi mặt nạ bằng 0, giá trị dự đoán và nhãn của vị trí tương ứng sẽ không được dùng trong phép tính hàm mất mát. Như đã đề cập, các biến mặt nạ có thể được sử dụng nhằm tránh ảnh hưởng của vùng đệm lên phép tính hàm mất mát.\n",
    "\n",
    "Với hai mẫu giống nhau, mặt nạ khác nhau sẽ dẫn đến giá trị mất mát cũng khác nhau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7241, 0.3620])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.tensor([[.5] * 4] * 2)\n",
    "label = torch.tensor([[1., 0., 1., 0.]] * 2)\n",
    "mask = torch.tensor([[1, 1, 1, 1], [1, 1, 0, 0]])\n",
    "loss(pred, label, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể chuẩn hóa mất mát trong từng mẫu do các mẫu có độ dài khác nhau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7241, 0.7241])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(pred, label, mask) / mask.sum(axis=1) * mask.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.2.2. Khởi tạo Tham số Mô hình\n",
    "Ta khai báo tầng embedding lần lượt của từ trung tâm và từ ngữ cảnh, và đặt siêu tham số số chiều của vector từ `embed_size` bằng 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100\n",
    "net = nn.Sequential(\n",
    "    nn.Embedding(num_embeddings=len(vocab), embedding_dim=embed_size),\n",
    "    nn.Embedding(num_embeddings=len(vocab), embedding_dim=embed_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.2.3. Huấn luyện\n",
    "Hàm huấn luyện được định nghĩa như dưới đây. Do có phần đệm nên phép tính mất mát có một chút khác biệt so với các hàm huấn luyện trước."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, data_iter, lr, num_epochs, device=d2l.try_gpu()):\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Embedding:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    net.apply(init_weights)\n",
    "    net = net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
    "                            xlim=[1, num_epochs])\n",
    "    metric = d2l.Accumulator(2)  # Sum of losses, no. of tokens\n",
    "    for epoch in range(num_epochs):\n",
    "        timer, num_batches = d2l.Timer(), len(data_iter)\n",
    "        for i, batch in enumerate(data_iter):\n",
    "            optimizer.zero_grad()\n",
    "            center, context_negative, mask, label = [\n",
    "                data.to(device) for data in batch]\n",
    "\n",
    "            pred = skip_gram(center, context_negative, net[0], net[1])\n",
    "            l = (\n",
    "                loss(pred.reshape(label.shape).float(), label.float(), mask) /\n",
    "                mask.sum(axis=1) * mask.shape[1])\n",
    "            l.sum().backward()\n",
    "            optimizer.step()\n",
    "            metric.add(l.sum(), l.numel())\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                             (metric[0] / metric[1],))\n",
    "    print(f'loss {metric[0] / metric[1]:.3f}, '\n",
    "          f'{metric[1] / timer.stop():.1f} tokens/sec on {str(device)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giờ ta có thể huấn luyện một mô hình skip-gram sử dụng phương pháp lấy mẫu âm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'load_data_ptb.<locals>.PTBDataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c04f85570b58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-140bef926834>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net, data_iter, lr, num_epochs, device)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtimer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             center, context_negative, mask, label = [\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'load_data_ptb.<locals>.PTBDataset'"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n",
       "<svg height=\"170.777344pt\" version=\"1.1\" viewBox=\"0 0 240.554688 170.777344\" width=\"240.554688pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       " <metadata>\r\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n",
       "   <cc:Work>\r\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n",
       "    <dc:date>2021-05-07T20:16:22.623508</dc:date>\r\n",
       "    <dc:format>image/svg+xml</dc:format>\r\n",
       "    <dc:creator>\r\n",
       "     <cc:Agent>\r\n",
       "      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n",
       "     </cc:Agent>\r\n",
       "    </dc:creator>\r\n",
       "   </cc:Work>\r\n",
       "  </rdf:RDF>\r\n",
       " </metadata>\r\n",
       " <defs>\r\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n",
       " </defs>\r\n",
       " <g id=\"figure_1\">\r\n",
       "  <g id=\"patch_1\">\r\n",
       "   <path d=\"M 0 170.777344 \r\n",
       "L 240.554688 170.777344 \r\n",
       "L 240.554688 0 \r\n",
       "L 0 0 \r\n",
       "z\r\n",
       "\" style=\"fill:none;\"/>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_1\">\r\n",
       "   <g id=\"patch_2\">\r\n",
       "    <path d=\"M 30.103125 146.899219 \r\n",
       "L 225.403125 146.899219 \r\n",
       "L 225.403125 10.999219 \r\n",
       "L 30.103125 10.999219 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_1\">\r\n",
       "    <g id=\"xtick_1\">\r\n",
       "     <g id=\"line2d_1\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 0 3.5 \r\n",
       "\" id=\"m8d41bd56c9\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m8d41bd56c9\" y=\"146.899219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_1\">\r\n",
       "      <!-- 0.0 -->\r\n",
       "      <g transform=\"translate(22.151563 161.497656)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 31.78125 66.40625 \r\n",
       "Q 24.171875 66.40625 20.328125 58.90625 \r\n",
       "Q 16.5 51.421875 16.5 36.375 \r\n",
       "Q 16.5 21.390625 20.328125 13.890625 \r\n",
       "Q 24.171875 6.390625 31.78125 6.390625 \r\n",
       "Q 39.453125 6.390625 43.28125 13.890625 \r\n",
       "Q 47.125 21.390625 47.125 36.375 \r\n",
       "Q 47.125 51.421875 43.28125 58.90625 \r\n",
       "Q 39.453125 66.40625 31.78125 66.40625 \r\n",
       "z\r\n",
       "M 31.78125 74.21875 \r\n",
       "Q 44.046875 74.21875 50.515625 64.515625 \r\n",
       "Q 56.984375 54.828125 56.984375 36.375 \r\n",
       "Q 56.984375 17.96875 50.515625 8.265625 \r\n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \r\n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \r\n",
       "Q 6.59375 17.96875 6.59375 36.375 \r\n",
       "Q 6.59375 54.828125 13.0625 64.515625 \r\n",
       "Q 19.53125 74.21875 31.78125 74.21875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-48\"/>\r\n",
       "        <path d=\"M 10.6875 12.40625 \r\n",
       "L 21 12.40625 \r\n",
       "L 21 0 \r\n",
       "L 10.6875 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-46\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_2\">\r\n",
       "     <g id=\"line2d_2\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.163125\" xlink:href=\"#m8d41bd56c9\" y=\"146.899219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_2\">\r\n",
       "      <!-- 0.2 -->\r\n",
       "      <g transform=\"translate(61.211563 161.497656)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 19.1875 8.296875 \r\n",
       "L 53.609375 8.296875 \r\n",
       "L 53.609375 0 \r\n",
       "L 7.328125 0 \r\n",
       "L 7.328125 8.296875 \r\n",
       "Q 12.9375 14.109375 22.625 23.890625 \r\n",
       "Q 32.328125 33.6875 34.8125 36.53125 \r\n",
       "Q 39.546875 41.84375 41.421875 45.53125 \r\n",
       "Q 43.3125 49.21875 43.3125 52.78125 \r\n",
       "Q 43.3125 58.59375 39.234375 62.25 \r\n",
       "Q 35.15625 65.921875 28.609375 65.921875 \r\n",
       "Q 23.96875 65.921875 18.8125 64.3125 \r\n",
       "Q 13.671875 62.703125 7.8125 59.421875 \r\n",
       "L 7.8125 69.390625 \r\n",
       "Q 13.765625 71.78125 18.9375 73 \r\n",
       "Q 24.125 74.21875 28.421875 74.21875 \r\n",
       "Q 39.75 74.21875 46.484375 68.546875 \r\n",
       "Q 53.21875 62.890625 53.21875 53.421875 \r\n",
       "Q 53.21875 48.921875 51.53125 44.890625 \r\n",
       "Q 49.859375 40.875 45.40625 35.40625 \r\n",
       "Q 44.1875 33.984375 37.640625 27.21875 \r\n",
       "Q 31.109375 20.453125 19.1875 8.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-50\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_3\">\r\n",
       "     <g id=\"line2d_3\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.223125\" xlink:href=\"#m8d41bd56c9\" y=\"146.899219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_3\">\r\n",
       "      <!-- 0.4 -->\r\n",
       "      <g transform=\"translate(100.271563 161.497656)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 37.796875 64.3125 \r\n",
       "L 12.890625 25.390625 \r\n",
       "L 37.796875 25.390625 \r\n",
       "z\r\n",
       "M 35.203125 72.90625 \r\n",
       "L 47.609375 72.90625 \r\n",
       "L 47.609375 25.390625 \r\n",
       "L 58.015625 25.390625 \r\n",
       "L 58.015625 17.1875 \r\n",
       "L 47.609375 17.1875 \r\n",
       "L 47.609375 0 \r\n",
       "L 37.796875 0 \r\n",
       "L 37.796875 17.1875 \r\n",
       "L 4.890625 17.1875 \r\n",
       "L 4.890625 26.703125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-52\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_4\">\r\n",
       "     <g id=\"line2d_4\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.283125\" xlink:href=\"#m8d41bd56c9\" y=\"146.899219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_4\">\r\n",
       "      <!-- 0.6 -->\r\n",
       "      <g transform=\"translate(139.331563 161.497656)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 33.015625 40.375 \r\n",
       "Q 26.375 40.375 22.484375 35.828125 \r\n",
       "Q 18.609375 31.296875 18.609375 23.390625 \r\n",
       "Q 18.609375 15.53125 22.484375 10.953125 \r\n",
       "Q 26.375 6.390625 33.015625 6.390625 \r\n",
       "Q 39.65625 6.390625 43.53125 10.953125 \r\n",
       "Q 47.40625 15.53125 47.40625 23.390625 \r\n",
       "Q 47.40625 31.296875 43.53125 35.828125 \r\n",
       "Q 39.65625 40.375 33.015625 40.375 \r\n",
       "z\r\n",
       "M 52.59375 71.296875 \r\n",
       "L 52.59375 62.3125 \r\n",
       "Q 48.875 64.0625 45.09375 64.984375 \r\n",
       "Q 41.3125 65.921875 37.59375 65.921875 \r\n",
       "Q 27.828125 65.921875 22.671875 59.328125 \r\n",
       "Q 17.53125 52.734375 16.796875 39.40625 \r\n",
       "Q 19.671875 43.65625 24.015625 45.921875 \r\n",
       "Q 28.375 48.1875 33.59375 48.1875 \r\n",
       "Q 44.578125 48.1875 50.953125 41.515625 \r\n",
       "Q 57.328125 34.859375 57.328125 23.390625 \r\n",
       "Q 57.328125 12.15625 50.6875 5.359375 \r\n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \r\n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \r\n",
       "Q 6.984375 17.96875 6.984375 36.375 \r\n",
       "Q 6.984375 53.65625 15.1875 63.9375 \r\n",
       "Q 23.390625 74.21875 37.203125 74.21875 \r\n",
       "Q 40.921875 74.21875 44.703125 73.484375 \r\n",
       "Q 48.484375 72.75 52.59375 71.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-54\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_5\">\r\n",
       "     <g id=\"line2d_5\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.343125\" xlink:href=\"#m8d41bd56c9\" y=\"146.899219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_5\">\r\n",
       "      <!-- 0.8 -->\r\n",
       "      <g transform=\"translate(178.391563 161.497656)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 31.78125 34.625 \r\n",
       "Q 24.75 34.625 20.71875 30.859375 \r\n",
       "Q 16.703125 27.09375 16.703125 20.515625 \r\n",
       "Q 16.703125 13.921875 20.71875 10.15625 \r\n",
       "Q 24.75 6.390625 31.78125 6.390625 \r\n",
       "Q 38.8125 6.390625 42.859375 10.171875 \r\n",
       "Q 46.921875 13.96875 46.921875 20.515625 \r\n",
       "Q 46.921875 27.09375 42.890625 30.859375 \r\n",
       "Q 38.875 34.625 31.78125 34.625 \r\n",
       "z\r\n",
       "M 21.921875 38.8125 \r\n",
       "Q 15.578125 40.375 12.03125 44.71875 \r\n",
       "Q 8.5 49.078125 8.5 55.328125 \r\n",
       "Q 8.5 64.0625 14.71875 69.140625 \r\n",
       "Q 20.953125 74.21875 31.78125 74.21875 \r\n",
       "Q 42.671875 74.21875 48.875 69.140625 \r\n",
       "Q 55.078125 64.0625 55.078125 55.328125 \r\n",
       "Q 55.078125 49.078125 51.53125 44.71875 \r\n",
       "Q 48 40.375 41.703125 38.8125 \r\n",
       "Q 48.828125 37.15625 52.796875 32.3125 \r\n",
       "Q 56.78125 27.484375 56.78125 20.515625 \r\n",
       "Q 56.78125 9.90625 50.3125 4.234375 \r\n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \r\n",
       "Q 19.734375 -1.421875 13.25 4.234375 \r\n",
       "Q 6.78125 9.90625 6.78125 20.515625 \r\n",
       "Q 6.78125 27.484375 10.78125 32.3125 \r\n",
       "Q 14.796875 37.15625 21.921875 38.8125 \r\n",
       "z\r\n",
       "M 18.3125 54.390625 \r\n",
       "Q 18.3125 48.734375 21.84375 45.5625 \r\n",
       "Q 25.390625 42.390625 31.78125 42.390625 \r\n",
       "Q 38.140625 42.390625 41.71875 45.5625 \r\n",
       "Q 45.3125 48.734375 45.3125 54.390625 \r\n",
       "Q 45.3125 60.0625 41.71875 63.234375 \r\n",
       "Q 38.140625 66.40625 31.78125 66.40625 \r\n",
       "Q 25.390625 66.40625 21.84375 63.234375 \r\n",
       "Q 18.3125 60.0625 18.3125 54.390625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-56\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_6\">\r\n",
       "     <g id=\"line2d_6\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"225.403125\" xlink:href=\"#m8d41bd56c9\" y=\"146.899219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_6\">\r\n",
       "      <!-- 1.0 -->\r\n",
       "      <g transform=\"translate(217.451563 161.497656)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 12.40625 8.296875 \r\n",
       "L 28.515625 8.296875 \r\n",
       "L 28.515625 63.921875 \r\n",
       "L 10.984375 60.40625 \r\n",
       "L 10.984375 69.390625 \r\n",
       "L 28.421875 72.90625 \r\n",
       "L 38.28125 72.90625 \r\n",
       "L 38.28125 8.296875 \r\n",
       "L 54.390625 8.296875 \r\n",
       "L 54.390625 0 \r\n",
       "L 12.40625 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-49\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_2\">\r\n",
       "    <g id=\"ytick_1\">\r\n",
       "     <g id=\"line2d_7\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L -3.5 0 \r\n",
       "\" id=\"m0e28497e4c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0e28497e4c\" y=\"146.899219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_7\">\r\n",
       "      <!-- 0.0 -->\r\n",
       "      <g transform=\"translate(7.2 150.698437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_2\">\r\n",
       "     <g id=\"line2d_8\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0e28497e4c\" y=\"119.719219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_8\">\r\n",
       "      <!-- 0.2 -->\r\n",
       "      <g transform=\"translate(7.2 123.518437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_3\">\r\n",
       "     <g id=\"line2d_9\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0e28497e4c\" y=\"92.539219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_9\">\r\n",
       "      <!-- 0.4 -->\r\n",
       "      <g transform=\"translate(7.2 96.338437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_4\">\r\n",
       "     <g id=\"line2d_10\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0e28497e4c\" y=\"65.359219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_10\">\r\n",
       "      <!-- 0.6 -->\r\n",
       "      <g transform=\"translate(7.2 69.158437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_5\">\r\n",
       "     <g id=\"line2d_11\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0e28497e4c\" y=\"38.179219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_11\">\r\n",
       "      <!-- 0.8 -->\r\n",
       "      <g transform=\"translate(7.2 41.978437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_6\">\r\n",
       "     <g id=\"line2d_12\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m0e28497e4c\" y=\"10.999219\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_12\">\r\n",
       "      <!-- 1.0 -->\r\n",
       "      <g transform=\"translate(7.2 14.798437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n",
       "       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_3\">\r\n",
       "    <path d=\"M 30.103125 146.899219 \r\n",
       "L 30.103125 10.999219 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_4\">\r\n",
       "    <path d=\"M 225.403125 146.899219 \r\n",
       "L 225.403125 10.999219 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_5\">\r\n",
       "    <path d=\"M 30.103125 146.899219 \r\n",
       "L 225.403125 146.899219 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_6\">\r\n",
       "    <path d=\"M 30.103125 10.999219 \r\n",
       "L 225.403125 10.999219 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       " </g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 5\n",
    "train(net, data_iter, lr, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.3. Áp dụng Mô hình Embedding Từ\n",
    "Sau khi huấn luyện mô hình embedding từ, ta có thể biểu diễn sự tương tự về nghĩa giữa các từ dựa trên độ tương tự cô-sin giữa hai vector từ. Có thể thấy, khi sử dụng mô hình embedding từ đã được huấn luyện, các từ có nghĩa gần nhất với từ “chip” hầu hết là những từ có liên quan đến chip xử lý."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_tokens(query_token, k, embed):\n",
    "    W = embed.weight.data\n",
    "    x = W[vocab[query_token]]\n",
    "    # Compute the cosine similarity. Add 1e-9 for numerical stability\n",
    "    cos = torch.mv(\n",
    "        W, x) / torch.sqrt(torch.sum(W * W, dim=1) * torch.sum(x * x) + 1e-9)\n",
    "    topk = torch.topk(cos, k=k + 1)[1].cpu().numpy().astype('int32')\n",
    "    for i in topk[1:]:  # Remove the input words\n",
    "        print(f'cosine sim={float(cos[i]):.3f}: {vocab.idx_to_token[i]}')\n",
    "\n",
    "get_similar_tokens('chip', 3, net[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.4. Tóm tắt\n",
    "Ta có thể tiền huấn luyện một mô hình skip-gram thông qua phương pháp lấy mẫu âm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.4.5. Bài tập\n",
    "1. Đặt sparse_grad=True khi tạo một đối tượng nn.Embedding. Việc này có tăng tốc quá trình huấn luyện không? Hãy tra tài liệu của MXNet để tìm hiểu ý nghĩa của tham số này.\n",
    "2. Hãy tìm từ đồng nghĩa cho các từ khác.\n",
    "3. Điều chỉnh các siêu tham số, quan sát và phân tích kết quả thí nghiệm.\n",
    "4. Khi tập dữ liệu lớn, ta thường lấy mẫu các từ ngữ cảnh và các từ nhiễu cho từ đích trung tâm trong minibatch hiện tại chỉ khi cập nhật tham số mô hình. Nói cách khác, cùng một từ đích trung tâm có thể có các từ ngữ cảnh và từ nhiễu khác nhau với mỗi epoch khác nhau. Cách huấn luyện này có lợi ích gì? Hãy thử lập trình phương pháp huấn luyện này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.5. Embedding từ với Vector Toàn cục (GloVe)\n",
    "Trước tiên, ta sẽ xem lại mô hình skip-gram trong word2vec. Xác suất có điều kiện  $P(w_j\\mid w_i)$  được biểu diễn trong mô hình skip-gram bằng hàm kích hoạt softmax sẽ được gọi là  $q_{ij}$  như sau:\n",
    "\n",
    "<center>$q_{ij}=\\frac{\\exp(\\mathbf{u}_j^\\top \\mathbf{v}_i)}{ \\sum_{k \\in \\mathcal{V}} \\text{exp}(\\mathbf{u}_k^\\top \\mathbf{v}_i)},$</center>\n",
    " \n",
    "Ở đây  $v_i$  và  $u_i$  là các biểu diễn vector từ  $w_i$  với chỉ số  $i$ , lần lượt khi nó là từ trung tâm và từ ngữ cảnh, và  $\\mathcal{V} = \\{0, 1, \\ldots, |\\mathcal{V}|-1\\}$  là tập chứa các chỉ số của bộ từ vựng.\n",
    "\n",
    "Từ  $w_i$  có thể xuất hiện trong tập dữ liệu nhiều lần. Ta gom tất cả các từ ngữ cảnh mỗi khi  wi  là từ trung tâm và giữ các lần trùng lặp, rồi ký hiệu đó là tập bội  $\\mathcal{C}_i$ . Số lượng của một phần tử trong tập bội được gọi là bội số của phần tử đó. Chẳng hạn, giả sử rằng từ  $w_i$  xuất hiện hai lần trong tập dữ liệu: khi hai từ  wi  đó là từ trung tâm trong chuỗi văn bản, hai cửa sổ ngữ cảnh tương ứng chứa các chỉ số từ ngữ cảnh  $2,1,5,2$  và  $2,3,2,1$ . Khi đó, ta sẽ có tập bội  $\\mathcal{C}_i = \\{1, 1, 2, 2, 2, 2, 3, 5\\}$ , trong đó bội số của phần tử 1 là 2, bội số của phần tử 2 là 4, và bội số của phần tử 3 và 5 đều là 1. Ta ký hiệu bội số của phần tử  $j$  trong tập bội  $\\mathcal{C}_i$  là  $x_{ij}$ : nó là số lần từ  $w_j$  xuất hiện trong cửa sổ ngữ cảnh khi từ trung tâm là  $w_j$  trong toàn bộ tập dữ liệu. Kết quả là hàm mất mát của mô hình skip-gram có thể được biểu diễn theo một cách khác:\n",
    "\n",
    "<center>$-\\sum_{i\\in\\mathcal{V}}\\sum_{j\\in\\mathcal{V}} x_{ij} \\log\\,q_{ij}.$</center>\n",
    " \n",
    "Ta tính tổng số lượng tất cả các từ ngữ cảnh đối với từ trung tâm  wi  để có  $x_i$ , rồi thu được xác suất có điều kiện để sinh ra từ ngữ cảnh  $w_j$  dựa trên từ trung tâm  wi  là  pij  bằng  $x_{ij}/x_i$ . Ta có thể viết lại hàm mất mất của mô hình skip-gram như sau\n",
    "\n",
    "<center>$-\\sum_{i\\in\\mathcal{V}} x_i \\sum_{j\\in\\mathcal{V}} p_{ij} \\log\\,q_{ij}.$</center>\n",
    " \n",
    "Trong công thức trên,  $\\sum_{j\\in\\mathcal{V}} p_{ij} \\log\\,q_{ij}$  tính toán phân phối xác suất có điều kiện  $p_{ij}$  của việc sinh từ ngữ cảnh dựa trên từ đích trung tâm  wi  và entropy chéo với phân phối xác suất có điều kiện  qij  được dự đoán bởi mô hình. Hàm mất mát được đánh trọng số bằng cách sử dụng tổng số từ ngữ cảnh cho từ đích trung tâm  $w_i$ . Việc cực tiểu hóa hàm mất mát theo công thức trên cho phép phân phối xác suất có điều kiện được dự đoán một cách gần nhất có thể tới phân phối xác suất có điều kiện thật sự.\n",
    "\n",
    "Tuy nhiên, mặc dù là hàm mất mát phổ biến nhất, đôi khi hàm mất mát entropy chéo lại không phải là một lựa chọn phù hợp. Một mặt, như ta đã đề cập trong Section 14.2, chi phí để mô hình đưa ra dự đoán  $q_{ij}$  trở thành phân phối xác suất hợp lệ gồm phép lấy tổng qua toàn bộ các từ trong từ điển ở mẫu số của nó. Điều này có thể dễ dàng khiến tổng chi phí tính toán trở nên quá lớn. Mặt khác, thường sẽ có rất nhiều từ hiếm gặp trong từ điển, và chúng ít khi xuất hiện trong tập dữ liệu. Trong hàm mất mát entropy chéo, dự đoán cuối cùng cho phân phối xác suất có điều kiện trên một lượng lớn các từ hiếm gặp rất có thể sẽ không được chính xác."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.5.1. Mô hình GloVe\n",
    "Để giải quyết vấn đề trên, GloVe [Pennington et al., 2014], một mô hình embedding từ xuất hiện sau word2vec đã áp dụng mất mát bình phương và đề xuất ba thay đổi trong mô hình skip-gram dựa theo mất mát này.\n",
    "\n",
    "1. Ở đây, ta sử dụng các biến phân phối phi xác suất  $p'_{ij}=x_{ij}$ và  $q'_{ij}=\\exp(\\mathbf{u}_j^\\top \\mathbf{v}_i)$  rồi tính log của chúng. Do đó, ta có mất mát bình phương $\\left(\\log\\,p'_{ij} - \\log\\,q'_{ij}\\right)^2 = \\left(\\mathbf{u}_j^\\top \\mathbf{v}_i - \\log\\,x_{ij}\\right)^2$ .\n",
    "2. Ta thêm hai tham số mô hình cho mỗi từ  wi : hệ số điều chỉnh  $b_i$  (cho các từ trung tâm) và  $c_i$  (cho các từ ngữ cảnh).\n",
    "3. Thay thế trọng số của mỗi giá trị mất mát bằng hàm  $h(x_{ij})$ . Hàm trọng số  $h(x)$  là hàm đơn điệu tăng trong khoảng  [0,1] .\n",
    "\n",
    "Do đó, mục tiêu của GloVe là cực tiểu hóa hàm mất mát.\n",
    "\n",
    "<center>$\\sum_{i\\in\\mathcal{V}} \\sum_{j\\in\\mathcal{V}} h(x_{ij}) \\left(\\mathbf{u}_j^\\top \\mathbf{v}_i + b_i + c_j - \\log\\,x_{ij}\\right)^2.$</center>\n",
    " \n",
    "Ở đây, chúng tôi có một đề xuất đối với việc lựa chọn hàm trọng số  $h(x)$ : khi  $x<c$  (ví dụ  $c=100$ ) thì  $h(x)=(x/c)^α$  (ví dụ  $α=0.75$ ), nếu không thì  $h(x)=1$ . Do  $h(0)=0$ , ta có thể đơn thuần bỏ qua mất mát bình phương tại  xij=0 . Khi sử dụng minibatch SGD trong quá trình huấn luyện, ta tiến hành lấy mẫu ngẫu nhiên để được một minibatch  $x_{ij}$  khác không tại mỗi bước thời gian và tính toán gradient để cập nhật các tham số mô hình. Các giá trị  $x_{ij}$  khác không trên được tính trước trên toàn bộ tập dữ liệu và là thống kê toàn cục của tập dữ liệu. Do đó, tên gọi GloVe được lấy từ “Global Vectors (Vector Toàn cục)”.\n",
    "\n",
    "Chú ý rằng nếu từ  $w_i$  xuất hiện trong cửa sổ ngữ cảnh của từ  $w_j$  thì từ  $w_j$  cũng sẽ xuất hiện trong cửa sổ ngữ cảnh của từ  wi . Do đó,  $x_{ij}=x_{ji}$ . Không như word2vec, GloVe khớp  $\\log\\, x_{ij}$  đối xứng thay vì xác suất có điều kiện  $p_{ij}$  bất đối xứng. Do đó, vector từ đích trung tâm và vector từ ngữ cảnh của bất kì từ nào đều tương đương nhau trong GloVe. Tuy vậy, hai tập vector từ được học bởi cùng một mô hình về cuối có thể sẽ khác nhau do giá trị khởi tạo khác nhau. Sau khi học tất cả các vector từ, GloVe sẽ sử dụng tổng của vector từ đích trung tâm và vector từ ngữ cảnh để làm vector từ cuối cùng cho từ đó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.5.2. Lý giải GloVe bằng Tỷ số Xác suất Có điều kiện\n",
    "Ta cũng có thể cố gắng lý giải embedding từ GloVe theo một cách nhìn khác. Ta sẽ tiếp tục sử dụng các ký hiệu như ở trên,  $P(w_j \\mid w_i)$  biểu diễn xác suất có điều kiện sinh từ ngữ cảnh  $w_j$  với từ tâm đích  $w_i$  trong tập dữ liệu, và xác suất này được ghi lại bằng  $p_{ij}$ . Xét ví dụ thực tế từ một kho ngữ liệu lớn, ở đây ta có hai tập các xác suất có điều kiện với “ice” và “steam” là các từ tâm đích và tỷ số giữa chúng:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| $w_k=$ \t| solid \t| gas \t| water \t| fashion \t|\n",
    "|:-\t|:-:\t|:-:\t|:-:\t|:-:\t|\n",
    "| $p_1=P(w_k\\mid \\text{ice})$ \t| 0.00019 \t| 0.000066 \t| 0.003 \t| 0.000017 \t|\n",
    "| $p_2=P(w_k\\mid\\text{steam})$ \t| 0.000022 \t| 0.00078 \t| 0.0022 \t| 0.000018 \t|\n",
    "| $p_1/p_2$ \t| 8.9 \t| 0.085 \t| 1.36 \t| 0.96 \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể quan sát thấy các hiện tượng như sau:\n",
    "\n",
    "Với từ wk liên quan tới từ “ice (đá)” nhưng không liên quan đến từ “steam (hơi nước)”, như là $w_k=solid$ (rắn), ta kỳ vọng là tỷ số xác suất có điều kiện sẽ lớn hơn, như trường hợp này là 8.9 ở hàng cuối cùng của bảng trên. Với từ $w_k$ liên quan tới từ “steam (hơi nước)” mà không có liên quan nào với từ “ice (đá)”, như là $w_k=gas$ (khí), ta kỳ vọng là tỷ số xác suất có điều kiện sẽ nhỏ hơn, như trường hợp này là 0.085 ở hàng cuối cùng của bảng trên. Với từ $w_k$ liên quan tới cả hai từ “steam (hơi nước)” và từ “ice (đá)”, như là $w_k=water$ (nước), ta kỳ vọng là tỷ số xác suất có điều kiện sẽ gần với 1, như trường hợp này là 1.36 ở hàng cuối cùng của bảng trên. Với từ $w_k$ không liên quan tới cả hai từ “steam (hơi)” và từ “ice (đá)”, như là $w_k=fashion$ (thời trang), ta kỳ vọng là tỷ số xác suất có điều kiện sẽ gần với 1, như trường hợp này là 0.96 ở hàng cuối cùng của bảng trên.\n",
    "\n",
    "Có thể thấy rằng tỷ số xác suất có điều kiện thể hiện mối quan hệ giữa các từ khác nhau trực quan hơn. Ta có thể tạo một hàm vector của từ để khớp tỷ số xác suất có điều kiện một cách hiệu quả hơn. Như đã biết, để thu được bất cứ tỷ số nào loại này đòi hỏi phải có ba từ $w_i$, $w_j$, và $w_k$. tỷ số xác suất có điều kiện với $w_i$ làm từ trung tâm là ${p_{ij}}/{p_{ik}}$. Ta có thể tìm một hàm dùng các vector từ để khớp với tỷ số xác suất có điều kiện này.\n",
    "\n",
    "<center>$f(\\mathbf{u}_j, \\mathbf{u}_k, {\\mathbf{v}}_i) \\approx \\frac{p_{ij}}{p_{ik}}.$</center>\n",
    "\n",
    "Thiết kế khả dĩ của hàm f ở đây không phải duy nhất. Ta chỉ cần quan tâm một lựa chọn hợp lý hơn. Do tỷ số xác suất có điều kiện là một số vô hướng, ta có thể giới hạn f vào một hàm vô hướng: $f(\\mathbf{u}_j, \\mathbf{u}_k, {\\mathbf{v}}_i) = f\\left((\\mathbf{u}_j - \\mathbf{u}_k)^\\top {\\mathbf{v}}_i\\right)$. Sau khi hóan đổi chỉ số $j$ và $k$, ta có thể thấy rằng hàm $f$ thỏa mãn điều kiện $f(x)f(−x)=1$, do đó một lựa chọn có thể là $f(x)=exp(x)$. Ta có:\n",
    "\n",
    "<center>$f(\\mathbf{u}_j, \\mathbf{u}_k, {\\mathbf{v}}_i) = \\frac{\\exp\\left(\\mathbf{u}_j^\\top {\\mathbf{v}}_i\\right)}{\\exp\\left(\\mathbf{u}_k^\\top {\\mathbf{v}}_i\\right)} \\approx \\frac{p_{ij}}{p_{ik}}.$<center>\n",
    "\n",
    "Một xác suất thỏa mãn vế phải biểu thức xấp xỉ là $\\exp\\left(\\mathbf{u}_j^\\top {\\mathbf{v}}_i\\right) \\approx \\alpha p_{ij}$, ở đây $α$ là một hằng số. Xét $p_{ij}=x_{ij}/x_i$, sau khi lấy logarit ta được $\\mathbf{u}_j^\\top {\\mathbf{v}}_i \\approx \\log\\,\\alpha + \\log\\,x_{ij} - \\log\\,x_i$. Ta sử dụng thêm hệ số điều chỉnh để khớp $- \\log\\, \\alpha + \\log\\, x_i$, cụ thể là hệ số điều chỉnh từ trung tâm bi và hệ số điều chỉnh từ ngữ cảnh $c_j$:\n",
    "\n",
    "<center>$\\mathbf{u}_j^\\top \\mathbf{v}_i + b_i + c_j \\approx \\log(x_{ij}).$</center>\n",
    "\n",
    "Bằng cách lấy sai số bình phương và đặt trọng số vào vế trái và vế phải của biểu thức trên, ta tính được hàm mất mát của GloVe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.5.3. Tóm tắt\n",
    "- Trong một số trường hợp, hàm mất mát entropy chéo có sự hạn chế. GloVe sử dụng mất mát bình phương và vector từ để khớp các thống kê toàn cục được tính trước dựa trên toàn bộ dữ liệu.\n",
    "- Vector từ đích trung tâm và vector từ ngữ cảnh của bất kì từ nào là như nhau trong GloVe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.5.4. Bài tập\n",
    "1. Nếu một từ xuất hiện trong cửa sổ ngữ cảnh của từ khác, làm thế nào để sử dụng khoảng cách giữa hai từ này trong chuỗi văn bản để thiết kế lại phương pháp tính toán xác suất có điều kiện  $p_{ij}$ ? Gợi ý: Tham khảo phần 4.2 trong bài báo GloVe [Pennington et al., 2014].\n",
    "2. Với một từ bất kỳ, liệu hệ số điều chỉnh của từ đích trung tâm và từ ngữ cảnh là như nhau trong GloVe không? Tại sao?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.6. Embedding từ con\n",
    "Các từ tiếng Anh thường có những cấu những trúc nội tại và phương thức cấu thành. Chẳng hạn, ta có thể suy ra mối quan hệ giữa các từ “dog”, “dogs” và “dogcatcher” thông qua cách viết của chúng. Tất cả các từ đó có cùng từ gốc là “dog” nhưng có hậu tố khác nhau làm thay đổi nghĩa của từ. Hơn nữa, sự liên kết này có thể được mở rộng ra đối với các từ khác. Chẳng hạn, mối quan hệ giữa từ “dog” và “dogs” đơn giản giống như mối quan hệ giữa từ “cat” và “cats”. Mối quan hệ giữa từ “boy” và “boyfriend” đơn giản giống mối quan hệ giữa từ “girl” và “girlfriend”. Đặc tính này không phải là duy nhất trong tiếng Anh. Trong tiếng Pháp và Tây Ban Nha, rất nhiều động từ có thể có hơn 40 dạng khác nhau tùy thuộc vào ngữ cảnh. Trong tiếng Phần Lan, một danh từ có thể có hơn 15 dạng. Thật vậy, hình thái học (**morphology**) là một nhánh quan trọng của ngôn ngữ học chuyên nghiên cứu về cấu trúc và hình thái của các từ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.6.1. fastText\n",
    "Trong word2vec, ta không trực tiếp sử dụng thông tin hình thái học. Trong cả mô hình skip-gram và túi từ (bag-of-word) liên tục, ta sử dụng các vector khác nhau để biểu diễn các từ ở các dạng khác nhau. Chẳng hạn, “dog” và “dogs” được biểu diễn bởi hai vector khác nhau, trong khi mối quan hệ giữa hai vector đó không biểu thị trực tiếp trong mô hình. Từ quan điểm này, fastText [Bojanowski et al., 2017] đề xuất phương thức embedding từ con (**subword embedding**), thông qua việc thực hiện đưa thông tin hình thái học vào trong mô hình skip-gram trong word2vec.\n",
    "\n",
    "Trong fastText, mỗi từ trung tâm được biểu diễn như một tập hợp của các từ con. Dưới đây ta sử dụng từ “where” làm ví dụ để hiểu cách các từ tố được tạo thành. Trước hết, ta thêm một số ký tự đặc biệt “<” và “>” vào phần bắt đầu và kết thúc của từ để phân biệt các từ con được dùng làm tiền tố và hậu tố. Rồi ta sẽ xem từ này như một chuỗi các ký tự để trích xuất  n -grams. Chẳng hạn, khi  $n=3$ , ta có thể nhận tất cả từ tố với chiều dài là  $3$ :\n",
    "\n",
    "<center>$\"<wh\", \"whe\", \"her\", \"ere\", \"re>\",$</center>\n",
    " \n",
    "và từ con đặc biệt  \"$<where>$\" .\n",
    "\n",
    "Trong fastText, với một từ  $w$ , ta ghi tập hợp của tất cả các từ con của nó với chiều dài từ  $3$  đến  $6$  và các từ con đặc biệt là  $\\mathcal{G}_w$ . Do đó, từ điển này là tập hợp các từ con của tất cả các từ. Giả sử vector của từ con  $g$  trong từ điển này là  $\\mathbf{z}_g$ . Thì vector từ trung tâm  $\\mathbf{u}_w$  cho từ  $w$  trong mô hình skip-gram có thể biểu diễn là\n",
    "\n",
    "<center>$\\mathbf{u}_w = \\sum_{g\\in\\mathcal{G}_w} \\mathbf{z}_g.$</center>\n",
    " \n",
    "Phần còn lại của tiến trình xử lý trong fastText đồng nhất với mô hình skip-gram, vì vậy ta không mô tả lại ở đây. Như chúng ta có thể thấy, so sánh với mô hình skip-gram, từ điển của fastText lớn hơn dẫn tới nhiều tham số mô hình hơn. Hơn nữa, vector của một từ đòi hỏi tính tổng của tất cả vector từ con dẫn tới độ phức tạp tính toán cao hơn. Tuy nhiên, ta có thể thu được các vector tốt hơn cho nhiều từ phức hợp ít thông dụng, thậm chí cho cả các từ không hiện diện trong từ điển này nhờ tham chiếu tới các từ khác có cấu trúc tương tự."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.6.2. Mã hoá cặp byte\n",
    "Trong fastText, tất cả các từ con được trích xuất phải nằm trong khoảng độ dài cho trước, ví dụ như từ  3  đến  6 , do đó kích thước bộ từ vựng không thể được xác định trước. Để cho phép các từ con có độ dài biến thiên trong bộ từ vựng có kích thước cố định, chúng ta có thể áp dụng thuật toán nén gọi là mã hoá cặp byte (**Byte Pair Encoding -BPE**) để trích xuất các từ con [Sennrich et al., 2015].\n",
    "\n",
    "Mã hóa cặp byte thực hiện phân tích thống kê tập dữ liệu huấn luyện để tìm các ký hiệu chung trong một từ, chẳng hạn như các ký tự liên tiếp có độ dài tùy ý. Bắt đầu từ các ký hiệu có độ dài bằng  1 , mã hóa cặp byte lặp đi lặp lại việc gộp các cặp ký hiệu liên tiếp thường gặp nhất để tạo ra các ký hiệu mới dài hơn. Lưu ý rằng để tăng hiệu năng, các cặp vượt qua ranh giới từ sẽ không được xét. Cuối cùng, chúng ta có thể sử dụng các ký hiệu đó như từ con để phân đoạn các từ. Mã hóa cặp byte và các biến thể của nó đã được sử dụng để biểu diễn đầu vào trong các mô hình tiền huấn luyện cho xử lý ngôn ngữ tự nhiên phổ biến như **GPT-2** [Radford et al., 2019] và **RoBERTa** [Liu et al., 2019]. Tiếp theo, chúng tôi sẽ minh hoạ cách hoạt động của mã hoá cặp byte.\n",
    "\n",
    "Đầu tiên, ta khởi tạo bộ từ vựng của các ký hiệu dưới dạng tất cả các ký tự viết thường trong tiếng Anh và hai ký hiệu đặc biệt: ký hiệu kết thúc của từ `'_'` , và ký hiệu không xác định `'[UNK]'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "symbols = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
    "           'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "           '_', '[UNK]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vì không xét các cặp ký hiệu vượt qua ranh giới của các từ, chúng ta chỉ cần một từ điển `raw_token_freqs` ánh xạ các từ tới tần suất của chúng (số lần xuất hiện) trong một tập dữ liệu. Lưu ý rằng ký hiệu đặc biệt `'_'` được thêm vào mỗi từ để có thể dễ dàng khôi phục chuỗi từ (ví dụ: “a taller man”) từ chuỗi ký hiệu đầu ra (ví dụ: “a_ tall er_ man”). Vì chúng ta bắt đầu quá trình gộp một từ vựng chỉ gồm các ký tự đơn và các ký hiệu đặc biệt, khoảng trắng được chèn giữa mọi cặp ký tự liên tiếp trong mỗi từ (các khóa của từ điển `token_freqs`). Nói cách khác, khoảng trắng là ký tự phân cách (delimiter) giữa các ký hiệu trong một từ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f a s t _': 4, 'f a s t e r _': 3, 't a l l _': 5, 't a l l e r _': 4}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_token_freqs = {'fast_': 4, 'faster_': 3, 'tall_': 5, 'taller_': 4}\n",
    "token_freqs = {}\n",
    "for token, freq in raw_token_freqs.items():\n",
    "    token_freqs[' '.join(list(token))] = raw_token_freqs[token]\n",
    "token_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta định nghĩa hàm `get_max_freq_pair` trả về cặp ký hiệu liên tiếp thường gặp nhất trong một từ, với từ là các khóa của từ điển đầu vào `token_freqs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_freq_pair(token_freqs):\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for token, freq in token_freqs.items():\n",
    "        symbols = token.split()\n",
    "        for i in range(len(symbols) - 1):\n",
    "            # Key of `pairs` is a tuple of two consecutive symbols\n",
    "            pairs[symbols[i], symbols[i + 1]] += freq\n",
    "    return max(pairs, key=pairs.get)  # Key of `pairs` with the max value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Là một thuật toán tham lam dựa trên tần suất của các ký hiệu liên tiếp nhau, mã hoá cặp byte sẽ dùng hàm `merge_symbols` để gộp cặp ký hiệu thường gặp nhất để tạo ra những ký hiệu mới."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_symbols(max_freq_pair, token_freqs, symbols):\n",
    "    symbols.append(''.join(max_freq_pair))\n",
    "    new_token_freqs = dict()\n",
    "    for token, freq in token_freqs.items():\n",
    "        new_token = token.replace(' '.join(max_freq_pair),\n",
    "                                  ''.join(max_freq_pair))\n",
    "        new_token_freqs[new_token] = token_freqs[token]\n",
    "    return new_token_freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ ta thực hiện vòng lặp giải thuật biểu diễn cặp byte với các khóa của từ điển `token_freqs`. Ở vòng lặp đầu tiên, cặp biểu tượng liền kề có tần suất cao nhất là `'t'` và `'a'`, do đó biểu diễn cặp byte ghép chúng lại để tạo ra một biểu tượng mới là `'ta'`. Ở vòng lặp thứ hai, biểu diễn cặp byte tiếp tục ghép 2 biểu tượng `'ta'` và `'l'` tạo ra một biểu tượng mới khác là `'tal'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge #1: ('t', 'a')\n",
      "merge #2: ('ta', 'l')\n",
      "merge #3: ('tal', 'l')\n",
      "merge #4: ('f', 'a')\n",
      "merge #5: ('fa', 's')\n",
      "merge #6: ('fas', 't')\n",
      "merge #7: ('e', 'r')\n",
      "merge #8: ('er', '_')\n",
      "merge #9: ('tall', '_')\n",
      "merge #10: ('fast', '_')\n"
     ]
    }
   ],
   "source": [
    "num_merges = 10\n",
    "for i in range(num_merges):\n",
    "    max_freq_pair = get_max_freq_pair(token_freqs)\n",
    "    token_freqs = merge_symbols(max_freq_pair, token_freqs, symbols)\n",
    "    print(f'merge #{i + 1}:', max_freq_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau 10 vòng lặp biểu diễn cặp byte, ta có thể thấy là danh sách symbols lúc này chứa hơn 10 biểu tượng đã được lần lượt ghép từ các biểu tượng khác."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '_', '[UNK]', 'ta', 'tal', 'tall', 'fa', 'fas', 'fast', 'er', 'er_', 'tall_', 'fast_']\n"
     ]
    }
   ],
   "source": [
    "print(symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với cùng tập dữ liệu đặc tả trong các khóa của từ điển `raw_token_freqs`, mỗi từ trong tập dữ liệu này bây giờ được phân đoạn bởi các từ con là `“fast_”`, `“fast”`, `“er_”`, `“tall_”`, và `“tall”` theo giải thuật biểu diễn cặp byte. Chẳng hạn, từ `“faster_”` và từ `“taller_”` được phân đoạn lần lượt là `“fast er_”` và `“tall er_”`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fast_', 'fast er_', 'tall_', 'tall er_']\n"
     ]
    }
   ],
   "source": [
    "print(list(token_freqs.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chú ý là kết quả của biểu diễn cặp byte tùy thuộc vào tập dữ liệu đang được sử dụng. Ta cũng có thể dùng các từ con đã học từ một tập dữ liệu để phân đoạn các từ của một tập dữ liệu khác. Với cách tiếp cận tham lam, hàm `segment_BPE` sau đây cố gắng tách các từ thành các từ con dài nhất có thể từ đối số đầu vào `symbols`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_BPE(tokens, symbols):\n",
    "    outputs = []\n",
    "    for token in tokens:\n",
    "        start, end = 0, len(token)\n",
    "        cur_output = []\n",
    "        # Segment token with the longest possible subwords from symbols\n",
    "        while start < len(token) and start < end:\n",
    "            if token[start: end] in symbols:\n",
    "                cur_output.append(token[start: end])\n",
    "                start = end\n",
    "                end = len(token)\n",
    "            else:\n",
    "                end -= 1\n",
    "        if start < len(token):\n",
    "            cur_output.append('[UNK]')\n",
    "        outputs.append(' '.join(cur_output))\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong phần tiếp theo, ta sử dụng các từ con trong danh sách `symbols` đã được học từ tập dữ liệu ở trên để phân đoạn các `tokens` biểu diễn tập dữ liệu khác."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tall e s t _', 'fa t t er_']\n"
     ]
    }
   ],
   "source": [
    "tokens = ['tallest_', 'fatter_']\n",
    "print(segment_BPE(tokens, symbols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.6.3. Tóm tắt\n",
    "- FastText đề xuất phương pháp embedding cho từ con. Dựa trên mô hình skip-gram trong word2vec, phương pháp này biểu diễn vector từ trung tâm thành tổng các vector từ con của từ đó.\n",
    "- Embedding cho từ con sử dụng nguyên tắc trong hình thái học, thường giúp cải thiện chất lượng biểu diễn của các từ ít gặp.\n",
    "- Mã hoá cặp byte thực hiện phân tích thống kê trên tập dữ liệu huấn luyện để phát hiện các ký hiệu chung trong một từ. Là một giải thuật tham lam, mã hoá cặp byte lần lượt gộp các cặp ký hiệu liên tiếp thường gặp nhất lại với nhau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.6.4. Bài tập\n",
    "1. Khi có quá nhiều từ con (ví dụ, 6 từ trong tiếng Anh có thể tạo ra  $3×10^8$  các tổ hợp khác nhau), vấn đề gì sẽ xảy ra? Bạn có thể giải quyết vấn đề trên không? Gợi ý: Tham khảo đoạn cuối phần 3.2 của bài báo fastText [1].\n",
    "2. Làm sao để thiết kế một mô hình embedding cho từ con dựa trên mô hình túi từ liên tục CBOW ?\n",
    "3. Để thu được bộ từ vựng có kích thước  $m$ , bao nhiêu phép gộp cần được thực hiện khi bộ từ vựng ký hiệu ban đầu có kích thước là  $n$ ?\n",
    "4. Ta có thể mở rộng ý tưởng của thuật toán mã hoá cặp byte để trích xuất các cụm từ bằng cách nào?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.7. Tìm kiếm từ Đồng nghĩa và Loại suy\n",
    "Trong Section 14.4 ta đã huấn luyện mô hình embedding từ word2vec trên tập dữ liệu cỡ nhỏ và tìm kiếm các từ đồng nghĩa sử dụng độ tương tự cô-sin giữa các vector từ. Trong thực tế, các vector từ được tiền huấn luyện trên kho ngữ liệu cỡ lớn thường được áp dụng cho các bài toán xử lý ngôn ngữ tự nhiên cụ thể. Phần này sẽ trình bày cách sử dụng các vector từ đã tiền huấn luyện để tìm các từ đồng nghĩa và các loại suy (**analogy**). Ta sẽ tiếp tục áp dụng các vector từ được tiền huấn luyện trong các phần sau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.7.1. Sử dụng các Vector Từ đã được Tiền Huấn luyện\n",
    "Dưới đây là các embedding GloVe đã được tiền huấn luyện với kích thước chiều là 50, 100, và 300, có thể được tải từ trang web [GloVe](https://nlp.stanford.edu/projects/glove/). Các embedding cho [fastText](https://fasttext.cc/) được tiền huấn luyện trên nhiều ngôn ngữ. Ở đây, ta quan tâm tới phiên bản cho tiếng Anh (“wiki.en” có chiều là 300) có thể được tải từ trang web fastText."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "d2l.DATA_HUB['glove.6b.50d'] = (d2l.DATA_URL + 'glove.6B.50d.zip',\n",
    "                                '0b8703943ccdb6eb788e6f091b8946e82231bc4d')\n",
    "\n",
    "#@save\n",
    "d2l.DATA_HUB['glove.6b.100d'] = (d2l.DATA_URL + 'glove.6B.100d.zip',\n",
    "                                 'cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a')\n",
    "\n",
    "#@save\n",
    "d2l.DATA_HUB['glove.42b.300d'] = (d2l.DATA_URL + 'glove.42B.300d.zip',\n",
    "                                  'b5116e234e9eb9076672cfeabf5469f3eec904fa')\n",
    "\n",
    "#@save\n",
    "d2l.DATA_HUB['wiki.en'] = (d2l.DATA_URL + 'wiki.en.zip',\n",
    "                           'c1816da3821ae9f43899be655002f6c723e91b88')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta định nghĩa lớp `TokenEmbedding` để nạp các embedding GloVe và fastText ở trên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class TokenEmbedding:\n",
    "    \"\"\"Token Embedding.\"\"\"\n",
    "    def __init__(self, embedding_name):\n",
    "        self.idx_to_token, self.idx_to_vec = self._load_embedding(\n",
    "            embedding_name)\n",
    "        self.unknown_idx = 0\n",
    "        self.token_to_idx = {token: idx for idx, token in\n",
    "                             enumerate(self.idx_to_token)}\n",
    "\n",
    "    def _load_embedding(self, embedding_name):\n",
    "        idx_to_token, idx_to_vec = ['<unk>'], []\n",
    "        data_dir = d2l.download_extract(embedding_name)\n",
    "        # GloVe website: https://nlp.stanford.edu/projects/glove/\n",
    "        # fastText website: https://fasttext.cc/\n",
    "        with open(os.path.join(data_dir, 'vec.txt'), 'r') as f:\n",
    "            for line in f:\n",
    "                elems = line.rstrip().split(' ')\n",
    "                token, elems = elems[0], [float(elem) for elem in elems[1:]]\n",
    "                # Skip header information, such as the top row in fastText\n",
    "                if len(elems) > 1:\n",
    "                    idx_to_token.append(token)\n",
    "                    idx_to_vec.append(elems)\n",
    "        idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n",
    "        return idx_to_token, np.array(idx_to_vec)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        indices = [self.token_to_idx.get(token, self.unknown_idx)\n",
    "                   for token in tokens]\n",
    "        vecs = self.idx_to_vec[np.array(indices)]\n",
    "        return vecs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo, ta sử dụng embedding GloVe có chiều là 50 được tiền huấn luyện trên tập con của Wikipedia. Embedding tương ứng của từ sẽ được tự động tải về khi tạo một thực thể `TokenEmbedding` lần đầu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ..\\data\\glove.6B.50d.zip from http://d2l-data.s3-accelerate.amazonaws.com/glove.6B.50d.zip...\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 2273: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-f7144bcb60b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mglove_6b50d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTokenEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'glove.6b.50d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-6f5acd5f9fa2>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, embedding_name)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;34m\"\"\"Token Embedding.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         self.idx_to_token, self.idx_to_vec = self._load_embedding(\n\u001b[0m\u001b[0;32m      6\u001b[0m             embedding_name)\n\u001b[0;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munknown_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-6f5acd5f9fa2>\u001b[0m in \u001b[0;36m_load_embedding\u001b[1;34m(self, embedding_name)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# fastText website: https://fasttext.cc/\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vec.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                 \u001b[0melems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melems\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0melems\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 2273: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "glove_6b50d = TokenEmbedding('glove.6b.50d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể in ra kích thước từ điển. Từ điển chứa  $400,000$  từ và một token đặc biệt cho các từ không biết."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(glove_6b50d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể lấy chỉ số của một từ trong từ điển, hoặc ngược lại tra từ tương ứng với chỉ số cho trước."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_6b50d.token_to_idx['beautiful'], glove_6b50d.idx_to_token[3367]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.7.2. Áp dụng các Vector Từ đã được Tiền huấn luyện¶\n",
    "Dưới đây, ta minh họa việc áp dụng các vector từ đã được tiền huấn luyện sử dụng Glove làm ví dụ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.7.2.1. Tìm các từ đồng nghĩa\n",
    "Tại đây, ta lập trình lại thuật toán tìm các từ đồng nghĩa bằng độ tương tự cô-sin giữa hai vector trong Section 14.1.\n",
    "\n",
    "Để sử dụng lại logic tìm kiếm  $k$  láng giềng gần nhất ( $k -nearest neighbors$) khi tìm kiếm các từ loại suy, ta đóng gói phần này một cách tách biệt trong hàm $knn$ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(W, x, k):\n",
    "    # The added 1e-9 is for numerical stability\n",
    "    cos = torch.mv(W, x.reshape(\n",
    "        -1,)) / (torch.sqrt(torch.sum(W * W, axis=1) + 1e-9) * torch.sqrt(\n",
    "            (x * x).sum()))\n",
    "    _, topk = torch.topk(cos, k=k)\n",
    "    return topk, [cos[int(i)] for i in topk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kế tiếp, ta tìm kiếm các từ đồng nghĩa nhờ tiền huấn luyện thực thể vector từ `embed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_tokens(query_token, k, embed):\n",
    "    topk, cos = knn(embed.idx_to_vec, embed[[query_token]], k + 1)\n",
    "    for i, c in zip(topk[1:], cos[1:]):  # Remove input words\n",
    "        print(f'cosine sim={float(c):.3f}: {embed.idx_to_token[int(i)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Từ điển vector từ được tiền huấn luyện `glove_6b50d` đã tạo chứa 400,000 từ và một token các từ không biết. Loại trừ những từ đầu vào và những từ không biết, ta tìm kiếm ba từ có nghĩa gần với từ `“chip”`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similar_tokens('chip', 3, glove_6b50d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kế tiếp, ta tìm các từ gần nghĩa với “baby” và “beautiful”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similar_tokens('baby', 3, glove_6b50d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similar_tokens('beautiful', 3, glove_6b50d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.7.2.2. Tìm kiếm các Loại suy\n",
    "Bên cạnh việc tìm kiếm các từ đồng nghĩa, ta cũng có thể sử dụng các vector từ đã tiền huấn luyện để tìm kiếm các loại suy giữa các từ. Ví dụ, “man”:“woman”::“son”:“daughter” là một loại suy, “man (nam)” với “woman (nữ)” giống như “son (con trai)” với “daughter (con gái)”. Bài toán tìm kiếm loại suy có thể được định nghĩa như sau: với bốn từ trong quan hệ loại suy  $a:b::c:d$ , cho trước ba từ  $a ,  b$  và  $c$ , ta muốn tìm từ  $d$ . Giả sử, vector từ cho từ  $w$  là  $vec(w)$ . Để giải quyết bài toán loại suy, ta cần tìm vector từ gần nhất với vector là kết quả của  $vec(c)+vec(b)−vec(a)$ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analogy(token_a, token_b, token_c, embed):\n",
    "    vecs = embed[[token_a, token_b, token_c]]\n",
    "    x = vecs[1] - vecs[0] + vecs[2]\n",
    "    topk, cos = knn(embed.idx_to_vec, x, 1)\n",
    "    return embed.idx_to_token[int(topk[0])]  # Remove unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kiểm tra quan hệ loại suy “nam giới - nữ giới”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_analogy('man', 'woman', 'son', glove_6b50d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loại suy “thủ đô-quốc gia”: từ `“beijing”` với từ `“china”` tương tự như từ `“tokyo”` với từ nào? Đáp án là `“japan”`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_analogy('beijing', 'china', 'tokyo', glove_6b50d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loại suy “tính từ - tính từ so sánh nhất”: từ `“bad”` với từ `“worst”` tương tự như từ `“big”` với từ nào? Đáp án là `“biggest”`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_analogy('bad', 'worst', 'big', glove_6b50d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loại suy “động từ thì hiện tại - động từ thì quá khứ”: từ `“do”` với từ `“did”` tương tự như từ `“go”` với từ nào? Đáp án là `“went”`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_analogy('do', 'did', 'go', glove_6b50d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.7.3. Tóm tắt\n",
    "- Các vector từ được tiền huấn luyện trên kho ngữ liệu cỡ lớn thường được áp dụng cho các tác vụ xử lý ngôn ngữ tự nhiên.\n",
    "- Ta có thể sử dụng các vector từ được tiền huấn luyện để tìm kiếm các từ đồng nghĩa và các loại suy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.7.4. Bài tập\n",
    "1. Hãy kiểm tra kết quả với fastText bằng cách sử dụng TokenEmbedding('wiki.en').\n",
    "2. Nếu từ điển quá lớn, ta có thể tăng tốc tìm kiếm các từ đồng nghĩa và các loại suy bằng cách nào?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.8. Biểu diễn Mã hóa hai chiều từ Transformer (BERT)\n",
    "Chúng tôi đã giới thiệu một vài mô hình embedding từ cho bài toán hiểu ngôn ngữ tự nhiên. Sau khi tiền huấn luyện, đầu ra của các mô hình này có thể xem là một ma trận trong đó mỗi hàng là một vector biểu diễn một từ trong bộ từ vựng được định nghĩa trước. Trong thực tế, tất cả các mô hình embedding từ này đều độc lập ngữ cảnh (**context-independent**). Hãy bắt đầu bằng việc minh họa tính chất này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.8.1. Từ Độc lập Ngữ cảnh đến Nhạy Ngữ cảnh\n",
    "Hãy nhớ lại các thí nghiệm trong Section 14.4 và Section 14.7. Cả word2vec và GloVe đều gán cùng một vector được tiền huấn luyện cho cùng một từ bất kể ngữ cảnh (nếu có) của nó như thế nào. Về mặt hình thức, biểu diễn độc lập ngữ cảnh của một token bất kỳ  $x$  là một hàm  $f(x)$  chỉ nhận  $x$  làm đầu vào. Do hiện tượng đa nghĩa cũng như sự phức tạp ngữ nghĩa xuất hiện khá phổ biến trong ngôn ngữ tự nhiên, biểu diễn độc lập ngữ cảnh có những hạn chế rõ ràng. Ví dụ, từ “crane” trong ngữ cảnh “a crane is flying (một con sếu đang bay)” và ngữ cảnh “a crane driver came (tài xế xe cần cẩu đã tới)” có nghĩa hoàn toàn khác nhau; do đó, cùng một từ nên được gán các biểu diễn khác nhau tùy ngữ cảnh.\n",
    "\n",
    "Điều này thúc đẩy sự phát triển của các biểu diễn từ nhạy ngữ cảnh (context-sensitive), trong đó biểu diễn của từ phụ thuộc vào ngữ cảnh của từ đó. Do đó, biểu diễn nhạy ngữ cảnh của một token bất kỳ  $x$  là hàm  $f(x,c(x))$  phụ thuộc vào cả từ  $x$  lẫn ngữ cảnh của từ  $c(x)$ . Các biểu diễn nhạy ngữ cảnh phổ biến bao gồm TagLM (Bộ Tag chuỗi được tăng cường với mô hình ngôn ngữ (language-model-augmented sequence tagger)) [Peters et al., 2017b], CoVe (vector ngữ cảnh (Context Vectors)) [McCann et al., 2017], và ELMo (embedding từ các mô hình ngôn ngữ (Embeddings from Language Models)) [Peters et al., 2018].\n",
    "\n",
    "Ví dụ, bằng cách lấy toàn bộ chuỗi làm đầu vào, ELMo gán một biểu diễn cho mỗi từ trong chuỗi đầu vào. Cụ thể, ELMo kết hợp tất cả các biểu diễn tầng trung gian từ LSTM hai chiều đã được tiền huấn luyện làm biểu diễn đầu ra. Sau đó, biểu diễn ELMo sẽ được đưa vào một mô hình học có giám sát cho các tác vụ xuôi dòng như một đặc trưng bổ sung, chẳng hạn bằng cách nối biểu diễn ELMo và biểu diễn gốc (ví dụ như GloVe) của token trong mô hình hiện tại. Một mặt, tất cả các trọng số trong mô hình LSTM hai chiều được tiền huấn luyện đều bị đóng băng sau khi các biểu diễn ELMo được thêm vào. Mặt khác, mô hình học có giám sát được tùy biến cụ thể cho một tác vụ nhất định. Tại thời điểm được công bố, thêm ELMo vào các mô hình tân tiến nhất giúp cải thiện chất lượng các mô hình này trên sáu tác vụ xử lý ngôn ngữ tự nhiên: phân tích cảm xúc (**sentiment analysis**), suy luận ngôn ngữ tự nhiên (**natural language inference**), gán nhãn vai trò ngữ nghĩa (**semantic role labeling**), phân giải đồng tham chiếu (**coreference resolution**), nhận dạng thực thể có tên (**named entity recognition**) và trả lời câu hỏi (**question answering**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.8.2. Từ Đặc thù Tác vụ đến Không phân biệt Tác vụ\n",
    "Mặc dù ELMo đã cải thiện đáng kể giải pháp cho một loạt các tác vụ xử lý ngôn ngữ tự nhiên, mỗi giải pháp vẫn dựa trên một kiến trúc đặc thù cho tác vụ (**task-specific**). Tuy nhiên trong thực tế, xây dựng một kiến trúc đặc thù cho mỗi tác vụ xử lý ngôn ngữ tự nhiên là điều không đơn giản. Phương pháp GPT (**Generative Pre-Training**) thể hiện nỗ lực thiết kế một mô hình không phân biệt tác vụ (**task-agnostic**) chung cho các biểu diễn nhạy ngữ cảnh [Radford et al., 2018]. Được xây dựng dựa trên bộ giải mã Transformer, GPT tiền huấn luyện mô hình ngôn ngữ được sử dụng để biểu diễn chuỗi văn bản. Khi áp dụng GPT cho một tác vụ xuôi dòng, đầu ra của mô hình ngôn ngữ sẽ được truyền tới một tầng đầu ra tuyến tính được bổ sung để dự đoán nhãn cho tác vụ đó. Trái ngược hoàn toàn với cách ELMo đóng băng các tham số của mô hình tiền huấn luyện, GPT tinh chỉnh tất cả các tham số trong bộ giải mã Transformer tiền huấn luyện trong suốt quá trình học có giám sát trên tác vụ xuôi dòng. GPT được đánh giá trên mười hai tác vụ về suy luận ngôn ngữ tự nhiên, trả lời câu hỏi, độ tương tự của câu, và bài toán phân loại, và cải thiện kết quả tân tiến nhất của chín tác vụ với vài thay đổi tối thiểu trong kiến trúc mô hình.\n",
    "\n",
    "Tuy nhiên, do tính chất tự hồi quy của các mô hình ngôn ngữ, GPT chỉ nhìn theo chiều xuôi (từ trái sang phải). Trong các ngữ cảnh `“I went to the bank to deposit cash”` (“tôi đến ngân hàng để gửi tiền”) và `“I went to the bank to sit down”` (“tôi ra bờ hồ ngồi”), do từ “bank” nhạy với ngữ cảnh bên trái, GPT sẽ trả về cùng một biểu diễn cho từ “bank”, mặc dù nó có nghĩa khác nhau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.8.3. BERT: Kết hợp những Điều Tốt nhất của Hai Phương pháp\n",
    "Như ta đã thấy, ELMo mã hóa ngữ cảnh hai chiều nhưng sử dụng các kiến​​trúc đặc thù cho từng tác vụ; trong khi đó GPT có kiến trúc không phân biệt tác vụ nhưng mã hóa ngữ cảnh từ trái sang phải. Kết hợp những điều tốt nhất của hai phương pháp trên, BERT (biểu diễn mã hóa hai chiều từ Transformer - **Bidirectional Encoder Representations from Transformers**) mã hóa ngữ cảnh theo hai chiều và chỉ yêu cầu vài thay đổi kiến trúc tối thiểu cho một loạt các tác vụ xử lý ngôn ngữ tự nhiên [Devlin et al., 2018]. Sử dụng bộ mã hóa Transformer được tiền huấn luyện, BERT có thể biểu diễn bất kỳ token nào dựa trên ngữ cảnh hai chiều của nó. Trong quá trình học có giám sát trên các tác vụ xuôi dòng, BERT tương tự như GPT ở hai khía cạnh. Đầu tiên, các biểu diễn BERT sẽ được truyền vào một tầng đầu ra được bổ sung, với những thay đổi tối thiểu tới kiến trúc mô hình tùy thuộc vào bản chất của tác vụ, chẳng hạn như dự đoán cho mỗi token hay dự đoán cho toàn bộ chuỗi. Thứ hai, tất cả các tham số của bộ mã hóa Transformer đã tiền huấn luyện đều được tinh chỉnh, trong khi tầng đầu ra bổ sung sẽ được huấn luyện từ đầu. Fig. 14.8.1 mô tả những điểm khác biệt giữa ELMo, GPT, và BERT.\n",
    "\n",
    "![](images/elmo-gpt-bert.svg)\n",
    "\n",
    "*Fig. 14.8.1 So sánh giữa ELMO, GPT, và BERT.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT cải thiện kết quả tân tiến nhất đối với mười một tác vụ xử lý ngôn ngữ tự nhiên trải khắp các hạng mục gồm: i) phân loại văn bản đơn (như phân tích cảm xúc), ii) phân loại cặp văn bản (như suy luận ngôn ngữ tự nhiên), iii) trả lời câu hỏi, và iv) gán thẻ văn bản (như nhận dạng thực thể có tên). Tất cả các kỹ thuật được đề xuất trong năm 2018, từ ELMo nhạy ngữ cảnh cho tới GPT không phân biệt tác vụ và BERT, tuy về ý tưởng đều đơn giản nhưng trên thực nghiệm là những phương pháp tiền huấn luyện hiệu quả cho các biểu diễn sâu của ngôn ngữ tự nhiên, và đã mang đến những giải pháp mang tính cách mạng cho nhiều tác vụ xử lý ngôn ngữ tự nhiên.\n",
    "\n",
    "Ở phần còn lại của chương này, ta sẽ đi sâu vào tiền huấn luyện BERT. Sau khi những ứng dụng xử lý ngôn ngữ tự nhiên đã được giải thích trong Section 15, ta sẽ minh họa việc tinh chỉnh BERT cho các ứng dụng xuôi dòng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.8.4. Biểu diễn Đầu vào\n",
    "Trong xử lý ngôn ngữ tự nhiên, một số nhiệm vụ (như phân tích cảm xúc) lấy một câu văn làm đầu vào, trong khi một số tác vụ khác (như suy diễn ngôn ngữ tự nhiên), đầu vào là một cặp chuỗi văn bản. Chuỗi đầu vào BERT biểu diễn một cách tường minh cả văn bản đơn và cặp văn bản. Với văn bản đơn, chuỗi đầu vào BERT là sự ghép nối của token phân loại đặc biệt `“<cls>”`, token của chuỗi văn bản, và token phân tách đặc biệt `“<sep>”`. Với cặp văn bản, chuỗi đầu vào BERT là sự ghép nối của `“<cls>”`, token của chuỗi văn bản đầu, `“<sep>”`, token của chuỗi văn bản thứ hai, và `“<sep>”`. Ta sẽ phân biệt nhất quán thuật ngữ “chuỗi đầu vào BERT” với các kiểu “chuỗi” khác. Chẳng hạn, một chuỗi đầu vào BERT có thể bao gồm cả một chuỗi văn bản hoặc hai chuỗi văn bản.\n",
    "\n",
    "Để phân biệt cặp văn bản, các embedding đoạn đã học  $\\mathbf{e}_A$  và  $\\mathbf{e}_B$  được cộng tương ứng vào các embedding token của chuỗi thứ nhất và chuỗi thứ hai. Đối với đầu vào là văn bản đơn, ta chỉ sử dụng  $\\mathbf{e}_A$ .\n",
    "\n",
    "Hàm `get_tokens_and_segments` sau đây có thể lấy một hoặc hai câu làm đầu vào, rồi trả về các token của chuỗi đầu vào BERT và các ID đoạn tương ứng của chúng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def get_tokens_and_segments(tokens_a, tokens_b=None):\n",
    "    tokens = ['<cls>'] + tokens_a + ['<sep>']\n",
    "    # 0 and 1 are marking segment A and B, respectively\n",
    "    segments = [0] * (len(tokens_a) + 2)\n",
    "    if tokens_b is not None:\n",
    "        tokens += tokens_b + ['<sep>']\n",
    "        segments += [1] * (len(tokens_b) + 1)\n",
    "    return tokens, segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kiến trúc hai chiều của BERT là bộ mã hóa Transformer. Thông thường trong bộ mã hóa Transformer, các embedding vị trí được cộng vào mỗi vị trí của chuỗi đầu vào BERT. Tuy nhiên, khác với bộ mã hóa Transformer nguyên bản, BERT sử dụng các **embedding vị trí có thể học được**. Fig. 14.8.2 cho thấy các embedding của chuỗi đầu vào BERT là **tổng các embedding của token, embedding đoạn và embedding vị trí.**\n",
    "\n",
    "![](images/bert-input.svg)\n",
    "\n",
    "*Fig. 14.8.2 Embedding của chuỗi đầu vào BERT là tổng các embedding của token, embedding đoạn và embedding vị trí.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lớp `BERTEncoder` dưới đây tương tự như lớp `TransformerEncoder` trong Section 10.3. Khác với `TransformerEncoder`, `BERTEncoder` sử dụng các embedding đoạn và các embedding vị trí có thể học được."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class BERTEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input,\n",
    "                 ffn_num_hiddens, num_heads, num_layers, dropout,\n",
    "                 max_len=1000, key_size=768, query_size=768, value_size=768,\n",
    "                 **kwargs):\n",
    "        super(BERTEncoder, self).__init__(**kwargs)\n",
    "        self.token_embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.segment_embedding = nn.Embedding(2, num_hiddens)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\n",
    "                f\"{i}\",\n",
    "                d2l.EncoderBlock(key_size, query_size, value_size,\n",
    "                                 num_hiddens, norm_shape, ffn_num_input,\n",
    "                                 ffn_num_hiddens, num_heads, dropout, True))\n",
    "        # In BERT, positional embeddings are learnable, thus we create a\n",
    "        # parameter of positional embeddings that are long enough\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, max_len,\n",
    "                                                      num_hiddens))\n",
    "\n",
    "    def forward(self, tokens, segments, valid_lens):\n",
    "        # Shape of `X` remains unchanged in the following code snippet:\n",
    "        # (batch size, max sequence length, `num_hiddens`)\n",
    "        X = self.token_embedding(tokens) + self.segment_embedding(segments)\n",
    "        X = X + self.pos_embedding.data[:, :X.shape[1], :]\n",
    "        for blk in self.blks:\n",
    "            X = blk(X, valid_lens)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giả sử kích thước bộ từ vựng là 10,000. Để minh họa suy luận xuôi của `BERTEncoder`, hãy tạo ra một thực thể của nó và khởi tạo các thông số."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, num_hiddens, ffn_num_hiddens, num_heads = 10000, 768, 1024, 4\n",
    "norm_shape, ffn_num_input, num_layers, dropout = [768], 768, 2, 0.2\n",
    "encoder = BERTEncoder(vocab_size, num_hiddens, norm_shape, ffn_num_input,\n",
    "                      ffn_num_hiddens, num_heads, num_layers, dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta định nghĩa `tokens` là hai chuỗi đầu vào BERT có độ dài là 8, mỗi token là một chỉ mục của bộ từ vựng. Lượt suy luận xuôi của `BERTEncoder` với đầu vào `tokens` trả về kết quả được mã hóa, với mỗi token được biểu diễn bởi một vector có chiều dài được định nghĩa trước bởi siêu tham số `num_hiddens`, là **kích thước ẩn** (số lượng nút ẩn) của bộ mã hóa Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = torch.randint(0, vocab_size, (2, 8))\n",
    "segments = torch.tensor([[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 0, 1, 1, 1, 1, 1]])\n",
    "encoded_X = encoder(tokens, segments, None)\n",
    "encoded_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.8.5. Những tác vụ Tiền huấn luyện\n",
    "Suy luận xuôi của `BERTEncoder` cho ra biểu diễn BERT của mỗi token của văn bản đầu vào và các token đặc biệt được thêm vào `“<cls>”` và `“<seq>”`. Kế tiếp, ta sẽ sử dụng các biểu diễn này để tính toán hàm mất mát khi tiền huấn luyện BERT. Tiền huấn luyện gồm hai tác vụ: mô hình ngôn ngữ có mặt nạ (**masked language modeling**) và dự đoán câu tiếp theo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.8.5.1. Mô hình Ngôn ngữ có Mặt nạ\n",
    "Như mô tả trong Section 8.3, một mô hình ngôn ngữ dự đoán một token bằng cách sử dụng ngữ cảnh phía bên trái của nó. Để mã hóa ngữ cảnh hai chiều khi biểu diễn mỗi token, BERT ngẫu nhiên che mặt nạ các token và sử dụng các token lấy từ ngữ cảnh hai chiều để dự đoán các token mặt nạ đó. Tác vụ này được gọi là **mô hình hóa ngôn ngữ có mặt nạ**.\n",
    "\n",
    "Trong tác vụ tiền huấn luyện này, 15% số token sẽ được lựa chọn ngẫu nhiên để làm các token mặt nạ cho việc dự đoán. Để dự đoán một token mặt nạ mà không sử dụng nhãn, một hướng tiếp cận đơn giản là luôn luôn thay thế nó bằng token đặc biệt “<mask>” trong chuỗi đầu vào BERT. Tuy nhiên, token “<mask>” sẽ không bao giờ xuất hiện khi tinh chỉnh. Để tránh sự không đồng nhất giữa tiền huấn luyện và tinh chỉnh, nếu một token được che mặt nạ để dự đoán (ví dụ, từ “great” được chọn để che mặt nạ và dự đoán trong câu “this movie is great”), trong đầu vào nó sẽ được thay thế bởi:\n",
    "\n",
    "- token đặc biệt `“<mask>”`, 80% số lần (ví dụ, `“this movie is great”` trở thành `“this movie is <mask>”`);\n",
    "- token ngẫu nhiên, 10% số lần (ví dụ, `“this movie is great” trở thành “this movie is drink”`);\n",
    "- chính token đó, 10% số lần (ví dụ, `“this movie is great” trở thành “this movie is great”`).\n",
    "    \n",
    "Lưu ý rằng trong 15% token được chọn để che mặt nạ, 10% số token đó sẽ được thay thế bằng một token ngẫu nhiên. Việc thi thoảng thêm nhiễu sẽ giúp BERT giảm thiên kiến về phía token có mặt nạ (đặc biệt khi token nhãn không đổi) khi mã hóa ngữ cảnh hai chiều.\n",
    "\n",
    "Ta lập trình lớp `MaskLM` sau để dự đoán token có mặt nạ trong tác vụ mô hình hóa ngôn ngữ có mặt nạ khi tiền huấn luyện BERT. MLP một-tầng-ẩn (`self.mlp`) được dùng cho việc dự đoán. Lượt suy luận xuôi nhận hai đầu vào: kết quả mã hóa của `BERTEncoder` và vị trí token để dự đoán. Đầu ra là kết quả dự đoán tại các vị trí này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class MaskLM(nn.Module):\n",
    "    def __init__(self, vocab_size, num_hiddens, num_inputs=768, **kwargs):\n",
    "        super(MaskLM, self).__init__(**kwargs)\n",
    "        self.mlp = nn.Sequential(nn.Linear(num_inputs, num_hiddens),\n",
    "                                 nn.ReLU(), nn.LayerNorm(num_hiddens),\n",
    "                                 nn.Linear(num_hiddens, vocab_size))\n",
    "\n",
    "    def forward(self, X, pred_positions):\n",
    "        num_pred_positions = pred_positions.shape[1]\n",
    "        pred_positions = pred_positions.reshape(-1)\n",
    "        batch_size = X.shape[0]\n",
    "        batch_idx = torch.arange(0, batch_size)\n",
    "        # Suppose that `batch_size` = 2, `num_pred_positions` = 3, then\n",
    "        # `batch_idx` is `torch.tensor([0, 0, 0, 1, 1, 1])`\n",
    "        batch_idx = torch.repeat_interleave(batch_idx, num_pred_positions)\n",
    "        masked_X = X[batch_idx, pred_positions]\n",
    "        masked_X = masked_X.reshape((batch_size, num_pred_positions, -1))\n",
    "        mlm_Y_hat = self.mlp(masked_X)\n",
    "        return mlm_Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để minh họa lượt suy luận xuôi của `MaskLM`, ta sẽ khởi tạo một thực thể `mlm`. Hãy nhớ lại rằng `encoded_X` từ lượt suy luận xuôi của `BERTEncoder` biểu diễn 2 chuỗi đầu vào BERT. Ta định nghĩa `mlm_positions` là 3 chỉ số để dự đoán ở một trong hai chuỗi đầu vào BERT của `encoded_X`. Lượt suy luận xuôi của mlm trả về kết quả dự đoán `mlm_Y_hat` tại tất cả các vị trí mặt nạ `mlm_positions` của `encoded_X`. Với mỗi dự đoán, kích thước của kết quả bằng với kích thước bộ từ vựng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 10000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm = MaskLM(vocab_size, num_hiddens)\n",
    "mlm_positions = torch.tensor([[1, 5, 2], [6, 1, 5]])\n",
    "mlm_Y_hat = mlm(encoded_X, mlm_positions)\n",
    "mlm_Y_hat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Với nhãn gốc `mlm_Y` của token có mặt nạ được dự đoán `mlm_Y_hat`, ta có thể tính mất mát entropy chéo của tác vụ mô hình hóa ngôn ngữ có mặt nạ trong quá trình tiền huấn luyện BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlm_Y = torch.tensor([[7, 8, 9], [10, 20, 30]])\n",
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "mlm_l = loss(mlm_Y_hat.reshape((-1, vocab_size)), mlm_Y.reshape(-1))\n",
    "mlm_l.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.8.5.2. Dự đoán Câu tiếp theo\n",
    "Mặc dù mô hình hóa ngôn ngữ có mặt nạ có thể mã hóa ngữ cảnh hai chiều để biểu diễn từ ngữ, nó không thể mô hình hóa các mối quan hệ logic giữa các cặp văn bản một cách tường minh. Để hiểu hơn về mối quan hệ giữa hai chuỗi văn bản, BERT sử dụng tác vụ phân loại nhị phân, dự đoán câu tiếp theo (**next sentence prediction**) trong quá trình tiền huấn luyện. Khi sinh các cặp câu cho quá trình tiền huấn luyện, một nửa trong số đó là các cặp câu liên tiếp nhau trong thực tế và được gán nhãn “Đúng” (True); và trong nửa còn lại, câu thứ hai được lấy mẫu ngẫu nhiên từ kho ngữ liệu và cặp này được gán nhãn “Sai” (False).\n",
    "\n",
    "Lớp `NextSentencePred` dưới đây sử dụng MLP một tầng ẩn để dự đoán câu thứ hai có phải là câu kế tiếp của câu thứ nhất trong chuỗi đầu vào BERT hay không. Do cơ chế tự tập trung trong bộ mã hóa Transformer, biểu diễn BERT của token đặc biệt `“<cls>”` mã hóa cả hai câu đầu vào. Vì vậy, tầng đầu ra (`self.output`) của bộ phân loại MLP nhận đầu vào X là đầu ra của tầng ẩn MLP có đầu vào là token được mã hóa `“<cls>”`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class NextSentencePred(nn.Module):\n",
    "    def __init__(self, num_inputs, **kwargs):\n",
    "        super(NextSentencePred, self).__init__(**kwargs)\n",
    "        self.output = nn.Linear(num_inputs, 2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # `X` shape: (batch size, `num_hiddens`)\n",
    "        return self.output(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể thấy lượt suy luận xuôi của thực thể `NextSentencePred` trả về dự đoán nhị phân cho mỗi chuỗi đầu vào BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch by default won't flatten the tensor as seen in mxnet where, if\n",
    "# flatten=True, all but the first axis of input data are collapsed together\n",
    "encoded_X = torch.flatten(encoded_X, start_dim=1)\n",
    "# input_shape for NSP: (batch size, `num_hiddens`)\n",
    "nsp = NextSentencePred(encoded_X.shape[-1])\n",
    "nsp_Y_hat = nsp(encoded_X)\n",
    "nsp_Y_hat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mất mát entropy chéo của 2 tác vụ phân loại nhị phân có thể được tính như sau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsp_y = torch.tensor([0, 1])\n",
    "nsp_l = loss(nsp_Y_hat, nsp_y)\n",
    "nsp_l.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đáng chú ý là tất cả nhãn trong hai tác vụ tiền huấn luyện nói trên đều có thể thu được từ kho ngữ liệu tiền huấn luyện mà không cần công sức gán nhãn thủ công. Phiên bản gốc của BERT được tiền huấn luyện trên cả hai kho ngữ liệu BookCorpus [Zhu et al., 2015] và Wikipedia tiếng Anh. Hai kho ngữ liệu văn bản này cực kỳ lớn, chứa lần lượt khoảng 800 triệu từ và 2.5 tỉ từ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.8.6. Kết hợp Tất cả lại\n",
    "Khi tiền huấn luyện BERT, hàm mất mát cuối cùng là tổ hợp tuyến tính của cả hai hàm mất mát trong tác vụ mô hình hóa ngôn ngữ có mặt nạ và dự đoán câu tiếp theo. Bây giờ ta có thể định nghĩa lớp `BERTModel` bằng cách khởi tạo ba lớp `BERTEncoder`, `MaskLM`, và `NextSentencePred`. Lượt suy luận xuôi trả về biểu diễn BERT được mã hóa `encoded_X`, các dự đoán `mlm_Y_hat` của tác vụ mô hình hóa ngôn ngữ có mặt nạ, và `nsp_Y_hat` của tác vụ dự đoán câu tiếp theo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class BERTModel(nn.Module):\n",
    "    def __init__(self, vocab_size, num_hiddens, norm_shape, ffn_num_input,\n",
    "                 ffn_num_hiddens, num_heads, num_layers, dropout,\n",
    "                 max_len=1000, key_size=768, query_size=768, value_size=768,\n",
    "                 hid_in_features=768, mlm_in_features=768,\n",
    "                 nsp_in_features=768):\n",
    "        super(BERTModel, self).__init__()\n",
    "        self.encoder = BERTEncoder(vocab_size, num_hiddens, norm_shape,\n",
    "                                   ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                                   num_layers, dropout, max_len=max_len,\n",
    "                                   key_size=key_size, query_size=query_size,\n",
    "                                   value_size=value_size)\n",
    "        self.hidden = nn.Sequential(nn.Linear(hid_in_features, num_hiddens),\n",
    "                                    nn.Tanh())\n",
    "        self.mlm = MaskLM(vocab_size, num_hiddens, mlm_in_features)\n",
    "        self.nsp = NextSentencePred(nsp_in_features)\n",
    "\n",
    "    def forward(self, tokens, segments, valid_lens=None, pred_positions=None):\n",
    "        encoded_X = self.encoder(tokens, segments, valid_lens)\n",
    "        if pred_positions is not None:\n",
    "            mlm_Y_hat = self.mlm(encoded_X, pred_positions)\n",
    "        else:\n",
    "            mlm_Y_hat = None\n",
    "        # The hidden layer of the MLP classifier for next sentence prediction.\n",
    "        # 0 is the index of the '<cls>' token\n",
    "        nsp_Y_hat = self.nsp(self.hidden(encoded_X[:, 0, :]))\n",
    "        return encoded_X, mlm_Y_hat, nsp_Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.8.7. Tóm tắt\n",
    "- Các mô hình embedding từ như word2vec và GloVe có tính chất độc lập với ngữ cảnh. Hai mô hình này gán cùng một vector được tiền huấn luyện cho cùng một từ bất kể ngữ cảnh xung quanh của từ đó là gì (nếu có). Do đó, rất khó để các mô hình này xử lý tốt các trường hợp phức tạp về ngữ nghĩa hay đa nghĩa trong các ngôn ngữ tự nhiên.\n",
    "- Đối với các biểu diễn từ nhạy ngữ cảnh như ELMo và GPT, biểu diễn của từ phụ thuộc vào ngữ cảnh của từ đó.\n",
    "- ELMo mã hóa ngữ cảnh theo hai chiều nhưng sử dụng kiến ​​trúc đặc thù cho tác vụ (tuy nhiên, trên thực tế không dễ để tạo ra một kiến​​trúc đặc thù cho mọi tác vụ xử lý ngôn ngữ tự nhiên); trong khi đó GPT không phân biệt tác vụ nhưng chỉ mã hóa ngữ cảnh theo chiều từ trái sang phải.\n",
    "- BERT kết hợp những gì tốt nhất của cả hai mô hình trên: mã hóa ngữ cảnh theo hai chiều và chỉ yêu cầu những thay đổi kiến ​​trúc tối thiểu cho một loạt các tác vụ xử lý ngôn ngữ tự nhiên.\n",
    "- Các embedding của chuỗi đầu vào BERT là tổng các embedding cho token, embedding đoạn và embedding vị trí.\n",
    "- Quá trình tiền huấn luyện BERT gồm có hai tác vụ: tác vụ mô hình hóa ngôn ngữ có mặt nạ và tác vụ dự đoán câu tiếp theo. Tác vụ đầu có thể mã hóa ngữ cảnh hai chiều để biểu diễn từ, trong khi tác vụ sau mô hình hóa mối quan hệ logic giữa các cặp văn bản một cách tường minh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.8.8. Bài tập\n",
    "1. Tại sao BERT lại gặt hái được thành công?\n",
    "2. Giữ nguyên các yếu tố khác, liệu một mô hình ngôn ngữ có mặt nạ sẽ đòi hỏi số bước tiền huấn luyện nhiều hơn hay ít hơn để hội tụ so với mô hình ngôn ngữ từ trái sang phải. Tại sao?\n",
    "3. Trong mã nguồn gốc của BERT, mạng truyền xuôi theo vị trí (**position-wise feed-forward network**) trong `BERTEncoder` (thông qua `d2l.EncoderBlock`) và tầng kết nối đầy đủ trong `MaskLM` đều sử dụng Đơn vị lỗi tuyến tính Gauss (**Gaussian error linear unit (GELU)**) [Hendrycks & Gimpel, 2016] làm hàm kích họat. Hãy nghiên cứu sự khác biệt giữa GELU và ReLU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.9. Tập dữ liệu để Tiền huấn luyện BERT\n",
    "Để tiền huấn luyện mô hình BERT như thực hiện trong Section 14.8, ta cần sinh tập dữ liệu ở định dạng lý tưởng để thuận tiện cho hai tác vụ tiền huấn luyện: mô hình hóa ngôn ngữ có mặt nạ và dự đoán câu tiếp theo. Một mặt, mô hình BERT gốc được tiền huấn luyện trên kho ngữ liệu được ghép lại từ hai kho ngữ liệu khổng lồ là BookCorpus và Wikipedia Tiếng Anh (xem Section 14.8.5), khiến việc thực hành trở nên khó khăn đối với hầu hết độc giả của cuốn sách này. Mặt khác, mô hình BERT đã được tiền huấn luyện sẵn có thể không phù hợp với các ứng dụng ở một số lĩnh vực cụ thể như ngành dược. Do đó, việc tiền huấn luyện BERT trên một tập dữ liệu tùy chỉnh đang ngày càng trở nên phổ biến hơn. Để thuận tiện minh họa cho tiền huấn luyện BERT, ta sử dụng một kho ngữ liệu nhỏ hơn là WikiText-2 [Merity et al., 2016].\n",
    "\n",
    "So với tập dữ liệu PTB đã dùng để thực hiện tiền huấn luyện word2vec ở Section 14.3, WikiText-2 đã i) giữ lại dấu ngắt câu ban đầu, giúp nó phù hợp cho việc dự đoán câu kế tiếp; ii) giữ lại ký tự viết hoa và số; iii) và lớn hơn gấp hai lần."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong tập dữ liệu WikiText-2, mỗi dòng biểu diễn một đoạn văn. Dấu cách được chèn vào giữa bất cứ dấu ngắt câu nào và token đứng trước nó. Các đoạn văn có tối thiểu hai câu được giữ lại. Để tách các câu, ta chỉ sử dụng dấu chấm làm dấu phân cách cho đơn giản. Ta sẽ dành việc thảo luận về các kỹ thuật tách câu phức tạp hơn ở phần bài tập cuối mục."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "d2l.DATA_HUB['wikitext-2'] = (\n",
    "    'https://s3.amazonaws.com/research.metamind.io/wikitext/'\n",
    "    'wikitext-2-v1.zip', '3c914d17d80b1459be871a5039ac23e752a53cbe')\n",
    "\n",
    "#@save\n",
    "def _read_wiki(data_dir):\n",
    "    file_name = os.path.join(data_dir, 'wiki.train.tokens')\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    # Uppercase letters are converted to lowercase ones\n",
    "    paragraphs = [\n",
    "        line.strip().lower().split(' . ') for line in lines\n",
    "        if len(line.split(' . ')) >= 2]\n",
    "    random.shuffle(paragraphs)\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.9.1. Định nghĩa các Hàm trợ giúp cho các Tác vụ Tiền huấn luyện\n",
    "Ở phần này, ta sẽ bắt đầu lập trình các hàm hỗ trợ cho các hai tác vụ tiền huấn luyện BERT: dự đoán câu tiếp theo và mô hình hóa ngôn ngữ có mặt nạ. Các hàm hỗ trợ này sẽ được gọi khi thực hiện chuyển đổi các kho ngữ liệu văn bản thô sang tập dữ liệu có định dạng lý tưởng để tiền huấn luyện BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.9.1.1. Sinh tác vụ Dự đoán câu tiếp theo\n",
    "Dựa theo mô tả của Section 14.8.5.2, hàm `_get_next_sentence` sinh một mẫu để huấn luyện cho tác vụ phân loại nhị phân."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def _get_next_sentence(sentence, next_sentence, paragraphs):\n",
    "    if random.random() < 0.5:\n",
    "        is_next = True\n",
    "    else:\n",
    "        # `paragraphs` is a list of lists of lists\n",
    "        next_sentence = random.choice(random.choice(paragraphs))\n",
    "        is_next = False\n",
    "    return sentence, next_sentence, is_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm sau đây sinh các mẫu huấn luyện cho tác vụ dự đoán câu tiếp theo từ đầu vào `paragraph` thông qua hàm `_get_next_sentence`. `paragraph` ở đây là một danh sách các câu mà mỗi câu là một danh sách các token. Đối số `max_len` là chiều dài cực đại của chuỗi đầu vào BERT trong suốt quá trình tiền huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def _get_nsp_data_from_paragraph(paragraph, paragraphs, vocab, max_len):\n",
    "    nsp_data_from_paragraph = []\n",
    "    for i in range(len(paragraph) - 1):\n",
    "        tokens_a, tokens_b, is_next = _get_next_sentence(\n",
    "            paragraph[i], paragraph[i + 1], paragraphs)\n",
    "        # Consider 1 '<cls>' token and 2 '<sep>' tokens\n",
    "        if len(tokens_a) + len(tokens_b) + 3 > max_len:\n",
    "            continue\n",
    "        tokens, segments = d2l.get_tokens_and_segments(tokens_a, tokens_b)\n",
    "        nsp_data_from_paragraph.append((tokens, segments, is_next))\n",
    "    return nsp_data_from_paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.9.1.2. Tạo Tác vụ Mô hình hóa Ngôn ngữ có Mặt nạ\n",
    "Để tạo dữ liệu huấn luyện cho tác vụ mô hình hóa ngôn ngữ có mặt nạ từ một chuỗi đầu vào BERT, chúng ta cần định nghĩa hàm `_replace_mlm_tokens`. Đầu vào của nó, `tokens` là một danh sách các token biểu diễn cho một chuỗi đầu vào BERT, còn `candidate_pred_positions` là một danh sách chỉ số của các token của chuỗi đầu vào BERT ngoại trừ những token đặc biệt (token đặc biệt không được dự đoán trong tác vụ mô hình hóa ngôn ngữ có mặt nạ), và `num_mlm_preds` chỉ định số lượng token được dự đoán (nhớ lại rằng 15% token ngẫu nhiên được dự đoán). Dựa trên định nghĩa của tác vụ mô hình hóa ngôn ngữ có mặt nạ trong Section 14.8.5.1, tại mỗi vị trí dự đoán, đầu vào có thể bị thay thế bởi token đặc biệt `“<mask>”` hoặc một token ngẫu nhiên, hoặc không đổi. Cuối cùng, hàm này trả về những token đầu vào sau khi thực hiện thay thế (nếu có), những chỉ số token được dự đoán và nhãn cho những dự đoán này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def _replace_mlm_tokens(tokens, candidate_pred_positions, num_mlm_preds,\n",
    "                        vocab):\n",
    "    # Make a new copy of tokens for the input of a masked language model,\n",
    "    # where the input may contain replaced '<mask>' or random tokens\n",
    "    mlm_input_tokens = [token for token in tokens]\n",
    "    pred_positions_and_labels = []\n",
    "    # Shuffle for getting 15% random tokens for prediction in the masked\n",
    "    # language modeling task\n",
    "    random.shuffle(candidate_pred_positions)\n",
    "    for mlm_pred_position in candidate_pred_positions:\n",
    "        if len(pred_positions_and_labels) >= num_mlm_preds:\n",
    "            break\n",
    "        masked_token = None\n",
    "        # 80% of the time: replace the word with the '<mask>' token\n",
    "        if random.random() < 0.8:\n",
    "            masked_token = '<mask>'\n",
    "        else:\n",
    "            # 10% of the time: keep the word unchanged\n",
    "            if random.random() < 0.5:\n",
    "                masked_token = tokens[mlm_pred_position]\n",
    "            # 10% of the time: replace the word with a random word\n",
    "            else:\n",
    "                masked_token = random.randint(0, len(vocab) - 1)\n",
    "        mlm_input_tokens[mlm_pred_position] = masked_token\n",
    "        pred_positions_and_labels.append(\n",
    "            (mlm_pred_position, tokens[mlm_pred_position]))\n",
    "    return mlm_input_tokens, pred_positions_and_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bằng cách gọi hàm `_replace_mlm_tokens` ở trên, hàm dưới đây nhận một chuỗi đầu vào BERT (`tokens`) làm đầu vào và trả về chỉ số của những token đầu vào (sau khi thay thế token (nếu có) như mô tả ở Section 14.8.5.1), những chỉ số của token được dự đoán và chỉ số nhãn cho những dự đoán này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def _get_mlm_data_from_tokens(tokens, vocab):\n",
    "    candidate_pred_positions = []\n",
    "    # `tokens` is a list of strings\n",
    "    for i, token in enumerate(tokens):\n",
    "        # Special tokens are not predicted in the masked language modeling\n",
    "        # task\n",
    "        if token in ['<cls>', '<sep>']:\n",
    "            continue\n",
    "        candidate_pred_positions.append(i)\n",
    "    # 15% of random tokens are predicted in the masked language modeling task\n",
    "    num_mlm_preds = max(1, round(len(tokens) * 0.15))\n",
    "    mlm_input_tokens, pred_positions_and_labels = _replace_mlm_tokens(\n",
    "        tokens, candidate_pred_positions, num_mlm_preds, vocab)\n",
    "    pred_positions_and_labels = sorted(pred_positions_and_labels,\n",
    "                                       key=lambda x: x[0])\n",
    "    pred_positions = [v[0] for v in pred_positions_and_labels]\n",
    "    mlm_pred_labels = [v[1] for v in pred_positions_and_labels]\n",
    "    return vocab[mlm_input_tokens], pred_positions, vocab[mlm_pred_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.9.2. Biến đổi Văn bản thành bộ Dữ liệu Tiền huấn luyện\n",
    "Bây giờ chúng ta gần như đã sẵn sàng để tùy chỉnh một lớp `Dataset` cho việc tiền huấn luyện BERT. Trước đó, chúng ta vẫn cần định nghĩa một hàm hỗ trợ `_pad_bert_inputs` để giúp nối các token `“<mask>”` đặc biệt vào đầu vào. Đối số `examples` của hàm chứa các kết quả đầu ra từ những hàm hỗ trợ `_get_nsp_data_from_paragraph` và `_get_mlm_data_from_tokens` cho hai tác vụ tiền huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def _pad_bert_inputs(examples, max_len, vocab):\n",
    "    max_num_mlm_preds = round(max_len * 0.15)\n",
    "    all_token_ids, all_segments, valid_lens, = [], [], []\n",
    "    all_pred_positions, all_mlm_weights, all_mlm_labels = [], [], []\n",
    "    nsp_labels = []\n",
    "    for (token_ids, pred_positions, mlm_pred_label_ids, segments,\n",
    "         is_next) in examples:\n",
    "        all_token_ids.append(\n",
    "            torch.tensor(\n",
    "                token_ids + [vocab['<pad>']] * (max_len - len(token_ids)),\n",
    "                dtype=torch.long))\n",
    "        all_segments.append(\n",
    "            torch.tensor(segments + [0] * (max_len - len(segments)),\n",
    "                         dtype=torch.long))\n",
    "        # `valid_lens` excludes count of '<pad>' tokens\n",
    "        valid_lens.append(torch.tensor(len(token_ids), dtype=torch.float32))\n",
    "        all_pred_positions.append(\n",
    "            torch.tensor(\n",
    "                pred_positions + [0] *\n",
    "                (max_num_mlm_preds - len(pred_positions)), dtype=torch.long))\n",
    "        # Predictions of padded tokens will be filtered out in the loss via\n",
    "        # multiplication of 0 weights\n",
    "        all_mlm_weights.append(\n",
    "            torch.tensor([1.0] * len(mlm_pred_label_ids) + [0.0] *\n",
    "                         (max_num_mlm_preds - len(pred_positions)),\n",
    "                         dtype=torch.float32))\n",
    "        all_mlm_labels.append(\n",
    "            torch.tensor(\n",
    "                mlm_pred_label_ids + [0] *\n",
    "                (max_num_mlm_preds - len(mlm_pred_label_ids)),\n",
    "                dtype=torch.long))\n",
    "        nsp_labels.append(torch.tensor(is_next, dtype=torch.long))\n",
    "    return (all_token_ids, all_segments, valid_lens, all_pred_positions,\n",
    "            all_mlm_weights, all_mlm_labels, nsp_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết hợp những hàm hỗ trợ để tạo dữ liệu huấn luyện cho hai tác vụ tiền huấn luyện và hàm hỗ trợ đệm đầu vào, ta tùy chỉnh lớp `_WikiTextDataset` sau đây thành bộ dữ liệu WikiText-2 cho tiền huấn luyện BERT. Bằng cách lập trình hàm `__getitem__`, ta có thể tùy ý truy cập những mẫu dữ liệu tiền huấn luyện (mô hình hóa ngôn ngữ có mặt nạ và dự đoán câu tiếp theo) được tạo ra từ một cặp câu trong kho ngữ liệu WikiText-2.\n",
    "\n",
    "Mô hình BERT ban đầu sử dụng embedding WordPiece có kích thước bộ từ vựng là 30,000 [Wu et al., 2016]. Phương pháp tách token của WordPiece là một phiên bản của thuật toán mã hóa cặp byte ban đầu Section 14.6.2 với một chút chỉnh sửa. Để cho đơn giản, chúng tôi sử dụng hàm `d2l.tokenize` để tách từ. Những token xuất hiện ít hơn năm lần được loại bỏ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class _WikiTextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paragraphs, max_len):\n",
    "        # Input `paragraphs[i]` is a list of sentence strings representing a\n",
    "        # paragraph; while output `paragraphs[i]` is a list of sentences\n",
    "        # representing a paragraph, where each sentence is a list of tokens\n",
    "        paragraphs = [\n",
    "            d2l.tokenize(paragraph, token='word') for paragraph in paragraphs]\n",
    "        sentences = [\n",
    "            sentence for paragraph in paragraphs for sentence in paragraph]\n",
    "        self.vocab = d2l.Vocab(\n",
    "            sentences, min_freq=5,\n",
    "            reserved_tokens=['<pad>', '<mask>', '<cls>', '<sep>'])\n",
    "        # Get data for the next sentence prediction task\n",
    "        examples = []\n",
    "        for paragraph in paragraphs:\n",
    "            examples.extend(\n",
    "                _get_nsp_data_from_paragraph(paragraph, paragraphs,\n",
    "                                             self.vocab, max_len))\n",
    "        # Get data for the masked language model task\n",
    "        examples = [(_get_mlm_data_from_tokens(tokens, self.vocab) +\n",
    "                     (segments, is_next))\n",
    "                    for tokens, segments, is_next in examples]\n",
    "        # Pad inputs\n",
    "        (self.all_token_ids, self.all_segments, self.valid_lens,\n",
    "         self.all_pred_positions, self.all_mlm_weights, self.all_mlm_labels,\n",
    "         self.nsp_labels) = _pad_bert_inputs(examples, max_len, self.vocab)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.all_token_ids[idx], self.all_segments[idx],\n",
    "                self.valid_lens[idx], self.all_pred_positions[idx],\n",
    "                self.all_mlm_weights[idx], self.all_mlm_labels[idx],\n",
    "                self.nsp_labels[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bằng cách sử dụng hàm `_read_wiki` và lớp `_WikiTextDataset`, ta định nghĩa hàm `load_data_wiki` dưới đây để tải xuống bộ dữ liệu WikiText-2 và tạo mẫu dữ liệu tiền huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def load_data_wiki(batch_size, max_len):\n",
    "    num_workers = d2l.get_dataloader_workers()\n",
    "    data_dir = d2l.download_extract('wikitext-2', 'wikitext-2')\n",
    "    paragraphs = _read_wiki(data_dir)\n",
    "    train_set = _WikiTextDataset(paragraphs, max_len)\n",
    "    train_iter = torch.utils.data.DataLoader(train_set, batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=num_workers)\n",
    "    return train_iter, train_set.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đặt kích thước batch là 512 và chiều dài tối đa của chuỗi đầu vào BERT là 64, ta in ra kích thước một minibatch dữ liệu tiền huấn luyện. Lưu ý rằng trong mỗi chuỗi đầu vào BERT,  $10  ( 64×0.15 )$ vị trí được dự đoán đối với tác vụ mô hình hóa ngôn ngữ có mặt nạ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, max_len = 512, 64\n",
    "train_iter, vocab = load_data_wiki(batch_size, max_len)\n",
    "\n",
    "for (tokens_X, segments_X, valid_lens_x, pred_positions_X, mlm_weights_X,\n",
    "     mlm_Y, nsp_y) in train_iter:\n",
    "    print(tokens_X.shape, segments_X.shape, valid_lens_x.shape,\n",
    "          pred_positions_X.shape, mlm_weights_X.shape, mlm_Y.shape,\n",
    "          nsp_y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuối cùng, hãy nhìn vào kích thước của bộ từ vựng. Mặc dù những token ít xuất hiện đã bị loại bỏ, kích thước của nó vẫn lớn gấp đôi bộ dữ liệu PTB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.9.3. Tóm tắt\n",
    "- So sánh với tập dữ liệu PTB, tập dữ liệu WikiText-2 vẫn giữ nguyên dấu câu, chữ viết hoa và ký tự số, có kích thước lớn hơn gấp đôi.\n",
    "- Ta có thể tùy ý truy cập vào các mẫu tiền huấn luyện (tác vụ mô hình hoá ngôn ngữ có mặt nạ và dự đoán câu tiếp theo) được sinh ra từ một cặp câu trong kho ngữ liệu WikiText-2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.9.4. Bài tập\n",
    "1. Để đơn giản, dấu chấm được dùng làm dấu phân cách duy nhất để tách các câu. Hãy thử các kỹ thuật tách câu khác, ví dụ như công cụ spaCy và NLTK. Lấy NLTK làm ví dụ. Bạn cần cài đặt NLTK trước: `pip install nltk`. Trong mã nguồn, đầu tiên hãy `import nltk`. Sau đó, tải xuống bộ token hoá câu Punkt (**Punkt sentence tokenizer**): `nltk.download('punkt')`. Để tách các câu, ví dụ `sentences = 'This is great ! Why not ?'`, việc gọi `nltk.tokenize.sent_tokenize(sentences)` sẽ trả về một danh sách gồm hai chuỗi câu là `['This is great !', 'Why not ?']`.\n",
    "2. Nếu ta không lọc ra những token ít gặp thì kích thước bộ từ vựng là bao nhiêu?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.10. Tiền Huấn luyện BERT\n",
    "Trong phần này, sử dụng mô hình BERT đã được lập trình trong Section 14.8 và các mẫu dữ liệu tiền huấn luyện được tạo ra từ tập dữ liệu WikiText-2 trong Section 14.9, ta sẽ tiền huấn luyện BERT trên tập dữ liệu này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Đầu tiên, ta nạp các mẫu dữ liệu của tập dữ liệu WikiText-2 thành các minibatch cho quá trình tiền huấn luyện hai tác vụ: mô hình hóa ngôn ngữ có mặt nạ và dự đoán câu tiếp theo. Kích thước batch là 512 và độ dài tối đa của chuỗi đầu vào BERT là 64. Lưu ý rằng trong mô hình BERT gốc, độ dài tối đa này là 512."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, max_len = 512, 64\n",
    "train_iter, vocab = d2l.load_data_wiki(batch_size, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.10.1. Tiền Huấn luyện BERT\n",
    "Mô hình BERT gốc có hai phiên bản với hai kích thước mô hình khác nhau [Devlin et al., 2018]. Mô hình cơ bản ( $BERT_{BASE}$ ) sử dụng 12 tầng (khối mã hóa của Transformer) với 768 nút ẩn (kích thước ẩn) và tầng tự tập trung 12 đầu. Mô hình lớn ( $BERT_{LARGE}$ ) sử dụng 24 tầng với 1024 nút ẩn và tầng tự tập trung 16 đầu. Đáng chú ý là tổng số lượng tham số trong mô hình đầu tiên là 110 triệu, còn ở mô hình thứ hai là 340 triệu. Để minh họa thì ta định nghĩa mô hình BERT nhỏ dưới đây, sử dụng 2 tầng với 128 nút ẩn và tầng tự tập trung 2 đầu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = d2l.BERTModel(len(vocab), num_hiddens=128, norm_shape=[128],\n",
    "                    ffn_num_input=128, ffn_num_hiddens=256, num_heads=2,\n",
    "                    num_layers=2, dropout=0.2, key_size=128, query_size=128,\n",
    "                    value_size=128, hid_in_features=128, mlm_in_features=128,\n",
    "                    nsp_in_features=128)\n",
    "devices = d2l.try_all_gpus()\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta sẽ định nghĩa hàm hỗ trợ `_get_batch_loss_bert` trước khi bắt đầu lập trình vòng lặp cho quá trình huấn luyện. Hàm này nhận đầu vào là một batch các mẫu huấn luyện và tính giá trị mất mát đối với hai tác vụ mô hình hóa ngôn ngữ có mặt nạ và dự đoán câu tiếp theo. Lưu ý rằng mất mát cuối cùng của tác vụ tiền huấn luyện BERT chỉ là tổng mất mát của cả hai tác vụ nói trên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def _get_batch_loss_bert(net, loss, vocab_size, tokens_X, segments_X,\n",
    "                         valid_lens_x, pred_positions_X, mlm_weights_X, mlm_Y,\n",
    "                         nsp_y):\n",
    "    # Forward pass\n",
    "    _, mlm_Y_hat, nsp_Y_hat = net(tokens_X, segments_X,\n",
    "                                  valid_lens_x.reshape(-1), pred_positions_X)\n",
    "    # Compute masked language model loss\n",
    "    mlm_l = loss(mlm_Y_hat.reshape(-1, vocab_size), mlm_Y.reshape(-1)) *\\\n",
    "    mlm_weights_X.reshape(-1, 1)\n",
    "    mlm_l = mlm_l.sum() / (mlm_weights_X.sum() + 1e-8)\n",
    "    # Compute next sentence prediction loss\n",
    "    nsp_l = loss(nsp_Y_hat, nsp_y)\n",
    "    l = mlm_l + nsp_l\n",
    "    return mlm_l, nsp_l, l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sử dụng hai hàm hỗ trợ được đề cập ở trên, hàm `train_bert` dưới đây sẽ định nghĩa quá trình tiền huấn luyện BERT (net) trên tập dữ liệu WikiText-2 (`train_iter`). Việc huấn luyện BERT có thể mất rất nhiều thời gian. Do đó, thay vì truyền vào số lượng epoch huấn luyện như trong hàm `train_ch13` (Section 13.1), ta sử dụng tham số `num_steps` trong hàm sau để xác định số vòng lặp huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bert(train_iter, net, loss, vocab_size, devices, num_steps):\n",
    "    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "    trainer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "    step, timer = 0, d2l.Timer()\n",
    "    animator = d2l.Animator(xlabel='step', ylabel='loss', xlim=[1, num_steps],\n",
    "                            legend=['mlm', 'nsp'])\n",
    "    # Sum of masked language modeling losses, sum of next sentence prediction\n",
    "    # losses, no. of sentence pairs, count\n",
    "    metric = d2l.Accumulator(4)\n",
    "    num_steps_reached = False\n",
    "    while step < num_steps and not num_steps_reached:\n",
    "        for tokens_X, segments_X, valid_lens_x, pred_positions_X,\\\n",
    "            mlm_weights_X, mlm_Y, nsp_y in train_iter:\n",
    "            tokens_X = tokens_X.to(devices[0])\n",
    "            segments_X = segments_X.to(devices[0])\n",
    "            valid_lens_x = valid_lens_x.to(devices[0])\n",
    "            pred_positions_X = pred_positions_X.to(devices[0])\n",
    "            mlm_weights_X = mlm_weights_X.to(devices[0])\n",
    "            mlm_Y, nsp_y = mlm_Y.to(devices[0]), nsp_y.to(devices[0])\n",
    "            trainer.zero_grad()\n",
    "            timer.start()\n",
    "            mlm_l, nsp_l, l = _get_batch_loss_bert(\n",
    "                net, loss, vocab_size, tokens_X, segments_X, valid_lens_x,\n",
    "                pred_positions_X, mlm_weights_X, mlm_Y, nsp_y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            metric.add(mlm_l, nsp_l, tokens_X.shape[0], 1)\n",
    "            timer.stop()\n",
    "            animator.add(step + 1,\n",
    "                         (metric[0] / metric[3], metric[1] / metric[3]))\n",
    "            step += 1\n",
    "            if step == num_steps:\n",
    "                num_steps_reached = True\n",
    "                break\n",
    "\n",
    "    print(f'MLM loss {metric[0] / metric[3]:.3f}, '\n",
    "          f'NSP loss {metric[1] / metric[3]:.3f}')\n",
    "    print(f'{metric[2] / timer.sum():.1f} sentence pairs/sec on '\n",
    "          f'{str(devices)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể vẽ đồ thị hàm mất mát ứng với hai tác vụ mô hình hóa ngôn ngữ có mặt nạ và dự đoán câu tiếp theo trong quá trình tiền huấn luyện BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bert(train_iter, net, loss, len(vocab), devices, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.10.2. Biểu diễn Văn bản với BERT\n",
    "Ta có thể sử dụng mô hình BERT đã tiền huấn luyện để biểu diễn một văn bản đơn, cặp văn bản hay một token bất kỳ trong văn bản. Hàm sau sẽ trả về biểu diễn của mô hình BERT (`net`) cho toàn bộ các token trong `tokens_a` và `tokens_b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_encoding(net, tokens_a, tokens_b=None):\n",
    "    tokens, segments = d2l.get_tokens_and_segments(tokens_a, tokens_b)\n",
    "    token_ids = torch.tensor(vocab[tokens], device=devices[0]).unsqueeze(0)\n",
    "    segments = torch.tensor(segments, device=devices[0]).unsqueeze(0)\n",
    "    valid_len = torch.tensor(len(tokens), device=devices[0]).unsqueeze(0)\n",
    "    encoded_X, _, _ = net(token_ids, segments, valid_len)\n",
    "    return encoded_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xét câu `“a crane is flying”`. Hãy nhớ lại biểu diễn đầu vào của BERT được thảo luận trong Section 14.8.4, sau khi thêm các token đặc biệt `“<cls>”` (dùng cho phân loại) và `“<sep>”` (dùng để ngăn cách), chiều dài của chuỗi đầu vào BERT là 6. Vì 0 là chỉ số của token `“<cls>”`, `encoded_text[:, 0, :]` là biểu diễn BERT của toàn bộ câu đầu vào. Để đánh giá token đa nghĩa `“crane”`, ta sẽ in cả ba phần tử đầu tiên trong biểu diễn BERT của token này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_a = ['a', 'crane', 'is', 'flying']\n",
    "encoded_text = get_bert_encoding(net, tokens_a)\n",
    "# Tokens: '<cls>', 'a', 'crane', 'is', 'flying', '<sep>'\n",
    "encoded_text_cls = encoded_text[:, 0, :]\n",
    "encoded_text_crane = encoded_text[:, 2, :]\n",
    "encoded_text.shape, encoded_text_cls.shape, encoded_text_crane[0][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ, ta sẽ xem xét cặp câu `“a crane driver came”` và `“he just left”`. Tương tự như trên, `encoded_pair[:, 0, :]` là kết quả mã hóa của cặp câu này thông qua BERT đã được tiền huấn luyện. Lưu ý rằng khi token đa nghĩa `“crane”` xuất hiện trong ngữ cảnh khác nhau, ba phần tử đầu tiên trong biểu diễn BERT token này cũng thay đổi. Điều này thể hiện rằng biểu diễn BERT có tính nhạy ngữ cảnh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_a, tokens_b = ['a', 'crane', 'driver', 'came'], ['he', 'just', 'left']\n",
    "encoded_pair = get_bert_encoding(net, tokens_a, tokens_b)\n",
    "# Tokens: '<cls>', 'a', 'crane', 'driver', 'came', '<sep>', 'he', 'just',\n",
    "# 'left', '<sep>'\n",
    "encoded_pair_cls = encoded_pair[:, 0, :]\n",
    "encoded_pair_crane = encoded_pair[:, 2, :]\n",
    "encoded_pair.shape, encoded_pair_cls.shape, encoded_pair_crane[0][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ở Section 15, ta sẽ tinh chỉnh mô hình BERT đã được tiền huấn luyện với một số tác vụ xuôi dòng trong xử lý ngôn ngữ tự nhiên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.10.3. Tóm tắt\n",
    "- Mô hình BERT gốc có hai phiên bản, trong đó mô hình cơ bản có 110 triệu tham số và mô hình lớn có 340 triệu tham số.\n",
    "- Ta có thể sử dụng mô hình BERT đã được tiền huấn luyện để biểu diễn một văn bản đơn, cặp văn bản hay một token bất kỳ.\n",
    "- Trong thí nghiệm trên, ta đã thấy rằng cùng một token có thể có nhiều cách biểu diễn khác nhau với những ngữ cảnh khác nhau. Điều này thể hiện rằng biểu diễn BERT có tính nhạy ngữ cảnh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.10.4. Bài tập\n",
    "1. Kết quả thí nghiệm trên cho thấy mất mát ứng với tác vụ mô hình hóa ngôn ngữ có mặt nạ cao hơn đáng kể so với tác vụ dự đoán câu tiếp theo. Hãy giải thích hiện tượng này.\n",
    "2. Thay đổi chiều dài tối đa của chuỗi đầu vào BERT thành 512 (giống với mô hình BERT gốc) và sử dụng cấu hình của mô hình BERT gốc như là  $BERT_{LARGE}$ . Bạn có gặp lỗi khi chạy lại thí nghiệm không? Giải thích tại sao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
