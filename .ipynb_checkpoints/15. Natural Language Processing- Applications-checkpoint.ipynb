{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. Xử lý Ngôn ngữ Tự nhiên: Ứng dụng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ở Section 14, chúng ta đã nhìn thấy cách biểu diễn token văn bản và huấn luyện các biểu diễn của chúng. Những biểu diễn văn bản được tiền huấn luyện như vậy có thể được truyền vào các mô hình cho các tác vụ xử lý ngôn ngữ tự nhiên xuôi dòng khác nhau.\n",
    "\n",
    "Cuốn sách này không có ý định trình bày các ứng dụng xử lý ngôn ngữ tự nhiên một cách toàn diện. Trọng tâm của cuốn sách là *làm sao để áp dụng học biểu diễn (sâu) của ngôn ngữ nhằm giải quyết các bài toán xử lý ngôn ngữ tự nhiên*. Tuy nhiên, chúng ta đã thảo luận về một số ứng dụng xử lý ngôn ngữ tự nhiên mà không cần tiền huấn luyện trong các chương trước, nhằm chỉ giải thích các kiến trúc học sâu. Như trong Section 8, chúng ta đã thiết kế các mô hình ngôn ngữ dựa trên RNN để sinh ra các văn bản có nội dung giống như tiểu thuyết. Trong Section 9 và Section 10, ta cũng đã thiết kế các mô hình ngôn ngữ dựa trên RNN và các cơ chế tập trung cho tác vụ dịch máy. Trong chương này, với những biểu diễn văn bản được tiền huấn luyện thì ta sẽ xem xét hai tác vụ xử lý ngôn ngữ tự nhiên xuôi dòng khác đó là, phân tích cảm xúc (**sentiment analysis**) và suy luận ngôn ngữ tự nhiên (**natural language inference**). Đây là những ứng dụng xử lý ngôn ngữ tự nhiên mang tính phổ biến và đại diện: ứng dụng trước phân tích văn bản đơn lẻ trong khi ứng dụng sau phân tích mối quan hệ của các cặp văn bản.\n",
    "\n",
    "![](images/nlp-map-app.svg)\n",
    "\n",
    "Fig. 15.1 Biểu diễn văn bản được tiền huấn luyện có thể được truyền vào các kiến trúc học sâu cho các ứng dụng xử lý ngôn ngữ tự nhiên xuôi dòng khác nhau. Chương này sẽ tập trung vào cách thiết kế mô hình cho các ứng dụng khác nhau đó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như được mô tả trong Fig. 15.1, chương này sẽ tập trung vào việc mô tả các ý tưởng cơ bản trong thiết kế các mô hình xử lý ngôn ngữ tự nhiên sử dụng các loại kiến ​​trúc học sâu khác nhau, chẳng hạn như MLP, CNN, RNN và cơ chế tập trung. Mặc dù có thể kết hợp bất kỳ biểu diễn văn bản được tiền huấn luyện với bất kỳ kiến ​​trúc nào cho các tác vụ xử lý ngôn ngữ tự nhiên xuôi dòng trong Fig. 15.1, nhưng ta chỉ chọn một vài kết hợp đại diện mà thôi. Cụ thể, chúng ta sẽ khám phá các kiến ​​trúc phổ biến dựa trên RNN và CNN để phân tích cảm xúc. Đối với suy luận ngôn ngữ tự nhiên, ta sẽ chọn cơ chế tập trung và MLP để minh họa cách phân tích quan hệ giữa các cặp văn bản. Cuối cùng, ta sẽ giới thiệu cách tinh chỉnh mô hình BERT được tiền huấn luyện cho một loạt các ứng dụng xử lý ngôn ngữ tự nhiên, ví dụ như các tác vụ cấp chuỗi (phân loại đơn văn bản và phân loại cặp văn bản) và cấp token (gắn thẻ văn bản và trả lời câu hỏi). Chúng ta sẽ tinh chỉnh BERT để xử lý ngôn ngữ tự nhiên như một thực nghiệm cụ thể.\n",
    "\n",
    "Như đã giới thiệu trong Section 14.8, BERT chỉ yêu cầu các thay đổi kiến trúc tối thiểu cho một loạt các ứng dụng xử lý ngôn ngữ tự nhiên. Tuy nhiên, lợi ích này đi kèm với chi phí phải tinh chỉnh một số lượng lớn các tham số mô hình BERT cho các ứng dụng xuôi dòng. Khi độ phức tạp về không gian hoặc thời gian bị giới hạn, những mô hình được thiết kế thủ công dựa trên MLP, CNN, RNN và cơ chế tập trung sẽ khả thi hơn. Trong phần sau, ta sẽ bắt đầu bằng ứng dụng phân tích cảm xúc và minh họa thiết kế mô hình dựa trên kiến trúc RNN và CNN tương ứng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.1. Tác vụ Phân tích Cảm xúc và Bộ Dữ liệu\n",
    "Phân loại văn bản là một tác vụ phổ biến trong xử lý ngôn ngữ tự nhiên, ánh xạ chuỗi văn bản có độ dài không cố định tới một hạng mục tương ứng. Tác vụ này khá giống với phân loại ảnh, vốn là ứng dụng phổ biến nhất được giới thiệu trong cuốn sách này, ví dụ, Section 18.9. Điểm khác biệt duy nhất đó là, mẫu đầu vào của tác vụ phân loại là một câu văn bản thay vì một bức ảnh.\n",
    "\n",
    "Phần này sẽ tập trung vào việc nạp dữ liệu cho một trong số những câu hỏi của bài toán này: sử dụng tác vụ phân loại cảm xúc văn bản để phân tích cảm xúc của người viết. Bài toán này cũng có thể gọi là phân tích cảm xúc (sắc thái) và có rất nhiều ứng dụng. Ví dụ, ta có thể phân tích đánh giá của khách hàng về sản phẩm để thu được thống kê độ hài lòng, hoặc phân tích cảm xúc của khách hàng về điều kiện thị trường và sử dụng kết quả này để dự đoán xu hướng tương lai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.1.1. Bộ Dữ liệu Phân tích Cảm xúc\n",
    "Ta sử dụng tập dữ liệu lớn về đánh giá phim ảnh ([Large Movie Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment/)) của Stanford làm dữ liệu cho tác vụ phân tích cảm xúc. Tập dữ liệu này được chia thành hai tập huấn luyện và kiểm tra, mỗi tập chứa 25,000 đánh giá phim tải về từ IMDb. Trong mỗi tập dữ liệu, số lượng đánh giá có nhãn “tích cực” (positive) và “tiêu cực” (negative) là bằng nhau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.1.1.1. Đọc Dữ liệu\n",
    "Đầu tiên, ta tải dữ liệu về thư mục “../data” và giải nén dữ liệu vào thư mục “../data/aclImdb”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ..\\data\\aclImdb_v1.tar.gz from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz...\n"
     ]
    }
   ],
   "source": [
    "#@save\n",
    "d2l.DATA_HUB['aclImdb'] = (\n",
    "    'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz',\n",
    "    '01ada507287d82875905620988597833ad4e0903')\n",
    "\n",
    "data_dir = d2l.download_extract('aclImdb', 'aclImdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo, ta đọc dữ liệu huấn luyện và dữ liệu kiểm tra. Mỗi mẫu là một bình luận đánh giá cùng với nhãn tương ứng: 1 cho “**tích cực**”, và 0 cho “**tiêu cực**”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# trainings: 25000\n",
      "label: 1 review: Bromwell High is a cartoon comedy. It ran at the same time a\n",
      "label: 1 review: Homelessness (or Houselessness as George Carlin stated) has \n",
      "label: 1 review: Brilliant over-acting by Lesley Ann Warren. Best dramatic ho\n"
     ]
    }
   ],
   "source": [
    "#@save\n",
    "def read_imdb(data_dir, is_train):\n",
    "    data, labels = [], []\n",
    "    for label in ('pos', 'neg'):\n",
    "        folder_name = os.path.join(data_dir, 'train' if is_train else 'test',\n",
    "                                   label)\n",
    "        for file in os.listdir(folder_name):\n",
    "            with open(os.path.join(folder_name, file), 'rb') as f:\n",
    "                review = f.read().decode('utf-8').replace('\\n', '')\n",
    "                data.append(review)\n",
    "                labels.append(1 if label == 'pos' else 0)\n",
    "    return data, labels\n",
    "\n",
    "train_data = read_imdb(data_dir, is_train=True)\n",
    "print('# trainings:', len(train_data[0]))\n",
    "for x, y in zip(train_data[0][:3], train_data[1][:3]):\n",
    "    print('label:', y, 'review:', x[0:60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.1.1.2. Token hoá và Bộ từ vựng\n",
    "Ta coi mỗi từ là một token, và tạo một từ điển dựa trên tập dữ liệu huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n",
       "<svg height=\"166.978125pt\" version=\"1.1\" viewBox=\"0 0 242.15 166.978125\" width=\"242.15pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       " <metadata>\r\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n",
       "   <cc:Work>\r\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n",
       "    <dc:date>2021-05-14T21:03:40.838259</dc:date>\r\n",
       "    <dc:format>image/svg+xml</dc:format>\r\n",
       "    <dc:creator>\r\n",
       "     <cc:Agent>\r\n",
       "      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n",
       "     </cc:Agent>\r\n",
       "    </dc:creator>\r\n",
       "   </cc:Work>\r\n",
       "  </rdf:RDF>\r\n",
       " </metadata>\r\n",
       " <defs>\r\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n",
       " </defs>\r\n",
       " <g id=\"figure_1\">\r\n",
       "  <g id=\"patch_1\">\r\n",
       "   <path d=\"M 0 166.978125 \r\n",
       "L 242.15 166.978125 \r\n",
       "L 242.15 0 \r\n",
       "L 0 0 \r\n",
       "z\r\n",
       "\" style=\"fill:none;\"/>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_1\">\r\n",
       "   <g id=\"patch_2\">\r\n",
       "    <path d=\"M 39.65 143.1 \r\n",
       "L 234.95 143.1 \r\n",
       "L 234.95 7.2 \r\n",
       "L 39.65 7.2 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_3\">\r\n",
       "    <path clip-path=\"url(#pc81d276a8b)\" d=\"M 48.527273 143.1 \r\n",
       "L 57.87177 143.1 \r\n",
       "L 57.87177 132.605279 \r\n",
       "L 48.527273 132.605279 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_4\">\r\n",
       "    <path clip-path=\"url(#pc81d276a8b)\" d=\"M 57.87177 143.1 \r\n",
       "L 67.216268 143.1 \r\n",
       "L 67.216268 98.065689 \r\n",
       "L 57.87177 98.065689 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_5\">\r\n",
       "    <path clip-path=\"url(#pc81d276a8b)\" d=\"M 67.216268 143.1 \r\n",
       "L 76.560766 143.1 \r\n",
       "L 76.560766 13.671429 \r\n",
       "L 67.216268 13.671429 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_6\">\r\n",
       "    <path clip-path=\"url(#pc81d276a8b)\" d=\"M 76.560766 143.1 \r\n",
       "L 85.905263 143.1 \r\n",
       "L 85.905263 51.361332 \r\n",
       "L 76.560766 51.361332 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_7\">\r\n",
       "    <path clip-path=\"url(#pc81d276a8b)\" d=\"M 85.905263 143.1 \r\n",
       "L 95.249761 143.1 \r\n",
       "L 95.249761 89.639548 \r\n",
       "L 85.905263 89.639548 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_8\">\r\n",
       "    <path clip-path=\"url(#pc81d276a8b)\" d=\"M 95.249761 143.1 \r\n",
       "L 104.594258 143.1 \r\n",
       "L 104.594258 108.029032 \r\n",
       "L 95.249761 108.029032 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_9\">\r\n",
       "    <path clip-path=\"url(#pc81d276a8b)\" d=\"M 104.594258 143.1 \r\n",
       "L 113.938756 143.1 \r\n",
       "L 113.938756 116.910641 \r\n",
       "L 104.594258 116.910641 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_10\">\r\n",
       "    <path clip-path=\"url(#pc81d276a8b)\" d=\"M 113.938756 143.1 \r\n",
       "L 123.283254 143.1 \r\n",
       "L 123.283254 124.027315 \r\n",
       "L 113.938756 124.027315 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_11\">\r\n",
       "    <path clip-path=\"url(#pc81d276a8b)\" d=\"M 123.283254 143.1 \r\n",
       "L 132.627751 143.1 \r\n",
       "L 132.627751 128.695853 \r\n",
       "L 123.283254 128.695853 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_12\">\r\n",
       "    <path clip-path=\"url(#pc81d276a8b)\" d=\"M 132.627751 143.1 \r\n",
       "L 141.972249 143.1 \r\n",
       "L 141.972249 132.0739 \r\n",
       "L 132.627751 132.0739 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_13\">\r\n",
       "    <path clip-path=\"url(#pc81d276a8b)\" d=\"M 141.972249 143.1 \r\n",
       "L 151.316746 143.1 \r\n",
       "L 151.316746 134.806703 \r\n",
       "L 141.972249 134.806703 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_14\">\r\n",
       "    <path clip-path=\"url(#pc81d276a8b)\" d=\"M 151.316746 143.1 \r\n",
       "L 160.661244 143.1 \r\n",
       "L 160.661244 136.476749 \r\n",
       "L 151.316746 136.476749 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_15\">\r\n",
       "    <path clip-path=\"url(#pc81d276a8b)\" d=\"M 160.661244 143.1 \r\n",
       "L 170.005742 143.1 \r\n",
       "L 170.005742 138.222706 \r\n",
       "L 160.661244 138.222706 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_16\">\r\n",
       "    <path clip-path=\"url(#pc81d276a8b)\" d=\"M 170.005742 143.1 \r\n",
       "L 179.350239 143.1 \r\n",
       "L 179.350239 139.171596 \r\n",
       "L 170.005742 139.171596 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_17\">\r\n",
       "    <path clip-path=\"url(#pc81d276a8b)\" d=\"M 179.350239 143.1 \r\n",
       "L 188.694737 143.1 \r\n",
       "L 188.694737 139.797863 \r\n",
       "L 179.350239 139.797863 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_18\">\r\n",
       "    <path clip-path=\"url(#pc81d276a8b)\" d=\"M 188.694737 143.1 \r\n",
       "L 198.039234 143.1 \r\n",
       "L 198.039234 140.575953 \r\n",
       "L 188.694737 140.575953 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_19\">\r\n",
       "    <path clip-path=\"url(#pc81d276a8b)\" d=\"M 198.039234 143.1 \r\n",
       "L 207.383732 143.1 \r\n",
       "L 207.383732 140.898576 \r\n",
       "L 198.039234 140.898576 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_20\">\r\n",
       "    <path clip-path=\"url(#pc81d276a8b)\" d=\"M 207.383732 143.1 \r\n",
       "L 216.72823 143.1 \r\n",
       "L 216.72823 141.486887 \r\n",
       "L 207.383732 141.486887 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_21\">\r\n",
       "    <path clip-path=\"url(#pc81d276a8b)\" d=\"M 216.72823 143.1 \r\n",
       "L 226.072727 143.1 \r\n",
       "L 226.072727 141.676665 \r\n",
       "L 216.72823 141.676665 \r\n",
       "z\r\n",
       "\" style=\"fill:#1f77b4;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_1\">\r\n",
       "    <g id=\"xtick_1\">\r\n",
       "     <g id=\"line2d_1\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 0 3.5 \r\n",
       "\" id=\"m0b446c64ad\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"48.527273\" xlink:href=\"#m0b446c64ad\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_1\">\r\n",
       "      <!-- 0 -->\r\n",
       "      <g transform=\"translate(45.346023 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 31.78125 66.40625 \r\n",
       "Q 24.171875 66.40625 20.328125 58.90625 \r\n",
       "Q 16.5 51.421875 16.5 36.375 \r\n",
       "Q 16.5 21.390625 20.328125 13.890625 \r\n",
       "Q 24.171875 6.390625 31.78125 6.390625 \r\n",
       "Q 39.453125 6.390625 43.28125 13.890625 \r\n",
       "Q 47.125 21.390625 47.125 36.375 \r\n",
       "Q 47.125 51.421875 43.28125 58.90625 \r\n",
       "Q 39.453125 66.40625 31.78125 66.40625 \r\n",
       "z\r\n",
       "M 31.78125 74.21875 \r\n",
       "Q 44.046875 74.21875 50.515625 64.515625 \r\n",
       "Q 56.984375 54.828125 56.984375 36.375 \r\n",
       "Q 56.984375 17.96875 50.515625 8.265625 \r\n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \r\n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \r\n",
       "Q 6.59375 17.96875 6.59375 36.375 \r\n",
       "Q 6.59375 54.828125 13.0625 64.515625 \r\n",
       "Q 19.53125 74.21875 31.78125 74.21875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-48\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_2\">\r\n",
       "     <g id=\"line2d_2\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"85.905263\" xlink:href=\"#m0b446c64ad\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_2\">\r\n",
       "      <!-- 200 -->\r\n",
       "      <g transform=\"translate(76.361513 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 19.1875 8.296875 \r\n",
       "L 53.609375 8.296875 \r\n",
       "L 53.609375 0 \r\n",
       "L 7.328125 0 \r\n",
       "L 7.328125 8.296875 \r\n",
       "Q 12.9375 14.109375 22.625 23.890625 \r\n",
       "Q 32.328125 33.6875 34.8125 36.53125 \r\n",
       "Q 39.546875 41.84375 41.421875 45.53125 \r\n",
       "Q 43.3125 49.21875 43.3125 52.78125 \r\n",
       "Q 43.3125 58.59375 39.234375 62.25 \r\n",
       "Q 35.15625 65.921875 28.609375 65.921875 \r\n",
       "Q 23.96875 65.921875 18.8125 64.3125 \r\n",
       "Q 13.671875 62.703125 7.8125 59.421875 \r\n",
       "L 7.8125 69.390625 \r\n",
       "Q 13.765625 71.78125 18.9375 73 \r\n",
       "Q 24.125 74.21875 28.421875 74.21875 \r\n",
       "Q 39.75 74.21875 46.484375 68.546875 \r\n",
       "Q 53.21875 62.890625 53.21875 53.421875 \r\n",
       "Q 53.21875 48.921875 51.53125 44.890625 \r\n",
       "Q 49.859375 40.875 45.40625 35.40625 \r\n",
       "Q 44.1875 33.984375 37.640625 27.21875 \r\n",
       "Q 31.109375 20.453125 19.1875 8.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-50\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_3\">\r\n",
       "     <g id=\"line2d_3\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"123.283254\" xlink:href=\"#m0b446c64ad\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_3\">\r\n",
       "      <!-- 400 -->\r\n",
       "      <g transform=\"translate(113.739504 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 37.796875 64.3125 \r\n",
       "L 12.890625 25.390625 \r\n",
       "L 37.796875 25.390625 \r\n",
       "z\r\n",
       "M 35.203125 72.90625 \r\n",
       "L 47.609375 72.90625 \r\n",
       "L 47.609375 25.390625 \r\n",
       "L 58.015625 25.390625 \r\n",
       "L 58.015625 17.1875 \r\n",
       "L 47.609375 17.1875 \r\n",
       "L 47.609375 0 \r\n",
       "L 37.796875 0 \r\n",
       "L 37.796875 17.1875 \r\n",
       "L 4.890625 17.1875 \r\n",
       "L 4.890625 26.703125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-52\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_4\">\r\n",
       "     <g id=\"line2d_4\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"160.661244\" xlink:href=\"#m0b446c64ad\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_4\">\r\n",
       "      <!-- 600 -->\r\n",
       "      <g transform=\"translate(151.117494 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 33.015625 40.375 \r\n",
       "Q 26.375 40.375 22.484375 35.828125 \r\n",
       "Q 18.609375 31.296875 18.609375 23.390625 \r\n",
       "Q 18.609375 15.53125 22.484375 10.953125 \r\n",
       "Q 26.375 6.390625 33.015625 6.390625 \r\n",
       "Q 39.65625 6.390625 43.53125 10.953125 \r\n",
       "Q 47.40625 15.53125 47.40625 23.390625 \r\n",
       "Q 47.40625 31.296875 43.53125 35.828125 \r\n",
       "Q 39.65625 40.375 33.015625 40.375 \r\n",
       "z\r\n",
       "M 52.59375 71.296875 \r\n",
       "L 52.59375 62.3125 \r\n",
       "Q 48.875 64.0625 45.09375 64.984375 \r\n",
       "Q 41.3125 65.921875 37.59375 65.921875 \r\n",
       "Q 27.828125 65.921875 22.671875 59.328125 \r\n",
       "Q 17.53125 52.734375 16.796875 39.40625 \r\n",
       "Q 19.671875 43.65625 24.015625 45.921875 \r\n",
       "Q 28.375 48.1875 33.59375 48.1875 \r\n",
       "Q 44.578125 48.1875 50.953125 41.515625 \r\n",
       "Q 57.328125 34.859375 57.328125 23.390625 \r\n",
       "Q 57.328125 12.15625 50.6875 5.359375 \r\n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \r\n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \r\n",
       "Q 6.984375 17.96875 6.984375 36.375 \r\n",
       "Q 6.984375 53.65625 15.1875 63.9375 \r\n",
       "Q 23.390625 74.21875 37.203125 74.21875 \r\n",
       "Q 40.921875 74.21875 44.703125 73.484375 \r\n",
       "Q 48.484375 72.75 52.59375 71.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-54\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_5\">\r\n",
       "     <g id=\"line2d_5\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"198.039234\" xlink:href=\"#m0b446c64ad\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_5\">\r\n",
       "      <!-- 800 -->\r\n",
       "      <g transform=\"translate(188.495484 157.698438)scale(0.1 -0.1)\">\r\n",
       "       <defs>\r\n",
       "        <path d=\"M 31.78125 34.625 \r\n",
       "Q 24.75 34.625 20.71875 30.859375 \r\n",
       "Q 16.703125 27.09375 16.703125 20.515625 \r\n",
       "Q 16.703125 13.921875 20.71875 10.15625 \r\n",
       "Q 24.75 6.390625 31.78125 6.390625 \r\n",
       "Q 38.8125 6.390625 42.859375 10.171875 \r\n",
       "Q 46.921875 13.96875 46.921875 20.515625 \r\n",
       "Q 46.921875 27.09375 42.890625 30.859375 \r\n",
       "Q 38.875 34.625 31.78125 34.625 \r\n",
       "z\r\n",
       "M 21.921875 38.8125 \r\n",
       "Q 15.578125 40.375 12.03125 44.71875 \r\n",
       "Q 8.5 49.078125 8.5 55.328125 \r\n",
       "Q 8.5 64.0625 14.71875 69.140625 \r\n",
       "Q 20.953125 74.21875 31.78125 74.21875 \r\n",
       "Q 42.671875 74.21875 48.875 69.140625 \r\n",
       "Q 55.078125 64.0625 55.078125 55.328125 \r\n",
       "Q 55.078125 49.078125 51.53125 44.71875 \r\n",
       "Q 48 40.375 41.703125 38.8125 \r\n",
       "Q 48.828125 37.15625 52.796875 32.3125 \r\n",
       "Q 56.78125 27.484375 56.78125 20.515625 \r\n",
       "Q 56.78125 9.90625 50.3125 4.234375 \r\n",
       "Q 43.84375 -1.421875 31.78125 -1.421875 \r\n",
       "Q 19.734375 -1.421875 13.25 4.234375 \r\n",
       "Q 6.78125 9.90625 6.78125 20.515625 \r\n",
       "Q 6.78125 27.484375 10.78125 32.3125 \r\n",
       "Q 14.796875 37.15625 21.921875 38.8125 \r\n",
       "z\r\n",
       "M 18.3125 54.390625 \r\n",
       "Q 18.3125 48.734375 21.84375 45.5625 \r\n",
       "Q 25.390625 42.390625 31.78125 42.390625 \r\n",
       "Q 38.140625 42.390625 41.71875 45.5625 \r\n",
       "Q 45.3125 48.734375 45.3125 54.390625 \r\n",
       "Q 45.3125 60.0625 41.71875 63.234375 \r\n",
       "Q 38.140625 66.40625 31.78125 66.40625 \r\n",
       "Q 25.390625 66.40625 21.84375 63.234375 \r\n",
       "Q 18.3125 60.0625 18.3125 54.390625 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-56\"/>\r\n",
       "       </defs>\r\n",
       "       <use xlink:href=\"#DejaVuSans-56\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_2\">\r\n",
       "    <g id=\"ytick_1\">\r\n",
       "     <g id=\"line2d_6\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L -3.5 0 \r\n",
       "\" id=\"m3df3f8b623\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m3df3f8b623\" y=\"143.1\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_6\">\r\n",
       "      <!-- 0 -->\r\n",
       "      <g transform=\"translate(26.2875 146.899219)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_2\">\r\n",
       "     <g id=\"line2d_7\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m3df3f8b623\" y=\"105.144407\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_7\">\r\n",
       "      <!-- 2000 -->\r\n",
       "      <g transform=\"translate(7.2 108.943626)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_3\">\r\n",
       "     <g id=\"line2d_8\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m3df3f8b623\" y=\"67.188814\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_8\">\r\n",
       "      <!-- 4000 -->\r\n",
       "      <g transform=\"translate(7.2 70.988033)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_4\">\r\n",
       "     <g id=\"line2d_9\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"39.65\" xlink:href=\"#m3df3f8b623\" y=\"29.233222\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_9\">\r\n",
       "      <!-- 6000 -->\r\n",
       "      <g transform=\"translate(7.2 33.03244)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_22\">\r\n",
       "    <path d=\"M 39.65 143.1 \r\n",
       "L 39.65 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_23\">\r\n",
       "    <path d=\"M 234.95 143.1 \r\n",
       "L 234.95 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_24\">\r\n",
       "    <path d=\"M 39.65 143.1 \r\n",
       "L 234.95 143.1 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_25\">\r\n",
       "    <path d=\"M 39.65 7.2 \r\n",
       "L 234.95 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       " </g>\r\n",
       " <defs>\r\n",
       "  <clipPath id=\"pc81d276a8b\">\r\n",
       "   <rect height=\"135.9\" width=\"195.3\" x=\"39.65\" y=\"7.2\"/>\r\n",
       "  </clipPath>\r\n",
       " </defs>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_tokens = d2l.tokenize(train_data[0], token='word')\n",
    "vocab = d2l.Vocab(train_tokens, min_freq=5, reserved_tokens=['<pad>'])\n",
    "\n",
    "d2l.set_figsize()\n",
    "d2l.plt.hist([len(line) for line in train_tokens], bins=range(0, 1000, 50));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.1.1.3. Đệm để cùng Độ dài\n",
    "Vì mỗi câu đánh giá có độ dài khác nhau, nên chúng không thể được tổng hợp trực tiếp thành minibatch được. Ta có thể cố định độ dài mỗi câu bình luận là 500 bằng cách cắt xén hoặc thêm vào các chỉ mục `“<unk>”`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25000, 500])\n"
     ]
    }
   ],
   "source": [
    "num_steps = 500  # sequence length\n",
    "train_features = torch.tensor([\n",
    "    d2l.truncate_pad(vocab[line], num_steps, vocab['<pad>'])\n",
    "    for line in train_tokens])\n",
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.1.1.4. Tạo Iterator cho Dữ liệu\n",
    "Bây giờ, ta sẽ tạo một iterator cho dữ liệu. Mỗi vòng lặp sẽ trả về một minibatch dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: torch.Size([64, 500]) , y: torch.Size([64])\n",
      "# batches: 391\n"
     ]
    }
   ],
   "source": [
    "train_iter = d2l.load_array((train_features, torch.tensor(train_data[1])), 64)\n",
    "\n",
    "for X, y in train_iter:\n",
    "    print('X:', X.shape, ', y:', y.shape)\n",
    "    break\n",
    "print('# batches:', len(train_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.1.2. Kết hợp Tất cả Lại\n",
    "Cuối cùng, ta lưu hàm `load_data_imdb` vào d2l, hàm này trả về bộ từ vựng và các iterator của dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def load_data_imdb(batch_size, num_steps=500):\n",
    "    data_dir = d2l.download_extract('aclImdb', 'aclImdb')\n",
    "    train_data = read_imdb(data_dir, True)\n",
    "    test_data = read_imdb(data_dir, False)\n",
    "    train_tokens = d2l.tokenize(train_data[0], token='word')\n",
    "    test_tokens = d2l.tokenize(test_data[0], token='word')\n",
    "    vocab = d2l.Vocab(train_tokens, min_freq=5)\n",
    "    train_features = torch.tensor([\n",
    "        d2l.truncate_pad(vocab[line], num_steps, vocab['<pad>'])\n",
    "        for line in train_tokens])\n",
    "    test_features = torch.tensor([\n",
    "        d2l.truncate_pad(vocab[line], num_steps, vocab['<pad>'])\n",
    "        for line in test_tokens])\n",
    "    train_iter = d2l.load_array((train_features, torch.tensor(train_data[1])),\n",
    "                                batch_size)\n",
    "    test_iter = d2l.load_array((test_features, torch.tensor(test_data[1])),\n",
    "                               batch_size, is_train=False)\n",
    "    return train_iter, test_iter, vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.1.3. Tóm tắt\n",
    "- Tác vụ phân loại văn bản có thể phân loại chuỗi văn bản theo hạng mục.\n",
    "- Để phân loại cảm xúc văn bản, ta nạp bộ dữ liệu IMDb và token hóa các từ trong đó. Sau đó, ta đệm thêm vào chuỗi văn bản của các câu đánh giá ngắn và tạo một iterator dữ liệu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.1.4. Bài tập\n",
    "Hãy khám phá một tập dữ liệu ngôn ngữ tự nhiên khác (ví dụ tập dữ liệu [Đánh giá Amazon](https://snap.stanford.edu/data/web-Amazon.html) và xây dựng một hàm `data_loader` tương tự như `load_data_imdb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.2. Phân tích Cảm xúc: Sử dụng Mạng Nơ-ron Hồi tiếp\n",
    "Tương tự như tìm kiếm các từ đồng nghĩa và loại suy, phân loại văn bản cũng là một tác vụ xuôi dòng của embedding từ. Trong phần này, ta sẽ áp dụng các vector từ đã được tiền huấn luyện (GloVe) và mạng nơ-ron truy hồi hai chiều với nhiều lớp ẩn [Maas et al., 2011], như được minh họa trong Fig. 15.2.1. Ta sẽ sử dụng mô hình này để xác định xem một chuỗi văn bản có độ dài không xác định chứa cảm xúc tích cực hay tiêu cực.\n",
    "\n",
    "![](images/nlp-map-sa-rnn.svg)\n",
    "\n",
    "Fig. 15.2.1 Phần này sẽ truyền các vector GloVe đã được tiền huấn luyện vào một kiến trúc RNN cho bài toán phân tích cảm xúc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size = 64\n",
    "train_iter, test_iter, vocab = d2l.load_data_imdb(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.2.1. Sử dụng Mạng Nơ-ron Hồi tiếp\n",
    "Trong mô hình này, đầu tiên mỗi từ nhận được một vector đặc trưng tương ứng từ tầng embedding. Sau đó, ta mã hóa thêm chuỗi đặc trưng bằng cách sử dụng mạng nơ-ron hồi tiếp hai chiều để thu được thông tin chuỗi. Cuối cùng, ta chuyển đổi thông tin chuỗi được mã hóa thành đầu ra thông qua tầng kết nối đầy đủ. Cụ thể, ta có thể ghép nối các trạng thái ẩn của bộ nhớ ngắn hạn dài hai chiều (**bidirectional long-short term memory**) ở bước thời gian ban đầu và bước thời gian cuối cùng và truyền nó tới tầng phân loại đầu ra như là đặc trưng mã hóa của thông tin chuỗi. Trong lớp `BiRNN` được lập trình bên dưới, thực thể `Embedding` là tầng embedding, thực thể LSTM là tầng ẩn để mã hóa chuỗi, và thực thể `Dense` là tầng đầu ra sinh kết quả phân loại."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 **kwargs):\n",
    "        super(BiRNN, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        # Set `bidirectional` to True to get a bidirectional recurrent neural\n",
    "        # network\n",
    "        self.encoder = nn.LSTM(embed_size, num_hiddens, num_layers=num_layers,\n",
    "                               bidirectional=True)\n",
    "        self.decoder = nn.Linear(4 * num_hiddens, 2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # The shape of `inputs` is (batch size, no. of words). Because LSTM\n",
    "        # needs to use sequence as the first dimension, the input is\n",
    "        # transformed and the word feature is then extracted. The output shape\n",
    "        # is (no. of words, batch size, word vector dimension).\n",
    "        embeddings = self.embedding(inputs.T)\n",
    "        # Since the input (embeddings) is the only argument passed into\n",
    "        # nn.LSTM, both h_0 and c_0 default to zero.\n",
    "        # we only use the hidden states of the last hidden layer\n",
    "        # at different time step (outputs). The shape of `outputs` is\n",
    "        # (no. of words, batch size, 2 * no. of hidden units).\n",
    "        self.encoder.flatten_parameters()\n",
    "        outputs, _ = self.encoder(embeddings)\n",
    "        # Concatenate the hidden states of the initial time step and final\n",
    "        # time step to use as the input of the fully connected layer. Its\n",
    "        # shape is (batch size, 4 * no. of hidden units)\n",
    "        encoding = torch.cat((outputs[0], outputs[-1]), dim=1)\n",
    "        outs = self.decoder(encoding)\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta sẽ tạo một mạng nơ-ron hồi tiếp hai chiều với hai tầng ẩn như sau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size, num_hiddens, num_layers, devices = 100, 100, 2, d2l.try_all_gpus()\n",
    "net = BiRNN(len(vocab), embed_size, num_hiddens, num_layers)\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "    if type(m) == nn.LSTM:\n",
    "        for param in m._flat_weights_names:\n",
    "            if \"weight\" in param:\n",
    "                nn.init.xavier_uniform_(m._parameters[param])\n",
    "\n",
    "net.apply(init_weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.2.1.1. Nạp các Vector Từ đã qua Tiền huấn luyện\n",
    "Bởi vì tập dữ liệu huấn luyện cho việc phân loại cảm xúc không quá lớn, để xử lý vấn đề quá khớp, ta sẽ dùng trực tiếp các vector từ đã được tiền huấn luyện trên tập ngữ liệu lớn hơn làm các vector đặc trưng cho tất cả các từ. Ở đây, ta nạp vector từ Glove 100-chiều cho mỗi từ trong từ điển `vocab`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ..\\data\\glove.6B.100d.zip from http://d2l-data.s3-accelerate.amazonaws.com/glove.6B.100d.zip...\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 2776: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-858f8fea360e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mglove_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTokenEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'glove.6b.100d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\d2l\\torch.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, embedding_name)\u001b[0m\n\u001b[0;32m   2187\u001b[0m     \u001b[1;34m\"\"\"Token Embedding.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2189\u001b[1;33m         self.idx_to_token, self.idx_to_vec = self._load_embedding(\n\u001b[0m\u001b[0;32m   2190\u001b[0m             embedding_name)\n\u001b[0;32m   2191\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munknown_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\d2l\\torch.py\u001b[0m in \u001b[0;36m_load_embedding\u001b[1;34m(self, embedding_name)\u001b[0m\n\u001b[0;32m   2199\u001b[0m         \u001b[1;31m# fastText website: https://fasttext.cc/\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2200\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vec.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2201\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2202\u001b[0m                 \u001b[0melems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2203\u001b[0m                 \u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melems\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0melems\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 2776: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "glove_embedding = d2l.TokenEmbedding('glove.6b.100d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truy vấn các vector từ nằm trong từ vựng của chúng ta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glove_embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ac7fac0acbdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0membeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglove_embedding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx_to_token\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0membeds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'glove_embedding' is not defined"
     ]
    }
   ],
   "source": [
    "embeds = glove_embedding[vocab.idx_to_token]\n",
    "embeds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo, ta sử dụng các vector từ đó làm vector đặc trưng cho mỗi từ trong các đánh giá. Lưu ý là các chiều của vector từ đã qua tiền huấn luyện cần nhất quán với kích thước đầu ra `embed_size` của tầng embedding trong mô hình đã tạo. Thêm vào đó, ta không còn cập nhật các vector từ này trong suốt quá trình huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.embedding.weight.data.copy_(embeds)\n",
    "net.embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.2.1.2. Huấn luyện và Đánh giá Mô hình\n",
    "Bây giờ ta có thể bắt đầu thực hiện huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs = 0.01, 5\n",
    "trainer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuối cùng, định nghĩa hàm dự đoán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def predict_sentiment(net, vocab, sentence):\n",
    "    sentence = torch.tensor(vocab[sentence.split()], device=d2l.try_gpu())\n",
    "    label = torch.argmax(net(sentence.reshape(1, -1)), dim=1)\n",
    "    return 'positive' if label == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo, sử dụng mô hình đã huấn luyện để phân loại cảm xúc cho hai câu đơn giản."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so bad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.2.2. Tóm tắt\n",
    "- Phân loại văn bản ánh xạ một chuỗi văn bản có độ dài không xác định thành hạng mục tương ứng của văn bản đó. Đây là một tác vụ xuôi dòng của embedding từ.\n",
    "- Ta có thể áp dụng các vector từ được tiền huấn luyện và mạng nơ-ron hồi tiếp để để phân loại cảm xúc trong văn bản."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.2.3. Bài tập\n",
    "1. Hãy tăng số epoch. Bạn có thể đạt được độ chính xác là bao nhiêu trên tập huấn luyện và tập kiểm tra? Thử tinh chỉnh các siêu tham số khác và đánh giá kết quả.\n",
    "2. Liệu sử dụng vector từ được tiền huấn luyện có kích thước lớn hơn, ví dụ vector từ GloVe có kích thước chiều là 300, có thể cải thiện độ chính xác hay không?\n",
    "3. Ta có thể cải thiện độ chính xác bằng cách sử dụng công cụ token hoá từ spaCy không? Bạn cần cài đặt spaCy bằng lệnh `pip install spacy` và cài đặt gói ngôn ngữ tiếng Anh bằng lệnh python -m spacy download en. Trong mã nguồn, đầu tiên hãy nhập thư viện spaCy với câu lệnh `import spacy`. Tiếp theo, hãy nạp gói spacy tiếng Anh `spacy_en = spacy.load('en')`. Cuối cùng, hãy định nghĩa hàm `def tokenizer(text): return [tok.text for tok in spacy_en.tokenizer(text)]` và thay thế hàm tokenizer ban đầu. Lưu ý rằng vector từ GloVe sử dụng **“-”** để kết nối mỗi từ trong cụm danh từ. Ví dụ, cụm từ **“new york”** được biểu diễn bằng **“new-york”** trong GloVe. Sau khi sử dụng công cụ token hoá spaCy, **“new york”** có thể sẽ được lưu thành **“new york”**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.3. Phân tích Cảm xúc: Sử dụng Mạng Nơ-ron Tích Chập\n",
    "Trong Section 6, chúng ta đã tìm hiểu cách xử lý dữ liệu ảnh hai chiều với mạng nơ-ron tích chập hai chiều. Ở chương trước về các mô hình ngôn ngữ và các tác vụ phân loại văn bản, ta coi dữ liệu văn bản như là dữ liệu chuỗi thời gian với chỉ một chiều duy nhất, và vì vậy, chúng sẽ được xử lí bằng mạng nơ-ron hồi tiếp. Thực tế, ta cũng có thể coi văn bản như một bức ảnh một chiều, và sử dụng mạng nơ-ron tích chập một chiều để tìm ra mối liên kết giữa những từ liền kề nhau. Như mô tả trong Fig. 15.3.1, chương này sẽ miêu tả một hướng tiếp cận đột phá bằng cách áp dụng mạng nơ-ron tích chập để phân tích cảm xúc: textCNN [Kim, 2014].\n",
    "\n",
    "![](images/nlp-map-sa-cnn.svg)\n",
    "\n",
    "Fig. 15.3.1 Phần này truyền mô hình tiền huấn luyện GloVe vào một kiến trúc mạng nơ-ron tích chập cho tác vụ phân loại cảm xúc\n",
    "\n",
    "Đầu tiên, nhập những gói thư viện và mô-đun cần thiết cho thử nghiệm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "batch_size = 64\n",
    "train_iter, test_iter, vocab = d2l.load_data_imdb(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3.1. Mạng Nơ-ron Tích chập Một chiều¶\n",
    "Trước khi giới thiệu mô hình, chúng ta hãy xem mạng nơ-ron tích chập một chiều họat động như thế nào. Tương tự như mạng nơ-ron tích chập hai chiều, mạng nơ-ron tích chập một chiều sử dụng phép tính tương quan chéo một chiều. Trong phép tính tương quan chéo một chiều, cửa sổ tích chập bắt đầu từ phía ngoài cùng bên trái của mảng đầu vào và trượt lần lượt từ trái qua phải. Xét trên một vị trí nhất định của cửa sổ tích chập khi trượt, ta nhân từng phần tử của mảng đầu vào con trong cửa sổ đó với mảng hạt nhân rồi cộng lại để lấy được phần tử ở vị trí tương ứng trong mảng đầu ra. Như ví dụ ở Fig. 15.3.2, đầu vào là một mảng một chiều với độ rộng là 7 và độ rộng của mảng hạt nhân là 2. Ta có thể thấy rằng độ rộng của đầu ra là  $7−2+1=6$  và phần tử đầu tiên được tính bằng cách nhân theo từng phần tử mảng đầu vào con chứa 2 phần tử ngoài cùng bên trái với mảng hạt nhân, rồi cộng lại với nhau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/conv1d.svg)\n",
    "\n",
    "Fig. 15.3.2 Phép tính tương quan chéo một chiều. Những vùng in đậm là phần tử đầu ra đầu tiên, cùng phần tử đầu vào và mảng hạt nhân được dùng trong phép tính đó:  $0×1+1×2=2$ .\n",
    "\n",
    "Tiếp theo, chúng ta sẽ lập trình phép tương quan chéo một chiều trong hàm `corr1d`. Hàm này nhận mảng đầu vào $X$ và mảng hạt nhân $K$ và cho ra đầu ra là mảng $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr1d(X, K):\n",
    "    w = K.shape[0]\n",
    "    Y = torch.zeros((X.shape[0] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        Y[i] = (X[i:i + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ chúng ta sẽ tái tạo lại kết quả của phép tính tương quan chéo một chiều ở Fig. 15.3.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, K = torch.tensor([0, 1, 2, 3, 4, 5, 6]), torch.tensor([1, 2])\n",
    "corr1d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phép tính tương quan chéo một chiều cho nhiều kênh đầu vào cũng tương tự như phép tương quan chéo hai chiều cho nhiều kênh đầu vào. Với mỗi kênh, toán tử này thực hiện phép tính tương quan chéo một chiều trên từng hạt nhân và đầu vào tương ứng, và cộng các kết quả trên từng kênh lại với nhau để thu được đầu ra. Fig. 15.3.3 minh họa phép tính tương quan chéo một chiều với ba kênh đầu vào.\n",
    "\n",
    "![](images/conv1d-channel.svg)\n",
    "\n",
    "Fig. 15.3.3 Phép tính tương quan chéo một chiều với ba kênh đầu vào. Những vùng được in đậm là phần tử đầu ra thứ nhất cũng như đầu vào và các phần tử của mảng hạt nhân được sử dụng trong phép tính:  $0×1+1×2+1×3+2×4+2×(−1)+3×(−3)=2$ .\n",
    "\n",
    "Bây giờ, ta sẽ tái tạo lại kết quả của phép tính tương quan chéo một chiều với đa kênh đầu vào trong Fig. 15.3.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, K = torch.tensor([0, 1, 2, 3, 4, 5, 6]), torch.tensor([1, 2])\n",
    "corr1d(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr1d_multi_in(X, K):\n",
    "    # First, we traverse along the 0th dimension (channel dimension) of `X`\n",
    "    # and `K`. Then, we add them together by using * to turn the result list\n",
    "    # into a positional argument of the `add_n` function\n",
    "    return sum(corr1d(x, k) for x, k in zip(X, K))\n",
    "\n",
    "X = torch.tensor([[0, 1, 2, 3, 4, 5, 6], [1, 2, 3, 4, 5, 6, 7],\n",
    "                  [2, 3, 4, 5, 6, 7, 8]])\n",
    "K = torch.tensor([[1, 2], [3, 4], [-1, -3]])\n",
    "corr1d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Định nghĩa phép tính tương quan chéo hai chiều cho ta thấy phép tính tương quan chéo một chiều với đa kênh đầu vào có thể được coi là phép tính tương quan chéo hai chiều với một kênh đầu vào. Như minh họa trong Fig. 15.3.4, ta có thể biểu diễn phép tính tương quan chéo một chiều với đa kênh đầu vào trong Fig. 15.3.3 tương tự như phép tính tương quan chéo hai chiều với một kênh đầu vào. Ở đây, chiều cao của hạt nhân bằng với chiều cao của đầu vào.\n",
    "\n",
    "![](images/conv1d-2d.svg)\n",
    "\n",
    "Fig. 15.3.4 Phép tính tương quan chéo hai chiều với một kênh đầu vào. Vùng được tô đậm là phần tử đầu ra thứ nhất và đầu vào cũng như các phần tử của mảng hạt nhân được sử dụng trong phép tính:  $2×(−1)+3×(−3)+1×3+2×4+0×1+1×2=2$ .\n",
    "\n",
    "Cả hai đầu ra trong Fig. 15.3.2 và Fig. 15.3.3 chỉ có một kênh. Ta đã thảo luận cách chỉ định đa kênh đầu ra trong tầng tích chập hai chiều tại Section 6.4. Tương tự, ta cũng có thể chỉ định đa kênh đầu ra trong tầng tích chập một chiều để mở rộng các tham số mô hình trong tầng tích chập đó."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3.2. Tầng Gộp Cực đại Theo Thời gian\n",
    "Tương tự, ta có tầng gộp một chiều. Tầng gộp cực đại theo thời gian được dùng trong TextCNN thực chất tương tự như tầng gộp cực đại toàn cục một chiều. Giả sử đầu vào có nhiều kênh, mỗi kênh bao gồm các giá trị bước thời gian khác nhau, đầu ra của mỗi kênh sẽ là giá trị lớn nhất qua tất cả bước thời gian trong từng kênh. Do đó, đầu vào của tầng gộp cực đại theo thời gian có thể có số lượng bước thời gian khác nhau tại mỗi kênh.\n",
    "\n",
    "Để cải thiện chất lượng tính toán, ta thường kết hợp những mẫu thời gian có độ dài khác nhau vào một minibatch và làm cho chiều dài theo thời gian của từng mẫu đồng nhất bằng cách thêm các ký tự đặc biệt (ví dụ 0) vào cuối những mẫu ngắn hơn. Tất nhiên, các ký tự được thêm vào không làm thay đổi bản chất ngữ nghĩa. Bởi vì, mục tiêu chính của tầng gộp cực đại theo thời gian là học được những đặc trưng quan trọng của thời gian, thông thường điều đó cho phép mô hình không bị ảnh hưởng bởi các ký tự được thêm vào thủ công."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3.3. Mô hình TextCNN\n",
    "TextCNN chủ yếu sử dụng tầng tích chập một chiều và tầng gộp cực đại theo thời gian. Giả sử chuỗi văn bản đầu vào gồm  $n$  từ, mỗi từ được biểu diễn bởi một vector  $d$  chiều. Lúc này mẫu đầu vào có chiều rộng là  $n$ , chiều cao là $1$, và  $d$  kênh đầu vào. Quá trình tính toán của **textCNN** chủ yếu được chia thành các bước sau:\n",
    "\n",
    "1. Định nghĩa nhiều hạt nhân tích chập một chiều để thực hiện các phép tính tích chập trên đầu vào. Những hạt nhân tích chập với độ rộng khác nhau có thể học được sự tương quan của các cụm từ liền kề với số lượng khác nhau.\n",
    "2. Thực hiện gộp cực đại theo thời gian trên tất cả các kênh đầu ra, sau đó nối các giá trị gộp được của các kênh này thành một vector.\n",
    "3. Vector nối trên sẽ được biến đổi thành đầu ra cho từng hạng mục bằng thông qua tầng kết nối đầy đủ. Tầng dropout có thể được sử dụng ở bước này để giải quyết tình trạng quá khớp.\n",
    "\n",
    "![](images/textcnn.svg)\n",
    "\n",
    "Fig. 15.3.5 Thiết kế TextCNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fig. 15.3.5 minh họa một ví dụ cho textCNN. Đầu vào ở đây là một câu gồm 11 từ, với mỗi từ được biểu diễn bằng một vector từ 6 chiều. Vì vậy, câu đầu vào có độ rộng là 11 và số kênh đầu vào là 6. Chúng ta giả sử rằng 2 hạt nhân tích chập một chiều có độ rộng lần lượt là 2 và 4, tương ứng với số kênh đầu ra là 4 và 5. Cho nên sau phép tính tích chập một chiều, đầu ra 4 kênh có chiều rộng là là  $11−2+1=10$ , trong khi đó độ rộng của đầu ra 5 kênh còn lại là  $11−4+1=8$ . Thậm chí độ rộng của mỗi kênh có khác nhau đi nữa, chúng ta vẫn có thể thực hiện gộp cực đại theo thời gian cho mỗi kênh và nối đầu ra sau gộp của 9 kênh thành một vector 9 chiều. Cuối cùng, chúng ta dùng một tầng kết nối đầy đủ để biến đổi vector 9 chiều đó thành một đầu ra 2 chiều: dự đoán cảm xúc tích cực và cảm xúc tiêu cực.\n",
    "\n",
    "Tiếp theo chúng ta bắt đầu lập trình mô hình textCNN. So với phần trước, ngoài việc thay mạng nơ-ron hồi tiếp bằng một tầng tích chập một chiều, ở đây chúng ta dùng 2 tầng embedding, một được giữ trọng số cố định và tầng còn lại tham gia quá trình huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, kernel_sizes, num_channels,\n",
    "                 **kwargs):\n",
    "        super(TextCNN, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        # The embedding layer does not participate in training\n",
    "        self.constant_embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.decoder = nn.Linear(sum(num_channels), 2)\n",
    "        # The max-over-time pooling layer has no weight, so it can share an\n",
    "        # instance\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.relu = nn.ReLU()\n",
    "        # Create multiple one-dimensional convolutional layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        for c, k in zip(num_channels, kernel_sizes):\n",
    "            self.convs.append(nn.Conv1d(2 * embed_size, c, k))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Concatenate the output of two embedding layers with shape of\n",
    "        # (batch size, no. of words, word vector dimension) by word vector\n",
    "        embeddings = torch.cat(\n",
    "            (self.embedding(inputs), self.constant_embedding(inputs)), dim=2)\n",
    "        # According to the input format required by Conv1d, the word vector\n",
    "        # dimension, that is, the channel dimension of the one-dimensional\n",
    "        # convolutional layer, is transformed into the previous dimension\n",
    "        embeddings = embeddings.permute(0, 2, 1)\n",
    "        # For each one-dimensional convolutional layer, after max-over-time\n",
    "        # pooling, a tensor with the shape of (batch size, channel size, 1)\n",
    "        # can be obtained. Use the flatten function to remove the last\n",
    "        # dimension and then concatenate on the channel dimension\n",
    "        encoding = torch.cat([\n",
    "            torch.squeeze(self.relu(self.pool(conv(embeddings))), dim=-1)\n",
    "            for conv in self.convs], dim=1)\n",
    "        # After applying the dropout method, use a fully connected layer to\n",
    "        # obtain the output\n",
    "        outputs = self.decoder(self.dropout(encoding))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tạo một thực thể TextCNN có 3 tầng tích chập với chiều rộng hạt nhân là 3, 4 và 5, tất cả đều có 100 kênh đầu ra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size, kernel_sizes, nums_channels = 100, [3, 4, 5], [100, 100, 100]\n",
    "devices = d2l.try_all_gpus()\n",
    "net = TextCNN(len(vocab), embed_size, kernel_sizes, nums_channels)\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) in (nn.Linear, nn.Conv1d):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "net.apply(init_weights);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3.3.1. Nạp Vector Từ đã được Tiền huấn luyện\n",
    "Tương tự phần trước, ta nạp GloVe 100 chiều đã được tiền huấn luyện và khởi tạo các tầng embedding `embedding` và `constant_embedding`. Ở đây, `embedding` sẽ tham gia quá trình huấn luyện trong khi `constant_embedding` có trọng số cố định."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embedding = d2l.TokenEmbedding('glove.6b.100d')\n",
    "embeds = glove_embedding[vocab.idx_to_token]\n",
    "net.embedding.weight.data.copy_(embeds)\n",
    "net.constant_embedding.weight.data.copy_(embeds)\n",
    "net.constant_embedding.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3.3.2. Huấn luyện và Đánh giá Mô hình\n",
    "Bây giờ ta có thể huấn luyện mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "trainer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dưới đây, ta sử dụng mô hình đã được huấn luyện để phân loại cảm xúc của hai câu đơn giản."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.predict_sentiment(net, vocab, 'this movie is so great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.predict_sentiment(net, vocab, 'this movie is so bad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3.4. Tóm tắt\n",
    "- Ta có thể dùng tích chập một chiều để xử lý và phân tích dữ liệu theo thời gian.\n",
    "- Phép tương quan chéo một chiều đa kênh đầu vào có thể xem như phép tương quan chéo hai chiều đơn kênh đầu vào.\n",
    "- Đầu vào của tầng gộp cực đại theo thời gian có thể có số bước thời gian trên mỗi kênh khác nhau.\n",
    "- TextCNN chủ yếu sử dụng một tầng chập một chiều và một tầng gộp cực đại theo thời gian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3.5. Bài tập\n",
    "1. Điều chỉnh các tham số mô hình và so sánh hai phương pháp phân tích cảm xúc giữa mạng nơ-ron truy hồi và mạng nơ-ron tích chập, xét trên khía cạnh độ chính xác và hiệu suất tính toán.\n",
    "2. Bạn có thể cải thiện thêm độ chính xác của mô hình trên tập kiểm tra thông qua việc sử dụng ba phương pháp đã được giới thiệu ở phần trước: điều chỉnh các tham số mô hình, sử dụng các vector từ tiền huấn luyện lớn hơn, và sử dụng công cụ token hóa từ spaCy.\n",
    "3. Bạn còn có thể sử dụng TextCNN cho những tác vụ xử lý ngôn ngữ tự nhiên nào khác?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.4. Suy luận ngôn ngữ tự nhiên và Tập dữ liệu\n",
    "Trong Section 15.1, chúng ta đã thảo luận về bài toán phân tích sắc thái cảm xúc (**sentiment analysis**). Mục đích của bài toán là phân loại một chuỗi văn bản vào các hạng mục đã định trước, chẳng hạn như các sắc thái đối lập. Tuy nhiên, trong trường hợp cần xác định liệu một câu có thể suy ra được từ một câu khác không, hoặc khi cần loại bỏ sự dư thừa bằng việc xác định các câu tương đương về ngữ nghĩa thì việc phân lớp một chuỗi văn bản là không đủ. Thay vào đó ta cần khả năng suy luận trên các cặp chuỗi văn bản."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.4.1. Suy luận Ngôn ngữ Tự nhiên\n",
    "Suy luận ngôn ngữ tự nhiên nghiên cứu liệu một giả thuyết (hypothesis) có thể được suy ra được từ một tiền đề (premise) không, cả hai đều là chuỗi văn bản. Nói cách khác, suy luận ngôn ngữ tự nhiên quyết định mối quan hệ logic giữa một cặp chuỗi văn bản. Các mối quan hệ đó thường rơi vào một trong ba loại sau đây:\n",
    "\n",
    "- Kéo theo: giả thuyết có thể suy ra được từ tiền đề.\n",
    "- Đối lập: phủ định của giả thuyết có thể suy ra được từ tiền đề.\n",
    "- Trung tính: tất cả các trường hợp khác.\n",
    "\n",
    "Suy luận ngôn ngữ tự nhiên còn được gọi là bài toán nhận dạng quan hệ kéo theo trong văn bản. Ví dụ, cặp sau được gán nhãn là kéo theo bởi vì “thể hiện tình cảm” trong giả thuyết có thể được suy ra từ “ôm nhau” trong tiền đề.\n",
    "\n",
    ">Tiền đề: Hai người đang ôm nhau.\n",
    "\n",
    ">Giả thuyết: Hai người đang thể hiện tình cảm\n",
    "\n",
    "Sau đây là một ví dụ về đối lập, vì “chạy đoạn mã ví dụ” cho biết “không ngủ” chứ không phải “ngủ”.\n",
    "\n",
    ">Tiền đề: Một bạn đang chạy đoạn mã ví dụ trong Đắm mình vào học sâu.\n",
    "\n",
    ">Giả thuyết: Bạn đó đang ngủ.\n",
    "\n",
    "Ví dụ thứ ba cho thấy mối quan hệ trung tính vì cả “nổi tiếng” và “không nổi tiếng” đều không thể được suy ra từ thực tế là “đang biểu diễn cho chúng tôi”.\n",
    "\n",
    ">Tiền đề: Các nhạc công đang biểu diễn cho chúng tôi.\n",
    "\n",
    ">Giả thuyết: Các nhạc công rất nổi tiếng.\n",
    "\n",
    "Suy luận ngôn ngữ tự nhiên là một chủ đề trung tâm trong việc hiểu ngôn ngữ tự nhiên. Nó có nhiều ứng dụng khác nhau, từ truy xuất thông tin đến hỏi đáp trong miền mở. Để nghiên cứu bài toán này, chúng ta sẽ bắt đầu bằng việc tìm hiểu một tập dữ liệu đánh giá xếp hạng phổ biến trong suy luận ngôn ngữ tự nhiên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.4.2. Tập dữ liệu Suy luận ngôn ngữ tự nhiên của Stanford (SNLI)\n",
    "Tập ngữ liệu ngôn ngữ tự nhiên của Stanford (SNLI) là một tập hợp gồm hơn  500,000  cặp câu Tiếng Anh được gán nhãn [Bowman et al., 2015]. Ta tải xuống và giải nén tập dữ liệu SNLI trong đường dẫn `../data/snli_1.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: '..\\\\data\\\\snli_1.0\\\\Icon\\r'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-094880731369>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                         '9fcde07509c7e87ec61c640c1b2753d9041758e4')\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload_extract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SNLI'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\d2l\\torch.py\u001b[0m in \u001b[0;36mdownload_extract\u001b[1;34m(name, folder)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Only zip/tar files can be extracted.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36mextractall\u001b[1;34m(self, path, members, pwd)\u001b[0m\n\u001b[0;32m   1645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1646\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1647\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1649\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[1;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[0;32m   1699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1700\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1701\u001b[1;33m              \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1702\u001b[0m             \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: '..\\\\data\\\\snli_1.0\\\\Icon\\r'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "#@save\n",
    "d2l.DATA_HUB['SNLI'] = ('https://nlp.stanford.edu/projects/snli/snli_1.0.zip',\n",
    "                        '9fcde07509c7e87ec61c640c1b2753d9041758e4')\n",
    "\n",
    "data_dir = d2l.download_extract('SNLI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.4.2.1. Đọc tập Dữ liệu\n",
    "Tập dữ liệu SNLI gốc chứa thông tin phong phú hơn những gì thực sự cần cho thí nghiệm của chúng ta. Vì thế, ta định nghĩa một hàm `read_snli` để trích xuất một phần của tập dữ liệu, rồi trả về các danh sách tiền đề, giả thuyết và nhãn của chúng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def read_snli(data_dir, is_train):\n",
    "    \"\"\"Read the SNLI dataset into premises, hypotheses, and labels.\"\"\"\n",
    "    def extract_text(s):\n",
    "        # Remove information that will not be used by us\n",
    "        s = re.sub('\\\\(', '', s)\n",
    "        s = re.sub('\\\\)', '', s)\n",
    "        # Substitute two or more consecutive whitespace with space\n",
    "        s = re.sub('\\\\s{2,}', ' ', s)\n",
    "        return s.strip()\n",
    "\n",
    "    label_set = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n",
    "    file_name = os.path.join(\n",
    "        data_dir, 'snli_1.0_train.txt' if is_train else 'snli_1.0_test.txt')\n",
    "    with open(file_name, 'r') as f:\n",
    "        rows = [row.split('\\t') for row in f.readlines()[1:]]\n",
    "    premises = [extract_text(row[1]) for row in rows if row[0] in label_set]\n",
    "    hypotheses = [extract_text(row[2]) for row in rows if row[0] in label_set]\n",
    "    labels = [label_set[row[0]] for row in rows if row[0] in label_set]\n",
    "    return premises, hypotheses, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ ta in  3  cặp **tiền đề** và **giả thuyết** đầu tiên cũng như nhãn của chúng (“0”, “1”, và “2” tương ứng với “kéo theo”, “đối lập”, và “trung tính”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_snli(data_dir, is_train=True)\n",
    "for x0, x1, y in zip(train_data[0][:3], train_data[1][:3], train_data[2][:3]):\n",
    "    print('premise:', x0)\n",
    "    print('hypothesis:', x1)\n",
    "    print('label:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tập huấn luyện có khoảng  $550,000$  cặp, và tập kiểm tra có khoảng  $10,000$  cặp. Đoạn mã dưới đây cho thấy rằng ba nhãn “kéo theo”, “đối lập”, và “trung tính” cân bằng trong cả hai tập huấn luyện và tập kiểm tra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = read_snli(data_dir, is_train=False)\n",
    "for data in [train_data, test_data]:\n",
    "    print([[row for row in data[2]].count(i) for i in range(3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.4.2.2. Định nghĩa Lớp để nạp Tập dữ liệu\n",
    "Dưới đây ta định nghĩa một lớp để nạp tập dữ liệu SNLI bằng cách kế thừa lớp Dataset trong Gluon. Đối số num_steps trong phương thức khởi tạo chỉ định độ dài chuỗi văn bản, do đó mỗi minibatch sẽ có cùng kích thước. Nói cách khác, các token phía sau `num_steps` token đầu tiên ở trong chuỗi dài hơn sẽ được loại bỏ, trong khi token đặc biệt `“<pad>”` sẽ được nối thêm vào các chuỗi ngắn hơn đến khi độ dài của chúng bằng `num_steps`. Bằng cách lập trình hàm `__getitem__`, ta có thể truy cập vào các tiền đề, giả thuyết và nhãn bất kỳ với chỉ số `idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class SNLIDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"A customized dataset to load the SNLI dataset.\"\"\"\n",
    "    def __init__(self, dataset, num_steps, vocab=None):\n",
    "        self.num_steps = num_steps\n",
    "        all_premise_tokens = d2l.tokenize(dataset[0])\n",
    "        all_hypothesis_tokens = d2l.tokenize(dataset[1])\n",
    "        if vocab is None:\n",
    "            self.vocab = d2l.Vocab(all_premise_tokens + all_hypothesis_tokens,\n",
    "                                   min_freq=5, reserved_tokens=['<pad>'])\n",
    "        else:\n",
    "            self.vocab = vocab\n",
    "        self.premises = self._pad(all_premise_tokens)\n",
    "        self.hypotheses = self._pad(all_hypothesis_tokens)\n",
    "        self.labels = torch.tensor(dataset[2])\n",
    "        print('read ' + str(len(self.premises)) + ' examples')\n",
    "\n",
    "    def _pad(self, lines):\n",
    "        return torch.tensor([\n",
    "            d2l.truncate_pad(self.vocab[line], self.num_steps,\n",
    "                             self.vocab['<pad>']) for line in lines])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.premises[idx], self.hypotheses[idx]), self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.premises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.4.2.3. Kết hợp tất cả lại\n",
    "Bây giờ ta có thể gọi hàm `read_snli` và lớp `SNLIDataset` để tải xuống tập dữ liệu SNLI và trả về thực thể `DataLoader` cho cả hai tập huấn luyện và tập kiểm tra, cùng với bộ từ vựng của tập huấn luyện. Lưu ý rằng ta phải sử dụng bộ từ vựng được xây dựng từ tập huấn luyện cho tập kiểm tra. Như vậy, mô hình được huấn luyện trên tập huấn luyện sẽ không biết bất kỳ token mới nào từ tập kiểm tra nếu có."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def load_data_snli(batch_size, num_steps=50):\n",
    "    \"\"\"Download the SNLI dataset and return data iterators and vocabulary.\"\"\"\n",
    "    num_workers = d2l.get_dataloader_workers()\n",
    "    data_dir = d2l.download_extract('SNLI')\n",
    "    train_data = read_snli(data_dir, True)\n",
    "    test_data = read_snli(data_dir, False)\n",
    "    train_set = SNLIDataset(train_data, num_steps)\n",
    "    test_set = SNLIDataset(test_data, num_steps, train_set.vocab)\n",
    "    train_iter = torch.utils.data.DataLoader(train_set, batch_size,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=num_workers)\n",
    "    test_iter = torch.utils.data.DataLoader(test_set, batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=num_workers)\n",
    "    return train_iter, test_iter, train_set.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ở đây ta đặt kích thước batch là  $128$  và độ dài chuỗi là  $50$ , và gọi hàm `load_data_snli` để lấy iterator dữ liệu và bộ từ vựng. Sau đó ta in kích thước của bộ từ vựng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, test_iter, vocab = load_data_snli(128, 50)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ ta in kích thước của minibatch đầu tiên. Trái với phân tích sắc thái cảm xúc, ta có  2  đầu vào X[0] và X[1] biểu diễn cặp tiền đề và giả thuyết."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, Y in train_iter:\n",
    "    print(X[0].shape)\n",
    "    print(X[1].shape)\n",
    "    print(Y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.4.3. Tóm tắt\n",
    "- Suy luận ngôn ngữ tự nhiên nghiên cứu liệu một giả thuyết có thể được suy ra từ một tiền đề hay không, khi cả hai đều là chuỗi văn bản.\n",
    "- Trong suy luận ngôn ngữ tự nhiên, mối quan hệ giữa tiền đề và giả thuyết bao gồm kéo theo, đối lập và trung tính.\n",
    "- Bộ dữ liệu suy luận ngôn ngữ tự nhiên Stanford (SNLI) là một tập dữ liệu đánh giá xếp hạng phổ biến cho suy luận ngôn ngữ tự nhiên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.4.4. Bài tập\n",
    "1. Dịch máy từ lâu nay vẫn được đánh giá bằng sự trùng lặp bề ngoài giữa các  `n -gram` của bản dịch đầu ra và bản dịch nhãn gốc. Bạn có thể thiết kế một phép đo để đánh giá kết quả dịch máy bằng cách sử dụng suy luận ngôn ngữ tự nhiên không?\n",
    "2. Thay đổi siêu tham số như thế nào để giảm kích thước bộ từ vựng?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.5. Suy luận Ngôn ngữ Tự nhiên: Sử dụng Cơ chế Tập trung\n",
    "Chúng tôi đã giới thiệu tác vụ suy luận ngôn ngữ tự nhiên và tập dữ liệu SNLI trong Section 15.4. Trong nhiều mô hình dựa trên các kiến trúc sâu và phức tạp, Parikh và các cộng sự đề xuất hướng giải quyết bài toán suy luận ngôn ngữ tự nhiên bằng cơ chế tập trung và gọi nó là một “mô hình tập trung có thể phân tách” (**decomposable attention model**) [Parikh et al., 2016]. Điều này dẫn đến một mô hình không có các tầng truy hồi hay tích chập, nhưng đạt được kết quả tốt nhất vào thời điểm đó trên tập dữ liệu SNLI với lượng tham số ít hơn nhiều. Trong phần này, chúng tôi sẽ mô tả và lập trình phương pháp dựa trên cơ chế tập trung (cùng với MLP) để suy luận ngôn ngữ tự nhiên, như minh họa trong Fig. 15.5.1.\n",
    "\n",
    "![](images/nlp-map-nli-attention.svg)\n",
    "\n",
    "Fig. 15.5.1 Mục này truyền Glove tiền huấn luyện vào kiến trúc tập trung và MLPs để suy diễn ngôn ngữ tự nhiên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.5.1. Mô hình\n",
    "Đơn giản hơn so với việc duy trì thứ tự của các từ trong các tiền đề và giả thuyết, ta có thể căn chỉnh các từ trong một chuỗi văn bản với mọi từ trong chuỗi khác và ngược lại, rồi so sánh và kết hợp các thông tin đó để dự đoán mối quan hệ logic giữa tiền đề và giả thuyết. Tương tự như việc căn chỉnh các từ giữa câu nguồn và đích trong dịch máy, việc căn chỉnh các từ giữa tiền đề và giả thuyết có thể được thực hiện nhanh gọn nhờ cơ chế tập trung.\n",
    "\n",
    "![](images/nli_attention.svg)\n",
    "\n",
    "Fig. 15.5.2 Suy luận ngôn ngữ tự nhiên sử dụng cơ chế tập trung.\n",
    "\n",
    "Fig. 15.5.2 minh họa phương pháp suy luận ngôn ngữ tự nhiên sử dụng cơ chế tập trung. Ở mức cao, nó bao gồm ba bước huấn luyện phối hợp: thực hiện tập trung, so sánh, và kết hợp. Ta sẽ từng bước mô tả chúng trong phần tiếp theo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.5.1.1. Thực hiện Tập trung\n",
    "Bước đầu tiên là phải căn chỉnh các từ trong một chuỗi văn bản với một chuỗi khác. Giả sử câu tiền đề là `“i do need sleep”` và câu giả thuyết là `“i am tired”`. Do sự tương đồng về ngữ nghĩa, ta mong muốn căn chỉnh `“i”` trong câu giả thuyết với `“i” `trong câu tiền đề, và căn chỉnh `“tired”` trong câu giả thuyết với `“sleep”` trong câu tiền đề. Tương tự, ta muốn căn chỉnh `“i”` trong câu tiền đề với `“i”` trong câu giả thuyết, và căn chỉnh `“need”` và `“sleep”` trong câu tiền đề với `“tired”` trong câu giả thuyết. Lưu ý là sự căn chỉnh này là **mềm**, sử dụng trung bình có trọng số, trong đó các trọng số nên có độ lớn hợp lý ứng với các từ được căn chỉnh. Để dễ dàng cho việc minh họa, Fig. 15.5.2 diễn tả sự căn chỉnh này theo cách **cứng**.\n",
    "\n",
    "Bây giờ ta mô tả sự căn chỉnh mềm sử dụng cơ chế tập trung chi tiết hơn. Ký hiệu  $A=(a_1,…,a_m)$  và  $B=(b_1,…,b_n)$  là câu tiền đề và câu giả thuyết, với số từ lần lượt là  $m$  và  $n$ . Ở đây  $\\mathbf{a}_i, \\mathbf{b}_j \\in \\mathbb{R}^{d}$ là một vector embedding từ  d -chiều. Để căn chỉnh mềm, ta tính trọng số tập trung  $e_{ij} \\in \\mathbb{R}$  như sau\n",
    "\n",
    "<center>$e_{ij} = f(\\mathbf{a}_i)^\\top f(\\mathbf{b}_j),$</center>\n",
    " \n",
    "ở đây hàm  $f$  là một MLP được định nghĩa theo hàm `mlp`. Chiều đầu ra của  $f$  được thiết lập bởi đối số `num_hiddens` của hàm `mlp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(num_inputs, num_hiddens, flatten):\n",
    "    net = []\n",
    "    net.append(nn.Dropout(0.2))\n",
    "    net.append(nn.Linear(num_inputs, num_hiddens))\n",
    "    net.append(nn.ReLU())\n",
    "    if flatten:\n",
    "        net.append(nn.Flatten(start_dim=1))\n",
    "    net.append(nn.Dropout(0.2))\n",
    "    net.append(nn.Linear(num_hiddens, num_hiddens))\n",
    "    net.append(nn.ReLU())\n",
    "    if flatten:\n",
    "        net.append(nn.Flatten(start_dim=1))\n",
    "    return nn.Sequential(*net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cũng nên chú ý rằng, trong (15.5.1)  $f$  nhận hai đầu vào  $\\mathbf{a}_i$  và  $\\mathbf{b}_j$  riêng biệt thay vì nhận cả cặp làm đầu vào. Thủ thuật phân tách này dẫn tới việc chỉ có  $m+n$  lần tính (độ phức tạp tuyến tính)  $f$  thay vì  $mn$  (độ phức tạp bậc hai).\n",
    "\n",
    "Thực hiện chuẩn hóa các trọng số tập trung trong (15.5.1), ta tính trung bình có trọng số của tất cả các embedding từ trong câu giả thuyết để thu được biểu diễn của câu giả thuyết được căn chỉnh mềm với từ được đánh chỉ số  i  trong câu tiền đề:\n",
    "\n",
    "<center>$\\boldsymbol{\\beta}_i = \\sum_{j=1}^{n}\\frac{\\exp(e_{ij})}{ \\sum_{k=1}^{n} \\exp(e_{ik})} \\mathbf{b}_j.$</center>\n",
    " \n",
    "Tương tự, ta tính sự căn chỉnh mềm của các từ trong câu tiền đề cho mỗi từ được đánh chỉ số  j  trong câu giả thuyết:\n",
    "\n",
    "<center>$\\boldsymbol{\\alpha}_j = \\sum_{i=1}^{m}\\frac{\\exp(e_{ij})}{ \\sum_{k=1}^{m} \\exp(e_{kj})} \\mathbf{a}_i.$</center>\n",
    " \n",
    "Dưới đây ta định nghĩa lớp `Attend` để tính sự căn chỉnh mềm của các câu giả thuyết (`beta`) với các câu tiền đề đầu vào A và sự căn chỉnh mềm của các câu tiền đề (`alpha`) với các câu giả thuyết $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attend(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, **kwargs):\n",
    "        super(Attend, self).__init__(**kwargs)\n",
    "        self.f = mlp(num_inputs, num_hiddens, flatten=False)\n",
    "\n",
    "    def forward(self, A, B):\n",
    "        # Shape of `A`/`B`: (`batch_size`, no. of words in sequence A/B,\n",
    "        # `embed_size`)\n",
    "        # Shape of `f_A`/`f_B`: (`batch_size`, no. of words in sequence A/B,\n",
    "        # `num_hiddens`)\n",
    "        f_A = self.f(A)\n",
    "        f_B = self.f(B)\n",
    "        # Shape of `e`: (`batch_size`, no. of words in sequence A,\n",
    "        # no. of words in sequence B)\n",
    "        e = torch.bmm(f_A, f_B.permute(0, 2, 1))\n",
    "        # Shape of `beta`: (`batch_size`, no. of words in sequence A,\n",
    "        # `embed_size`), where sequence B is softly aligned with each word\n",
    "        # (axis 1 of `beta`) in sequence A\n",
    "        beta = torch.bmm(F.softmax(e, dim=-1), B)\n",
    "        # Shape of `alpha`: (`batch_size`, no. of words in sequence B,\n",
    "        # `embed_size`), where sequence A is softly aligned with each word\n",
    "        # (axis 1 of `alpha`) in sequence B\n",
    "        alpha = torch.bmm(F.softmax(e.permute(0, 2, 1), dim=-1), A)\n",
    "        return beta, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15.5.1.2. So sánh\n",
    "Bước tiếp theo, chúng ta so sánh một từ trong chuỗi với chuỗi khác được căn chỉnh mềm với từ đó.\n",
    "Lưu ý rằng trong **“căn chỉnh mềm”**, tất cả từ đều đến từ một chuỗi, tuy nhiên do có những trọng số tập trung khác nhau, chúng sẽ được so sánh với một từ trong chuỗi khác. Để dễ minh hoạ, Fig. 15.5.2 ghép đôi từ với các từ được **căn chỉnh cứng**. Ví dụ, giả sử bước tập trung xác định rằng `“need” ` và `“sleep”` trong câu tiền đề đều được căn chỉnh với `“tired”` trong câu giả thuyết, thì cặp `“tired–need sleep”` sẽ được so sánh.\n",
    "Tại bước so sánh, chúng ta đưa những từ đã được ghép nối (toán tử  [⋅,⋅] ) và những từ đã căn chỉnh của chuỗi còn lại vào hàm  $g$  (một MLP):\n",
    "\n",
    "\\begin{split}\\mathbf{v}_{A,i} = g([\\mathbf{a}_i, \\boldsymbol{\\beta}_i]), i = 1, \\ldots, m\\\\ \\mathbf{v}_{B,j} = g([\\mathbf{b}_j, \\boldsymbol{\\alpha}_j]), j = 1, \\ldots, n.\\end{split}\n",
    " \n",
    "Trong (15.5.4),  $\\mathbf{v}_{A,i}$  là phép so sánh giữa từ thứ  $i$  của câu tiền đề và tất cả các từ trong câu giả thuyết được căn chỉnh mềm với từ thứ  $i$ ; trong khi  $\\mathbf{v}_{B,j}$  lại là phép so sánh giữa từ thứ  $j$  trong câu giả thuyết và tất cả từ trong câu tiền đề được căn chỉnh mềm với từ thứ  $j$ . Lớp Compare sau định nghĩa bước so sánh này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compare(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, **kwargs):\n",
    "        super(Compare, self).__init__(**kwargs)\n",
    "        self.g = mlp(num_inputs, num_hiddens, flatten=False)\n",
    "\n",
    "    def forward(self, A, B, beta, alpha):\n",
    "        V_A = self.g(torch.cat([A, beta], dim=2))\n",
    "        V_B = self.g(torch.cat([B, alpha], dim=2))\n",
    "        return V_A, V_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.5.1.3. Tổng hợp\n",
    "Với hai tập vector so sánh  $i = 1, \\ldots, m$ và  $j = 1 , \\ldots, n$ trong tay, ta sẽ tổng hợp các thông tin đó để suy ra mối quan hệ logic tại bước cuối cùng. Chúng ta bắt đầu bằng cách lấy tổng trên cả hai tập:\n",
    "\n",
    "<center>$\\mathbf{v}_A = \\sum_{i=1}^{m} \\mathbf{v}_{A,i}, \\quad \\mathbf{v}_B = \\sum_{j=1}^{n}\\mathbf{v}_{B,j}.$</center>\n",
    " \n",
    "Tiếp theo, chúng ta ghép nối hai kết quả tổng rồi đưa vào hàm  $h$  (một MLP) để thu được kết quả phân loại của mối quan hệ logic:\n",
    "\n",
    "<center>$\\hat{\\mathbf{y}} = h([\\mathbf{v}_A, \\mathbf{v}_B]).$</center>\n",
    " \n",
    "Bước tổng hợp được định nghĩa trong lớp `Aggregate` sau đây."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aggregate(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens, num_outputs, **kwargs):\n",
    "        super(Aggregate, self).__init__(**kwargs)\n",
    "        self.h = mlp(num_inputs, num_hiddens, flatten=True)\n",
    "        self.linear = nn.Linear(num_hiddens, num_outputs)\n",
    "\n",
    "    def forward(self, V_A, V_B):\n",
    "        # Sum up both sets of comparison vectors\n",
    "        V_A = V_A.sum(dim=1)\n",
    "        V_B = V_B.sum(dim=1)\n",
    "        # Feed the concatenation of both summarization results into an MLP\n",
    "        Y_hat = self.linear(self.h(torch.cat([V_A, V_B], dim=1)))\n",
    "        return Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15.5.1.4. Kết hợp tất cả lại\n",
    "Bằng cách gộp các bước thực hiện tập trung, so sánh và tổng hợp lại với nhau, ta định nghĩa mô hình tập trung có thể phân tách để cùng huấn luyện cả ba bước này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecomposableAttention(nn.Module):\n",
    "    def __init__(self, vocab, embed_size, num_hiddens, num_inputs_attend=100,\n",
    "                 num_inputs_compare=200, num_inputs_agg=400, **kwargs):\n",
    "        super(DecomposableAttention, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(len(vocab), embed_size)\n",
    "        self.attend = Attend(num_inputs_attend, num_hiddens)\n",
    "        self.compare = Compare(num_inputs_compare, num_hiddens)\n",
    "        # There are 3 possible outputs: entailment, contradiction, and neutral\n",
    "        self.aggregate = Aggregate(num_inputs_agg, num_hiddens, num_outputs=3)\n",
    "\n",
    "    def forward(self, X):\n",
    "        premises, hypotheses = X\n",
    "        A = self.embedding(premises)\n",
    "        B = self.embedding(hypotheses)\n",
    "        beta, alpha = self.attend(A, B)\n",
    "        V_A, V_B = self.compare(A, B, beta, alpha)\n",
    "        Y_hat = self.aggregate(V_A, V_B)\n",
    "        return Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.5.2. Huấn luyện và Đánh giá Mô hình\n",
    "Bây giờ ta sẽ huấn luyện và đánh giá mô hình tập trung có thế phân tách vừa được định nghĩa trên tập dữ liệu SNLI. Ta bắt đầu bằng việc đọc tập dữ liệu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.5.2.1. Đọc tập dữ liệu\n",
    "Ta tải xuống và đọc tập dữ liệu SNLI bằng hàm định nghĩa trong Section 15.4. Kích thước batch và độ dài chuỗi được đặt là  $256$  và  $50$ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_steps = 256, 50\n",
    "train_iter, test_iter, vocab = d2l.load_data_snli(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.5.2.2. Tạo mô hình\n",
    "Ta sử dụng embedding GloVe  100 -chiều đã tiền huấn luyện để biểu diễn các token đầu vào. Do đó, ta định nghĩa trước chiều của các vector  $\\mathbf{a}_i$  và  $\\mathbf{b}_j$  trong `:eqref:eq_nli_e` là  $100$ . Chiều đầu ra của hàm  $f$  trong `:eqref:eq_nli_e` và  $g$  trong `:eqref:eq_nli_v_ab` được đặt bằng  $200$ . Sau đó ta tạo thực thể của mô hình, khởi tạo tham số, và nạp embedding GloVe để khởi tạo các vector token đầu vào."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size, num_hiddens, devices = 100, 200, d2l.try_all_gpus()\n",
    "net = DecomposableAttention(vocab, embed_size, num_hiddens)\n",
    "glove_embedding = d2l.TokenEmbedding('glove.6b.100d')\n",
    "embeds = glove_embedding[vocab.idx_to_token]\n",
    "net.embedding.weight.data.copy_(embeds);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.5.2.3. Huấn luyện và Đánh giá Mô hình\n",
    "Trái ngược với hàm `split_batch` trong Section 12.5 nhận đầu vào đơn như một chuỗi văn bản (hoặc ảnh) chẳng hạn, ta định nghĩa hàm `split_batch_multi_inputs` để nhận đa đầu vào, ví dụ như cặp tiền đề và giả thuyết ở trong các minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs = 0.001, 4\n",
    "trainer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.5.2.4. Sử dụng Mô hình\n",
    "Cuối cùng, ta định nghĩa hàm dự đoán để xuất ra mối quan hệ logic giữa cặp tiền đề và giả thuyết."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "def predict_snli(net, vocab, premise, hypothesis):\n",
    "    net.eval()\n",
    "    premise = torch.tensor(vocab[premise], device=d2l.try_gpu())\n",
    "    hypothesis = torch.tensor(vocab[hypothesis], device=d2l.try_gpu())\n",
    "    label = torch.argmax(\n",
    "        net([premise.reshape((1, -1)),\n",
    "             hypothesis.reshape((1, -1))]), dim=1)\n",
    "    return 'entailment' if label == 0 else 'contradiction' if label == 1 \\\n",
    "            else 'neutral'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể sử dụng mô hình đã huấn luyện để thu được kết quả suy luận ngôn ngữ tự nhiên cho các cặp câu mẫu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_snli(net, vocab, ['he', 'is', 'good', '.'], ['he', 'is', 'bad', '.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.5.3. Tóm tắt\n",
    "- Mô hình tập trung có thể phân tách bao gồm 3 bước để dự đoán mối quan hệ logic giữa cặp tiền đề và giả thuyết: thực hiện tập trung, so sánh và tổng hợp.\n",
    "- Với cơ chế tập trung, ta có thể căn chỉnh các từ trong một chuỗi văn bản với tất cả các từ trong chuỗi văn bản còn lại, và ngược lại. Đây là kỹ thuật căn chỉnh mềm, sử dụng trung bình có trọng số, trong đó các trọng số có độ lớn hợp lý được gán với các từ sẽ được căn chỉnh.\n",
    "- Thủ thuật phân tách tầng tập trung giúp giảm độ phức tạp thành tuyến tính thay vì là bậc hai khi tính toán trọng số tập trung.\n",
    "- Ta có thể sử dụng embedding từ đã tiền huấn luyện để biểu diễn đầu vào cho các tác vụ xử lý ngôn ngữ tự nhiên xuôi dòng, ví dụ như suy luận ngôn ngữ tự nhiên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.5.4. Bài tập\n",
    "1. Huấn luyện mô hình với các tập siêu tham số khác nhau. Bạn có thể thu được độ chính xác cao hơn trên tập kiểm tra không?\n",
    "2. Những điểm hạn chế chính của mô hình tập trung kết hợp đối với suy luận ngôn ngữ tự nhiên là gì?\n",
    "3. Giả sử ta muốn tính độ tương tự ngữ nghĩa (một giá trị liên tục trong khoảng  $0$  và  $1$ ) cho một cặp câu bất kỳ. Ta sẽ thu thập và gán nhãn tập dữ liệu như thế nào? Bạn có thể thiết kế một mô hình với cơ chế tập trung không?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.6. Tinh chỉnh BERT cho các Ứng dụng Cấp Chuỗi và Cấp Token\n",
    "Trong các phần trước, ta đã thiết kế các mô hình khác nhau cho các ứng dụng xử lý ngôn ngữ tự nhiên, dựa trên RNN, CNN, MLP và cơ chế tập trung. Những mô hình này rất hữu ích khi mô hình bị giới hạn về không gian bộ nhớ hoặc thời gian thực thi; tuy nhiên, việc thiết kế thủ công một mô hình cụ thể cho mọi tác vụ xử lý ngôn ngữ tự nhiên trong thực tế là điều không khả thi. Trong Section 14.8, chúng ta đã giới thiệu mô hình BERT được tiền huấn luyện mà chỉ yêu cầu thay đổi kiến trúc tối thiểu cho một loạt các tác vụ xử lý ngôn ngữ tự nhiên. Một mặt, tại thời điểm BERT được đề xuất, nó đã cải thiện kết quả tốt nhất trên các tác vụ xử lý ngôn ngữ tự nhiên khác nhau. Mặt khác, như đã lưu ý trong Section 14.10, hai phiên bản của mô hình BERT gốc lần lượt có 110 triệu và 340 triệu tham số. Do đó, khi có đủ tài nguyên tính toán, ta có thể xem xét việc tinh chỉnh BERT cho các ứng dụng xử lý ngôn ngữ tự nhiên xuôi dòng.\n",
    "\n",
    "Sau đây, ta sẽ tổng quát hóa một số ứng dụng xử lý ngôn ngữ tự nhiên thành các ứng dụng cấp độ chuỗi và cấp độ token. Ở cấp độ chuỗi, chúng tôi sẽ giới thiệu cách chuyển đổi biểu diễn BERT của văn bản đầu vào thành nhãn đầu ra trong các tác vụ phân loại văn bản đơn và phân loại hay hồi quy cặp văn bản. Ở cấp độ token, chúng tôi sẽ giới thiệu ngắn gọn các ứng dụng mới như gán thẻ văn bản và trả lời câu hỏi, từ đó làm sáng tỏ cách BERT biểu diễn đầu vào và biến đổi chúng thành nhãn đầu ra như thế nào. Trong quá trình tinh chỉnh, những “thay đổi kiến trúc tối thiểu” mà BERT yêu cầu trên các ứng dụng khác nhau là các tầng kết nối đầy đủ được bổ sung. Trong quá trình học có giám sát của một ứng dụng xuôi dòng, tham số của các tầng bổ sung này được học từ đầu trong khi tất cả các tham số trong mô hình BERT đã tiền huấn luyện sẽ được tinh chỉnh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.6.1. Phân loại Văn bản Đơn\n",
    "Tác vụ phân loại văn bản đơn nhận một chuỗi văn bản đơn làm đầu vào và đầu ra là kết quả phân loại của văn bản đó. Bên cạnh tác vụ phân tích cảm xúc mà ta đã nghiên cứu trong chương này, tập dữ liệu **CoLA (Corpus of Linguistic Acceptability)** cũng được sử dụng cho tác vụ phân loại văn bản đơn, đánh giá xem một câu đã cho có chấp nhận được về mặt ngữ pháp hay không [Warstadt et al., 2019]. Ví dụ, câu `“I should study.”` là chấp nhận được nhưng câu `“I should studying.”` thì không.\n",
    "\n",
    "![](images/bert-one-seq.svg)\n",
    "\n",
    "Fig. 15.6.1 Tinh chỉnh mô hình BERT cho các ứng dụng phân loại văn bản đơn, ví dụ như phân tích cảm xúc hay đánh giá khả năng chấp nhận được về ngôn ngữ học. Giả sử văn bản đơn đầu vào có sáu token.\n",
    "\n",
    "Section 14.8 mô tả biểu diễn đầu vào của BERT. Chuỗi đầu vào BERT biểu diễn cả văn bản đơn và cặp văn bản một cách rạch ròi, trong đó token đặc biệt `“<cls>”` được sử dụng cho các tác vụ phân loại chuỗi, và token đặc biệt `“<sep>”` đánh dấu vị trí kết thúc của văn bản đơn hoặc vị trí phân tách cặp văn bản. Như minh họa trong Fig. 15.6.1, biểu diễn BERT của token đặc biệt `“<cls>”` mã hóa thông tin của toàn bộ chuỗi văn bản đầu vào trong các tác vụ phân loại văn bản đơn. Là biểu diễn của văn bản đầu vào đơn, vector này sẽ được truyền vào một mạng MLP nhỏ chứa các tầng kết nối đầy đủ để biến đổi thành phân phối của các giá trị nhãn rời rạc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.6.3. Gán thẻ Văn bản\n",
    "Bây giờ ta hãy xem xét các tác vụ ở mức token, ví dụ như gán thẻ văn bản, nơi mỗi token được gán một nhãn. Trong số các tác vụ gán thẻ văn bản, gán thẻ từ loại (**part-of-speech tagging**) gán cho mỗi từ một thẻ từ loại (ví dụ, tính từ hay danh từ) dựa vào vai trò của từ đó trong câu. Ví dụ, dựa vào tập thẻ Penn Treebank II, câu “John Smith ’s car is new” nên được gán thẻ như “NNP (danh từ riêng, số ít) NNP POS (sở hữu cách) NN (danh từ, số ít hoặc nhiều) VB (động từ, động từ nguyên thể không”to“) JJ (tính từ)”.\n",
    "\n",
    "![](images/bert-tagging.svg)\n",
    "\n",
    "Fig. 15.6.3 Tinh chỉnh BERT cho ứng dụng gán thẻ văn bản, ví dụ như gán thẻ từ loại. Giả sử đầu vào là một văn bản đơn có sáu token.\n",
    "\n",
    "Tinh chỉnh BERT cho ứng dụng gán thẻ văn bản được minh họa trong Fig. 15.6.3. So với Fig. 15.6.1, sự khác biệt duy nhất là biểu diễn BERT của mỗi token trong văn bản đầu vào được truyền vào cùng một mạng kết nối đầy đủ bổ sung để đưa ra nhãn của các token, ví dụ như thẻ từ loại."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.6.4. Trả lời Câu hỏi\n",
    "Là một ứng dụng khác ở mức token, **trả lời câu hỏi** phản ánh khả năng đọc hiểu. Ví dụ, tập dữ liệu trả lời câu hỏi Stanford (SQuAD v1.1) bao gồm các đoạn văn và các câu hỏi, nơi mà câu trả lời cho mỗi câu hỏi chỉ là một phần văn bản (khoảng văn bản - text span) trong đoạn văn mà câu hỏi đang đề cập tới [Rajpurkar et al., 2016]. Để giải thích, hãy xét đoạn văn sau “Một số chuyên gia cho rằng sự hiệu quả của khẩu trang là chưa thể khẳng định. Tuy nhiên, các nhà sản xuất khẩu trang cho rằng sản phẩm của họ, như là khẩu trang N95, có thể bảo vệ khỏi virus.” và câu hỏi “Ai cho rằng khẩu trang N95 có thể bảo vệ khỏi virus?”. Câu trả lời nên là khoảng văn bản “các nhà sản xuất khẩu trang” trong đoạn văn. Vì thế, mục đích trong SQuAD v1.1 là dự đoán điểm khởi đầu và kết thúc của khoảng văn bản trong đoạn văn, khi cho trước câu hỏi và đoạn văn.\n",
    "\n",
    "![](images/bert-qa.svg)\n",
    "\n",
    "Fig. 15.6.4 Tinh chỉnh BERT cho trả lời câu hỏi. Giả sử rằng cặp văn bản đầu vào có hai và ba token.\n",
    "\n",
    "Để tinh chỉnh BERT cho ứng dụng trả lời câu hỏi, câu hỏi và đoạn văn được đóng gói tương ứng lần lượt là chuỗi văn bản thứ nhất và thứ hai trong đầu vào của BERT. Để dự đoán vị trí của phần bắt đầu của khoảng văn bản, cùng một tầng kết nối đầy đủ được thêm vào sẽ chuyển hóa biểu diễn BERT của bất kỳ token nào từ đoạn văn bản có vị trí  $i$  thành một giá trị vô hướng  $s_i$ . Các giá trị vô hướng của tất cả token trong đoạn văn được tiếp tục biến đổi bởi hàm softmax trở thành một phân phối xác suất, dẫn tới mỗi vị trí  $i$  của token trong đoạn văn được gán cho một xác suất  $p_i$ , là xác suất token đó là điểm bắt đầu của khoảng văn bản. Dự đoán điểm kết thúc của khoảng văn bản cũng tương tự, ngoại trừ việc các tham số trong tầng kết nối đầy đủ mở rộng là độc lập với các tầng để dự đoán điểm bắt đầu. Khi dự đoán điểm kết thúc, token có vị trí  $i$  trong đoạn văn được biến đổi thành một giá trị vô hướng  ei  bởi tầng kết nối đầy đủ. Fig. 15.6.4 minh họa quá trình tinh chỉnh BERT cho ứng dụng trả lời câu hỏi.\n",
    "\n",
    "Cho việc trả lời câu hỏi, mục đích của huấn luyện có giám sát đơn giản là cực đại hóa hàm log hợp lý của các vị trí bắt đầu và kết thúc nhãn gốc. Khi dự đoán khoảng văn bản, ta có thể tính toán giá trị  $s_i+e_j$  cho một khoảng hợp lệ từ vị trí  $i$  tới vị trí  $j$  ( $i≤j$ ), và đưa ra khoảng có giá trị cao nhất làm đầu ra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.6.5. Tóm tắt\n",
    "- BERT chỉ yêu cầu các thay đổi tối thiểu tới kiến trúc (thêm các tầng kết nối đầy đủ) cho nhiều ứng dụng xử lý ngôn ngữ tự nhiên ở mức chuỗi và mức token, ví dụ như phân loại văn bản đơn (phân tích cảm xúc và kiểm tra khả năng chấp nhận được về ngôn ngữ), phân loại hoặc hồi quy cặp văn bản (suy luận ngôn ngữ tự nhiên và đo sự tương đồng ngữ nghĩa văn bản), gán thẻ văn bản (như gán thẻ từ loại) và trả lời câu hỏi.\n",
    "- Trong suốt quá trình học có giám sát của một ứng dụng xuôi dòng, các thông số của các tầng mở rộng được học từ đầu trong khi tất cả các thông số trong mô hình BERT đã tiền huấn luyện sẽ được tinh chỉnh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.6.6. Bài tập\n",
    "1. Hãy thiết kế một công cụ tìm kiếm các bài báo tin tức. Khi hệ thống nhận một truy vấn (ví dụ, “ngành công nghiệp dầu mỏ trong đại dịch COVID-19”), nó trả về một danh sách xếp hạng các bài viết tin tức liên quan tới truy vấn nhất. Giả sử như ta có một tập lớn các bài báo và một số lượng lớn các truy vấn. Để đơn giản hóa vấn đề, giả thiết rằng bài báo liên quan nhất được gán nhãn cho từng truy vấn. Làm cách nào để ta áp dụng phương pháp lấy mẫu âm (xem Section 14.2.1) và BERT khi thiết kế thuật toán?\n",
    "2. Làm thế nào để tận dụng BERT khi huấn luyện các mô hình ngôn ngữ?\n",
    "3. Làm thế nào để tận dụng BERT trong dịch máy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.7. Suy luận Ngôn ngữ Tự nhiên: Tinh chỉnh BERT¶\n",
    "Ở các phần đầu của chương này, ta đã thiết kế một kiến trúc dựa trên cơ chế tập trung (trong Section 15.5) cho tác vụ suy luận ngôn ngữ tự nhiên trên tập dữ liệu SNLI (như được mô tả trong Section 15.4). Bây giờ ta trở lại tác vụ này qua thực hiện tinh chỉnh BERT. Như đã thảo luận trong Section 15.6, suy luận ngôn ngữ tự nhiên là bài toán phân loại cặp văn bản ở cấp độ chuỗi, và việc tinh chỉnh BERT chỉ đòi hỏi thêm một kiến trúc bổ trợ dựa trên MLP, như minh họa trong Fig. 15.7.1.\n",
    "\n",
    "![](images/nlp-map-nli-bert.svg)\n",
    "\n",
    "Fig. 15.7.1 Phần này truyền BERT đã tiền huấn luyện vào một kiến trúc dựa trên MLP cho suy luận ngôn ngữ tự nhiên.\n",
    "\n",
    "Trong phần này, chúng ta sẽ tải một phiên bản BERT đã tiền huấn luyện kích thước nhỏ, rồi tinh chỉnh nó để suy luận ngôn ngữ tự nhiên trên tập dữ liệu SNLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import multiprocessing\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.7.1. Nạp BERT đã Tiền huấn luyện\n",
    "Chúng ta đã giải thích cách tiền huấn luyện BERT trên tập dữ liệu WikiText-2 trong Section 14.9 và Section 14.10 (lưu ý rằng mô hình BERT ban đầu được tiền huấn luyện trên các kho ngữ liệu lớn hơn nhiều). Ở thảo luận trong Section 14.10, mô hình BERT gốc có hàng trăm triệu tham số. Trong phần sau đây, chúng tôi cung cấp hai phiên bản BERT tiền huấn luyện: `“bert.base”` có kích thước xấp xỉ mô hình BERT cơ sở gốc, là mô hình đòi hỏi nhiều tài nguyên tính toán để tinh chỉnh, trong khi `“bert.small”` là phiên bản nhỏ để thuận tiện cho việc minh họa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.DATA_HUB['bert.base'] = (d2l.DATA_URL + 'bert.base.torch.zip',\n",
    "                             '225d66f04cae318b841a13d32af3acc165f253ac')\n",
    "d2l.DATA_HUB['bert.small'] = (d2l.DATA_URL + 'bert.small.torch.zip',\n",
    "                              'c72329e68a732bef0452e4b96a1c341c8910f81f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cả hai mô hình BERT đã tiền huấn luyện đều chứa tập tin `“vocab.json”` định nghĩa tập từ vựng và tập tin `“pretrained.params”` chứa các tham số tiền huấn luyện. Ta thực hiện hàm `load_pretrained_model` sau đây để nạp các tham số đã tiền huấn luyện của BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model(pretrained_model, num_hiddens, ffn_num_hiddens,\n",
    "                          num_heads, num_layers, dropout, max_len, devices):\n",
    "    data_dir = d2l.download_extract(pretrained_model)\n",
    "    # Define an empty vocabulary to load the predefined vocabulary\n",
    "    vocab = d2l.Vocab()\n",
    "    vocab.idx_to_token = json.load(open(os.path.join(data_dir, 'vocab.json')))\n",
    "    vocab.token_to_idx = {\n",
    "        token: idx for idx, token in enumerate(vocab.idx_to_token)}\n",
    "    bert = d2l.BERTModel(len(vocab), num_hiddens, norm_shape=[256],\n",
    "                         ffn_num_input=256, ffn_num_hiddens=ffn_num_hiddens,\n",
    "                         num_heads=4, num_layers=2, dropout=0.2,\n",
    "                         max_len=max_len, key_size=256, query_size=256,\n",
    "                         value_size=256, hid_in_features=256,\n",
    "                         mlm_in_features=256, nsp_in_features=256)\n",
    "    # Load pretrained BERT parameters\n",
    "    bert.load_state_dict(\n",
    "        torch.load(os.path.join(data_dir, 'pretrained.params')))\n",
    "    return bert, vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để thuận tiện biểu diễn trên hầu hết các phần cứng, ta sẽ nạp và tinh chỉnh phiên bản nhỏ (`“bert-small”`) của BERT đã tiền huấn luyện ở phần này. Phần bài tập sẽ hướng dẫn cách tinh chỉnh mô hình `“bert-base”` lớn hơn nhiều, để cải thiện đáng kể độ chính xác khi kiểm tra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ..\\data\\bert.small.torch.zip from http://d2l-data.s3-accelerate.amazonaws.com/bert.small.torch.zip...\n"
     ]
    }
   ],
   "source": [
    "devices = d2l.try_all_gpus()\n",
    "bert, vocab = load_pretrained_model('bert.small', num_hiddens=256,\n",
    "                                    ffn_num_hiddens=512, num_heads=4,\n",
    "                                    num_layers=2, dropout=0.1, max_len=512,\n",
    "                                    devices=devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.7.2. Tập dữ liệu để Tinh chỉnh BERT\n",
    "Đối với tác vụ xuôi dòng suy luận ngôn ngữ tự nhiên trên tập dữ liệu SNLI, ta định nghĩa một lớp `SNLIBERTDataset` là tập dữ liệu tuỳ biến. Trong mỗi mẫu, tiền đề và giả thuyết tạo thành một cặp chuỗi văn bản và được đóng gói thành một chuỗi đầu vào BERT như được mô tả trong Fig. 15.6.2. Nhắc lại Section 14.8.4, ID của các đoạn đó được sử dụng để phân biệt tiền đề và giả thuyết trong chuỗi đầu vào BERT. Với độ dài tối đa đã định trước của chuỗi đầu vào BERT (`max_len`), token cuối cùng của đoạn dài hơn trong cặp văn bản đầu vào sẽ liên tục bị xóa cho đến khi độ dài của nó là `max_len`. Để tăng tốc quá trình tạo tập dữ liệu SNLI cho việc tinh chỉnh BERT, ta sử dụng 4 tiến trình thợ để tạo ra các mẫu cho tập huấn luyện và tập kiểm tra một cách song song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNLIBERTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, max_len, vocab=None):\n",
    "        all_premise_hypothesis_tokens = [[\n",
    "            p_tokens, h_tokens] for p_tokens, h_tokens in zip(*[\n",
    "                d2l.tokenize([s.lower() for s in sentences])\n",
    "                for sentences in dataset[:2]])]\n",
    "\n",
    "        self.labels = torch.tensor(dataset[2])\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "        (self.all_token_ids, self.all_segments,\n",
    "         self.valid_lens) = self._preprocess(all_premise_hypothesis_tokens)\n",
    "        print('read ' + str(len(self.all_token_ids)) + ' examples')\n",
    "\n",
    "    def _preprocess(self, all_premise_hypothesis_tokens):\n",
    "        pool = multiprocessing.Pool(4)  # Use 4 worker processes\n",
    "        out = pool.map(self._mp_worker, all_premise_hypothesis_tokens)\n",
    "        all_token_ids = [token_ids for token_ids, segments, valid_len in out]\n",
    "        all_segments = [segments for token_ids, segments, valid_len in out]\n",
    "        valid_lens = [valid_len for token_ids, segments, valid_len in out]\n",
    "        return (torch.tensor(all_token_ids, dtype=torch.long),\n",
    "                torch.tensor(all_segments,\n",
    "                             dtype=torch.long), torch.tensor(valid_lens))\n",
    "\n",
    "    def _mp_worker(self, premise_hypothesis_tokens):\n",
    "        p_tokens, h_tokens = premise_hypothesis_tokens\n",
    "        self._truncate_pair_of_tokens(p_tokens, h_tokens)\n",
    "        tokens, segments = d2l.get_tokens_and_segments(p_tokens, h_tokens)\n",
    "        token_ids = self.vocab[tokens] + [self.vocab['<pad>']] \\\n",
    "                             * (self.max_len - len(tokens))\n",
    "        segments = segments + [0] * (self.max_len - len(segments))\n",
    "        valid_len = len(tokens)\n",
    "        return token_ids, segments, valid_len\n",
    "\n",
    "    def _truncate_pair_of_tokens(self, p_tokens, h_tokens):\n",
    "        # Reserve slots for '<CLS>', '<SEP>', and '<SEP>' tokens for the BERT\n",
    "        # input\n",
    "        while len(p_tokens) + len(h_tokens) > self.max_len - 3:\n",
    "            if len(p_tokens) > len(h_tokens):\n",
    "                p_tokens.pop()\n",
    "            else:\n",
    "                h_tokens.pop()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.all_token_ids[idx], self.all_segments[idx],\n",
    "                self.valid_lens[idx]), self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi tải xuống tập dữ liệu SNLI, ta tạo các mẫu huấn luyện và kiểm tra bằng cách khởi tạo lớp `SNLIBERTDataset`. Các mẫu đó sẽ được đọc từ các minibatch trong quá trình huấn luyện và kiểm tra của suy luận ngôn ngữ tự nhiên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce `batch_size` if there is an out of memory error. In the original BERT\n",
    "# model, `max_len` = 512\n",
    "batch_size, max_len, num_workers = 512, 128, d2l.get_dataloader_workers()\n",
    "data_dir = d2l.download_extract('SNLI')\n",
    "train_set = SNLIBERTDataset(d2l.read_snli(data_dir, True), max_len, vocab)\n",
    "test_set = SNLIBERTDataset(d2l.read_snli(data_dir, False), max_len, vocab)\n",
    "train_iter = torch.utils.data.DataLoader(train_set, batch_size, shuffle=True,\n",
    "                                         num_workers=num_workers)\n",
    "test_iter = torch.utils.data.DataLoader(test_set, batch_size,\n",
    "                                        num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.7.3. Tinh chỉnh BERT\n",
    "Như Fig. 15.6.2 đã chỉ ra, tinh chỉnh BERT trong suy luận ngôn ngữ tự nhiên chỉ yêu cầu thêm một perceptron đa tầng gồm hai tầng kết nối đầy đủ (xem `self.hiised` và `self.output` trong lớp `BERTClassifier` bên dưới). Perceptron đa tầng này biến đổi biểu diễn BERT của token đặc biệt `“<cls>”`, là token mã hóa thông tin của cả tiền đề và giả thuyết, thành ba đầu ra của suy luận ngôn ngữ tự nhiên: kéo theo, đối lập và trung tính."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.encoder = bert.encoder\n",
    "        self.hidden = bert.hidden\n",
    "        self.output = nn.Linear(256, 3)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        tokens_X, segments_X, valid_lens_x = inputs\n",
    "        encoded_X = self.encoder(tokens_X, segments_X, valid_lens_x)\n",
    "        return self.output(self.hidden(encoded_X[:, 0, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau đây, mô hình BERT đã tiền huấn luyện bert được đưa vào thực thể net của lớp `BERTClassifier` cho tác vụ xuôi dòng. Thông thường khi lập trình tinh chỉnh BERT, chỉ các tham số của tầng đầu ra của perception đa tầng bổ sung (`net.output`) mới được học từ đầu. Còn tất cả các tham số của bộ mã hóa BERT đã tiền huấn luyện (`net.encoder`) và tầng ẩn của perception đa tầng bổ sung (`net.hidden`) thì sẽ được tinh chỉnh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BERTClassifier(bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nhớ lại rằng trong Section 14.8, cả 2 lớp `MaskLM` và lớp `NextSentencePred` đều có các tham số của perceptron đa tầng mà chúng sử dụng. Các tham số này là một phần của các tham số trong mô hình BERT đã tiền huấn luyện `bert`, và do đó là một phần của các tham số trong net. Tuy nhiên, các tham số này chỉ được dùng để tính toán mất mát của mô hình ngôn ngữ có mặt nạ và mất mát khi dự đoán câu tiếp theo trong quá trình tiền huấn luyện. Hai hàm mất mát này không liên quan đến việc tinh chỉnh trong các ứng dụng xuôi dòng, do đó các tham số của perceptron đa tầng dùng trong `MaskLM` và `NextSentencePred` không được cập nhật khi tinh chỉnh BERT.\n",
    "\n",
    "Để cho phép sử dụng các tham số với gradient không cập nhật, ta đặt cờ `ignore_stale_grad = True` trong hàm step của `d2l.train_batch_ch13`. Chúng ta sử dụng chức năng này để huấn luyện và đánh giá mô hình net bằng cách sử dụng tập huấn luyện (`train_iter`) và tập kiểm tra (`test_iter`) của SNLI. Do hạn chế về tài nguyên tính toán, độ chính xác của việc huấn luyện và kiểm tra vẫn còn có thể được cải thiện hơn nữa: chúng sẽ thảo luận vấn đề này trong phần bài tập."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs = 1e-4, 5\n",
    "trainer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.7.4. Tóm tắt\n",
    "- Chúng ta có thể tinh chỉnh mô hình BERT đã tiền huấn luyện cho các ứng dụng xuôi dòng, chẳng hạn như suy luận ngôn ngữ tự nhiên trên tập dữ liệu SNLI.\n",
    "- Trong quá trình tinh chỉnh, mô hình BERT trở thành một phần của mô hình ứng dụng xuôi dòng. Các tham số chỉ liên quan đến phần mất mát trong tiền huấn luyện sẽ không được cập nhật trong quá trình tinh chỉnh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.7.5. Bài tập\n",
    "1. Hãy tinh chỉnh một mô hình BERT tiền huấn luyện lớn hơn, có kích thước tương đương với mô hình BERT cơ sở ban đầu, nếu tài nguyên tính toán của bạn cho phép. Hãy thay đổi các đối số trong hàm `load_pretrained_mode`l: thay thế `‘bert.small’` bằng `‘bert.base’`, lần lượt tăng giá trị của `num_hiddens = 256` ,`ffn_num_hiddens = 512`, `num_heads = 4`, `num_layers = 2` thành `768,3072, 12,12`. Bằng cách tăng số epoch khi tinh chỉnh (và có thể điều chỉnh các siêu tham số khác), có thể nhận được độ chính xác trên tập kiểm tra cao hơn 0,86 không?\n",
    "2. Làm thế nào để cắt ngắn một cặp chuỗi theo tỉ lệ độ dài của chúng? So sánh phương thức cắt ngắn cặp này và phương thức được sử dụng trong lớp `SNLIBERTDataset`. Ưu và nhược điểm của chúng là gì?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
